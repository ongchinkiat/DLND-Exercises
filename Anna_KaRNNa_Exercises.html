<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>Anna_KaRNNa_Exercises</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Anna-KaRNNa">Anna KaRNNa<a class="anchor-link" href="#Anna-KaRNNa">&#182;</a></h1><p>In this notebook, we'll build a character-wise RNN trained on Anna Karenina, one of my all-time favorite books. It'll be able to generate new text based on the text from the book.</p>
<p>This network is based off of Andrej Karpathy's <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">post on RNNs</a> and <a href="https://github.com/karpathy/char-rnn">implementation in Torch</a>. Also, some information <a href="http://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html">here at r2rt</a> and from <a href="https://github.com/sherjilozair/char-rnn-tensorflow">Sherjil Ozair</a> on GitHub. Below is the general architecture of the character-wise RNN.</p>
<p><img src="assets/charseq.jpeg" width="500"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">namedtuple</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First we'll load the text file and convert it into integers for our network to use. Here I'm creating a couple dictionaries to convert the characters to and from integers. Encoding the characters as integers makes it easier to use as input in the network.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;anna.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">text</span><span class="o">=</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">vocab_to_int</span> <span class="o">=</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span>
<span class="n">int_to_vocab</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">encoded</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">vocab_to_int</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">text</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's check out the first 100 characters, make sure everything is peachy. According to the <a href="http://americanbookreview.org/100bestlines.asp">American Book Review</a>, this is the 6th best first line of a book ever.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[3]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>&#39;Chapter 1\n\n\nHappy families are all alike; every unhappy family is unhappy in its own\nway.\n\nEverythin&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we can see the characters encoded as integers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">encoded</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[4]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>array([60, 37, 28,  7, 38, 32, 15,  1,  4, 58, 58, 58, 33, 28,  7,  7, 64,
        1,  5, 28, 19, 81, 36, 81, 32, 70,  1, 28, 15, 32,  1, 28, 36, 36,
        1, 28, 36, 81,  0, 32, 22,  1, 32, 82, 32, 15, 64,  1, 21, 40, 37,
       28,  7,  7, 64,  1,  5, 28, 19, 81, 36, 64,  1, 81, 70,  1, 21, 40,
       37, 28,  7,  7, 64,  1, 81, 40,  1, 81, 38, 70,  1, 50, 47, 40, 58,
       47, 28, 64,  2, 58, 58, 14, 82, 32, 15, 64, 38, 37, 81, 40], dtype=int32)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since the network is working with individual characters, it's similar to a classification problem in which we are trying to predict the next character from the previous text.  Here's how many 'classes' our network has to pick from.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[5]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>83</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Making-training-mini-batches">Making training mini-batches<a class="anchor-link" href="#Making-training-mini-batches">&#182;</a></h2><p>Here is where we'll make our mini-batches for training. Remember that we want our batches to be multiple sequences of some desired number of sequence steps. Considering a simple example, our batches would look like this:</p>
<p>&lt;img src="assets/sequence_batching@1x.png" width=500px&gt;</p>
<p><br>
We have our text encoded as integers as one long array in <code>encoded</code>. Let's create a function that will give us an iterator for our batches. I like using <a href="https://jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/">generator functions</a> to do this. Then we can pass <code>encoded</code> into this function and get our batch generator.</p>
<p>The first thing we need to do is discard some of the text so we only have completely full batches. Each batch contains $N \times M$ characters, where $N$ is the batch size (the number of sequences) and $M$ is the number of steps. Then, to get the number of batches we can make from some array <code>arr</code>, you divide the length of <code>arr</code> by the batch size. Once you know the number of batches and the batch size, you can get the total number of characters to keep.</p>
<p>After that, we need to split <code>arr</code> into $N$ sequences. You can do this using <code>arr.reshape(size)</code> where <code>size</code> is a tuple containing the dimensions sizes of the reshaped array. We know we want $N$ sequences (<code>n_seqs</code> below), let's make that the size of the first dimension. For the second dimension, you can use <code>-1</code> as a placeholder in the size, it'll fill up the array with the appropriate data for you. After this, you should have an array that is $N \times (M * K)$ where $K$ is the number of batches.</p>
<p>Now that we have this array, we can iterate through it to get our batches. The idea is each batch is a $N \times M$ window on the array. For each subsequent batch, the window moves over by <code>n_steps</code>. We also want to create both the input and target arrays. Remember that the targets are the inputs shifted over one character. You'll usually see the first input character used as the last target character, so something like this:</p>
<div class="highlight"><pre><span></span><span class="n">y</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:],</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
</pre></div>
<p>where <code>x</code> is the input batch and <code>y</code> is the target batch.</p>
<p>The way I like to do this window is use <code>range</code> to take steps of size <code>n_steps</code> from $0$ to <code>arr.shape[1]</code>, the total number of steps in each sequence. That way, the integers you get from <code>range</code> always point to the start of a batch, and each window is <code>n_steps</code> wide.</p>
<blockquote><p><strong>Exercise:</strong> Write the code for creating batches in the function below. The exercises in this notebook <em>will not be easy</em>. I've provided a notebook with solutions alongside this notebook. If you get stuck, checkout the solutions. The most important thing is that you don't copy and paste the code into here, <strong>type out the solution code yourself.</strong></p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_batches</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">n_seqs</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Create a generator that returns batches of size</span>
<span class="sd">       n_seqs x n_steps from arr.</span>
<span class="sd">       </span>
<span class="sd">       Arguments</span>
<span class="sd">       ---------</span>
<span class="sd">       arr: Array you want to make batches from</span>
<span class="sd">       n_seqs: Batch size, the number of sequences per batch</span>
<span class="sd">       n_steps: Number of sequence steps per batch</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># Get the batch size and number of batches we can make</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">n_seqs</span> <span class="o">*</span> <span class="n">n_steps</span>
    <span class="n">n_batches</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">batch_size</span>
    
    <span class="c1"># Keep only enough characters to make full batches</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="n">arr</span><span class="p">[:</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">n_batches</span><span class="p">]</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1"># Reshape into n_seqs rows</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_seqs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_steps</span><span class="p">):</span>
        <span class="c1"># The features</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">arr</span><span class="p">[:,</span> <span class="n">n</span><span class="p">:</span><span class="n">n</span><span class="o">+</span><span class="n">n_steps</span><span class="p">]</span>
        <span class="c1"># The targets, shifted by one</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:],</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="c1">#y = arr[:, n+1:n+n_steps+1]</span>
        <span class="k">yield</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now I'll make my data sets and we can check out what's going on here. Here I'm going to use a batch size of 10 and 50 sequence steps.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batches</span> <span class="o">=</span> <span class="n">get_batches</span><span class="p">(</span><span class="n">encoded</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>(1985000,)
(10, 198500)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">[:</span><span class="mi">10</span><span class="p">,</span> <span class="p">:</span><span class="mi">10</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">y</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">y</span><span class="p">[:</span><span class="mi">10</span><span class="p">,</span> <span class="p">:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>x
 [[60 37 28  7 38 32 15  1  4 58]
 [ 1 28 19  1 40 50 38  1 26 50]
 [82 81 40  2 58 58 72 80 32 70]
 [40  1 66 21 15 81 40 26  1 37]
 [ 1 81 38  1 81 70 16  1 70 81]
 [ 1 76 38  1 47 28 70 58 50 40]
 [37 32 40  1 25 50 19 32  1  5]
 [22  1 27 21 38  1 40 50 47  1]
 [38  1 81 70 40 41 38  2  1 74]
 [ 1 70 28 81 66  1 38 50  1 37]]

y
 [[37 28  7 38 32 15  1  4 58 58]
 [28 19  1 40 50 38  1 26 50 81]
 [81 40  2 58 58 72 80 32 70 16]
 [ 1 66 21 15 81 40 26  1 37 81]
 [81 38  1 81 70 16  1 70 81 15]
 [76 38  1 47 28 70 58 50 40 36]
 [32 40  1 25 50 19 32  1  5 50]
 [ 1 27 21 38  1 40 50 47  1 70]
 [ 1 81 70 40 41 38  2  1 74 37]
 [70 28 81 66  1 38 50  1 37 32]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you implemented <code>get_batches</code> correctly, the above output should look something like</p>

<pre><code>x
 [[55 63 69 22  6 76 45  5 16 35]
 [ 5 69  1  5 12 52  6  5 56 52]
 [48 29 12 61 35 35  8 64 76 78]
 [12  5 24 39 45 29 12 56  5 63]
 [ 5 29  6  5 29 78 28  5 78 29]
 [ 5 13  6  5 36 69 78 35 52 12]
 [63 76 12  5 18 52  1 76  5 58]
 [34  5 73 39  6  5 12 52 36  5]
 [ 6  5 29 78 12 79  6 61  5 59]
 [ 5 78 69 29 24  5  6 52  5 63]]

y
 [[63 69 22  6 76 45  5 16 35 35]
 [69  1  5 12 52  6  5 56 52 29]
 [29 12 61 35 35  8 64 76 78 28]
 [ 5 24 39 45 29 12 56  5 63 29]
 [29  6  5 29 78 28  5 78 29 45]
 [13  6  5 36 69 78 35 52 12 43]
 [76 12  5 18 52  1 76  5 58 52]
 [ 5 73 39  6  5 12 52 36  5 78]
 [ 5 29 78 12 79  6 61  5 59 63]
 [78 69 29 24  5  6 52  5 63 76]]</code></pre>
<p>although the exact numbers will be different. Check to make sure the data is shifted over one step for <code>y</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-the-model">Building the model<a class="anchor-link" href="#Building-the-model">&#182;</a></h2><p>Below is where you'll build the network. We'll break it up into parts so it's easier to reason about each bit. Then we can connect them up into the whole network.</p>
<p>&lt;img src="assets/charRNN.png" width=500px&gt;</p>
<h3 id="Inputs">Inputs<a class="anchor-link" href="#Inputs">&#182;</a></h3><p>First off we'll create our input placeholders. As usual we need placeholders for the training data and the targets. We'll also create a placeholder for dropout layers called <code>keep_prob</code>. This will be a scalar, that is a 0-D tensor. To make a scalar, you create a placeholder without giving it a size.</p>
<blockquote><p><strong>Exercise:</strong> Create the input placeholders in the function below.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_inputs</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Define placeholders for inputs, targets, and dropout </span>
<span class="sd">    </span>
<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        batch_size: Batch size, number of sequences per batch</span>
<span class="sd">        num_steps: Number of sequence steps in a batch</span>
<span class="sd">        </span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># Declare placeholders we&#39;ll feed into the graph</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;inputs&#39;</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;targets&#39;</span><span class="p">)</span>
    
    <span class="c1"># Keep probability placeholder for drop out layers</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;keep_prob&#39;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">keep_prob</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="LSTM-Cell">LSTM Cell<a class="anchor-link" href="#LSTM-Cell">&#182;</a></h3><p>Here we will create the LSTM cell we'll use in the hidden layer. We'll use this cell as a building block for the RNN. So we aren't actually defining the RNN here, just the type of cell we'll use in the hidden layer.</p>
<p>We first create a basic LSTM cell with</p>
<div class="highlight"><pre><span></span><span class="n">lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">num_units</span><span class="p">)</span>
</pre></div>
<p>where <code>num_units</code> is the number of units in the hidden layers in the cell. Then we can add dropout by wrapping it with</p>
<div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
</pre></div>
<p>You pass in a cell and it will automatically add dropout to the inputs or outputs. Finally, we can stack up the LSTM cells into layers with <a href="https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/rnn/MultiRNNCell"><code>tf.contrib.rnn.MultiRNNCell</code></a>. With this, you pass in a list of cells and it will send the output of one cell into the next cell. For example,</p>
<div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">cell</span><span class="p">]</span><span class="o">*</span><span class="n">num_layers</span><span class="p">)</span>
</pre></div>
<p>This might look a little weird if you know Python well because this will create a list of the same <code>cell</code> object. However, TensorFlow will create different weight matrices for all <code>cell</code> objects. Even though this is actually multiple LSTM cells stacked on each other, you can treat the multiple layers as one cell.</p>
<p>We also need to create an initial cell state of all zeros. This can be done like so</p>
<div class="highlight"><pre><span></span><span class="n">initial_state</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
<blockquote><p><strong>Exercise:</strong> Below, implement the <code>build_lstm</code> function to create these LSTM cells and the initial state.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_lstm</span><span class="p">(</span><span class="n">lstm_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Build LSTM cell.</span>
<span class="sd">    </span>
<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        keep_prob: Scalar tensor (tf.placeholder) for the dropout keep probability</span>
<span class="sd">        lstm_size: Size of the hidden layers in the LSTM cells</span>
<span class="sd">        num_layers: Number of LSTM layers</span>
<span class="sd">        batch_size: Batch size</span>

<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1">### Build the LSTM Cell</span>
    <span class="c1"># Use a basic LSTM cell</span>
    <span class="n">lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">lstm_size</span><span class="p">)</span>
    
    <span class="c1"># Add dropout to the cell outputs</span>
    <span class="n">drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="c1"># Stack up multiple LSTM layers, for deep learning</span>
    <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">drop</span><span class="p">]</span><span class="o">*</span><span class="n">num_layers</span><span class="p">)</span>
    <span class="n">initial_state</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">cell</span><span class="p">,</span> <span class="n">initial_state</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="RNN-Output">RNN Output<a class="anchor-link" href="#RNN-Output">&#182;</a></h3><p>Here we'll create the output layer. We need to connect the output of the RNN cells to a full connected layer with a softmax output. The softmax output gives us a probability distribution we can use to predict the next character, so we want this layer to have size $C$, the number of classes/characters we have in our text.</p>
<p>If our input has batch size $N$, number of steps $M$, and the hidden layer has $L$ hidden units, then the output is a 3D tensor with size $N \times M \times L$. The output of each LSTM cell has size $L$, we have $M$ of them, one for each sequence step, and we have $N$ sequences. So the total size is $N \times M \times L$.</p>
<p>We are using the same fully connected layer, the same weights, for each of the outputs. Then, to make things easier, we should reshape the outputs into a 2D tensor with shape $(M * N) \times L$. That is, one row for each sequence and step, where the values of each row are the output from the LSTM cells. We get the LSTM output as a list, <code>lstm_output</code>. First we need to concatenate this whole list into one array with <a href="https://www.tensorflow.org/api_docs/python/tf/concat"><code>tf.concat</code></a>. Then, reshape it (with <code>tf.reshape</code>) to size $(M * N) \times L$.</p>
<p>One we have the outputs reshaped, we can do the matrix multiplication with the weights. We need to wrap the weight and bias variables in a variable scope with <code>tf.variable_scope(scope_name)</code> because there are weights being created in the LSTM cells. TensorFlow will throw an error if the weights created here have the same names as the weights created in the LSTM cells, which they will be default. To avoid this, we wrap the variables in a variable scope so we can give them unique names.</p>
<blockquote><p><strong>Exercise:</strong> Implement the output layer in the function below.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_output</span><span class="p">(</span><span class="n">lstm_output</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Build a softmax layer, return the softmax output and logits.</span>
<span class="sd">    </span>
<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        </span>
<span class="sd">        lstm_output: List of output tensors from the LSTM layer</span>
<span class="sd">        in_size: Size of the input tensor, for example, size of the LSTM cells</span>
<span class="sd">        out_size: Size of this softmax layer</span>
<span class="sd">    </span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="c1"># Reshape output so it&#39;s a bunch of rows, one row for each step for each sequence.</span>
    <span class="c1"># Concatenate lstm_output over axis 1 (the columns)</span>
    <span class="n">seq_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">lstm_output</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Reshape seq_output to a 2D tensor with lstm_size columns</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">seq_output</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">])</span>
    
    <span class="c1"># Connect the RNN outputs to a softmax layer</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">):</span>
        <span class="c1"># Create the weight and bias variables here</span>
        <span class="n">softmax_w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">((</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">),</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
        <span class="n">softmax_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">out_size</span><span class="p">))</span>
    
    <span class="c1"># Since output is a bunch of rows of RNN cell outputs, logits will be a bunch</span>
    <span class="c1"># of rows of logit outputs, one for each step and sequence</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">softmax_w</span><span class="p">)</span> <span class="o">+</span><span class="n">softmax_b</span>
    
    <span class="c1"># Use softmax to get the probabilities for predicted characters</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">logits</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Training-loss">Training loss<a class="anchor-link" href="#Training-loss">&#182;</a></h3><p>Next up is the training loss. We get the logits and targets and calculate the softmax cross-entropy loss. First we need to one-hot encode the targets, we're getting them as encoded characters. Then, reshape the one-hot targets so it's a 2D tensor with size $(M*N) \times C$ where $C$ is the number of classes/characters we have. Remember that we reshaped the LSTM outputs and ran them through a fully connected layer with $C$ units. So our logits will also have size $(M*N) \times C$.</p>
<p>Then we run the logits and targets through <code>tf.nn.softmax_cross_entropy_with_logits</code> and find the mean to get the loss.</p>
<blockquote><p><strong>Exercise:</strong> Implement the loss calculation in the function below.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Calculate the loss from the logits and the targets.</span>
<span class="sd">    </span>
<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        logits: Logits from final fully connected layer</span>
<span class="sd">        targets: Targets for supervised learning</span>
<span class="sd">        lstm_size: Number of LSTM hidden units</span>
<span class="sd">        num_classes: Number of classes in targets</span>
<span class="sd">        </span>
<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="c1"># One-hot encode targets and reshape to match logits, one row per sequence per step</span>
    <span class="n">y_one_hot</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
    <span class="n">y_reshaped</span> <span class="o">=</span>  <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_one_hot</span><span class="p">,</span> <span class="n">logits</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span>
    
    <span class="c1"># Softmax cross entropy loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y_reshaped</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Optimizer">Optimizer<a class="anchor-link" href="#Optimizer">&#182;</a></h3><p>Here we build the optimizer. Normal RNNs have have issues gradients exploding and disappearing. LSTMs fix the disappearance problem, but the gradients can still grow without bound. To fix this, we can clip the gradients above some threshold. That is, if a gradient is larger than that threshold, we set it to the threshold. This will ensure the gradients never grow overly large. Then we use an AdamOptimizer for the learning step.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_optimizer</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">grad_clip</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Build optmizer for training, using gradient clipping.</span>
<span class="sd">    </span>
<span class="sd">        Arguments:</span>
<span class="sd">        loss: Network loss</span>
<span class="sd">        learning_rate: Learning rate for optimizer</span>
<span class="sd">    </span>
<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="c1"># Optimizer for training, using gradient clipping to control exploding gradients</span>
    <span class="n">tvars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()</span>
    <span class="n">grads</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">clip_by_global_norm</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">tvars</span><span class="p">),</span> <span class="n">grad_clip</span><span class="p">)</span>
    <span class="n">train_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">train_op</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">tvars</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">optimizer</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-network">Build the network<a class="anchor-link" href="#Build-the-network">&#182;</a></h3><p>Now we can put all the pieces together and build a class for the network. To actually run data through the LSTM cells, we will use <a href="https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn</code></a>. This function will pass the hidden and cell states across LSTM cells appropriately for us. It returns the outputs for each LSTM cell at each step for each sequence in the mini-batch. It also gives us the final LSTM state. We want to save this state as <code>final_state</code> so we can pass it to the first LSTM cell in the the next mini-batch run. For <code>tf.nn.dynamic_rnn</code>, we pass in the cell and initial state we get from <code>build_lstm</code>, as well as our input sequences. Also, we need to one-hot encode the inputs before going into the RNN.</p>
<blockquote><p><strong>Exercise:</strong> Use the functions you've implemented previously and <code>tf.nn.dynamic_rnn</code> to build the network.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">CharRNN</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
                       <span class="n">lstm_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> 
                       <span class="n">grad_clip</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">sampling</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    
        <span class="c1"># When we&#39;re using this network for sampling later, we&#39;ll be passing in</span>
        <span class="c1"># one character at a time, so providing an option for that</span>
        <span class="k">if</span> <span class="n">sampling</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span>

        <span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
        
        <span class="c1"># Build the input placeholder tensors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_prob</span> <span class="o">=</span> <span class="n">build_inputs</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>

        <span class="c1"># Build the LSTM cell</span>
        <span class="n">cell</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_state</span> <span class="o">=</span> <span class="n">build_lstm</span><span class="p">(</span><span class="n">lstm_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_prob</span><span class="p">)</span>

        <span class="c1">### Run the data through the RNN layers</span>
        <span class="c1"># First, one-hot encode the input tokens</span>
        <span class="n">x_one_hot</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        
        <span class="c1"># Run each sequence step through the RNN with tf.nn.dynamic_rnn </span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">x_one_hot</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_state</span> <span class="o">=</span> <span class="n">state</span>
        
        <span class="c1"># Get softmax predictions and logits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prediction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">logits</span> <span class="o">=</span> <span class="n">build_output</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        
        <span class="c1"># Loss and optimizer (with gradient clipping)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span>  <span class="n">build_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">build_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">grad_clip</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h2><p>Here are the hyperparameters for the network.</p>
<ul>
<li><code>batch_size</code> - Number of sequences running through the network in one pass.</li>
<li><code>num_steps</code> - Number of characters in the sequence the network is trained on. Larger is better typically, the network will learn more long range dependencies. But it takes longer to train. 100 is typically a good number here.</li>
<li><code>lstm_size</code> - The number of units in the hidden layers.</li>
<li><code>num_layers</code> - Number of hidden LSTM layers to use</li>
<li><code>learning_rate</code> - Learning rate for training</li>
<li><code>keep_prob</code> - The dropout keep probability when training. If you're network is overfitting, try decreasing this.</li>
</ul>
<p>Here's some good advice from Andrej Karpathy on training the network. I'm going to copy it in here for your benefit, but also link to <a href="https://github.com/karpathy/char-rnn#tips-and-tricks">where it originally came from</a>.</p>
<blockquote><h2 id="Tips-and-Tricks">Tips and Tricks<a class="anchor-link" href="#Tips-and-Tricks">&#182;</a></h2><h3 id="Monitoring-Validation-Loss-vs.-Training-Loss">Monitoring Validation Loss vs. Training Loss<a class="anchor-link" href="#Monitoring-Validation-Loss-vs.-Training-Loss">&#182;</a></h3><p>If you're somewhat new to Machine Learning or Neural Networks it can take a bit of expertise to get good models. The most important quantity to keep track of is the difference between your training loss (printed during training) and the validation loss (printed once in a while when the RNN is run on the validation data (by default every 1000 iterations)). In particular:</p>
<ul>
<li>If your training loss is much lower than validation loss then this means the network might be <strong>overfitting</strong>. Solutions to this are to decrease your network size, or to increase dropout. For example you could try dropout of 0.5 and so on.</li>
<li>If your training/validation loss are about equal then your model is <strong>underfitting</strong>. Increase the size of your model (either number of layers or the raw number of neurons per layer)</li>
</ul>
<h3 id="Approximate-number-of-parameters">Approximate number of parameters<a class="anchor-link" href="#Approximate-number-of-parameters">&#182;</a></h3><p>The two most important parameters that control the model are <code>lstm_size</code> and <code>num_layers</code>. I would advise that you always use <code>num_layers</code> of either 2/3. The <code>lstm_size</code> can be adjusted based on how much data you have. The two important quantities to keep track of here are:</p>
<ul>
<li>The number of parameters in your model. This is printed when you start training.</li>
<li>The size of your dataset. 1MB file is approximately 1 million characters.</li>
</ul>
<p>These two should be about the same order of magnitude. It's a little tricky to tell. Here are some examples:</p>
<ul>
<li>I have a 100MB dataset and I'm using the default parameter settings (which currently print 150K parameters). My data size is significantly larger (100 mil &gt;&gt; 0.15 mil), so I expect to heavily underfit. I am thinking I can comfortably afford to make <code>lstm_size</code> larger.</li>
<li>I have a 10MB dataset and running a 10 million parameter model. I'm slightly nervous and I'm carefully monitoring my validation loss. If it's larger than my training loss then I may want to try to increase dropout a bit and see if that helps the validation loss.</li>
</ul>
<h3 id="Best-models-strategy">Best models strategy<a class="anchor-link" href="#Best-models-strategy">&#182;</a></h3><p>The winning strategy to obtaining very good models (if you have the compute time) is to always err on making the network larger (as large as you're willing to wait for it to compute) and then try different dropout values (between 0,1). Whatever model has the best validation performance (the loss, written in the checkpoint filename, low is good) is the one you should use in the end.</p>
<p>It is very common in deep learning to run many different models with many different hyperparameter settings, and in the end take whatever checkpoint gave the best validation performance.</p>
<p>By the way, the size of your training and validation splits are also parameters. Make sure you have a decent amount of data in your validation set or otherwise the validation performance will be noisy and not very informative.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>         <span class="c1"># Sequences per batch</span>
<span class="n">num_steps</span> <span class="o">=</span> <span class="mi">100</span>          <span class="c1"># Number of sequence steps per batch</span>
<span class="n">lstm_size</span> <span class="o">=</span> <span class="mi">512</span>         <span class="c1"># Size of hidden layers in LSTMs</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>          <span class="c1"># Number of LSTM layers</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>    <span class="c1"># Learning rate</span>
<span class="n">keep_prob</span> <span class="o">=</span> <span class="mf">0.5</span>         <span class="c1"># Dropout keep probability</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Time-for-training">Time for training<a class="anchor-link" href="#Time-for-training">&#182;</a></h2><p>This is typical training code, passing inputs and targets into the network, then running the optimizer. Here we also get back the final LSTM state for the mini-batch. Then, we pass that state back into the network so the next batch can continue the state from the previous batch. And every so often (set by <code>save_every_n</code>) I save a checkpoint.</p>
<p>Here I'm saving checkpoints with the format</p>
<p><code>i{iteration number}_l{# hidden layer units}.ckpt</code></p>
<blockquote><p><strong>Exercise:</strong> Set the hyperparameters above to train the network. Watch the training loss, it should be consistently dropping. Also, I highly advise running this on a GPU.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1"># Save every N iterations</span>
<span class="n">save_every_n</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">CharRNN</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="n">num_steps</span><span class="p">,</span>
                <span class="n">lstm_size</span><span class="o">=</span><span class="n">lstm_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> 
                <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">(</span><span class="n">max_to_keep</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    
    <span class="c1"># Use the line below to load a checkpoint and resume training</span>
    <span class="c1">#saver.restore(sess, &#39;checkpoints/______.ckpt&#39;)</span>
    <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># Train network</span>
        <span class="n">new_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">initial_state</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">get_batches</span><span class="p">(</span><span class="n">encoded</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">):</span>
            <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">feed</span> <span class="o">=</span> <span class="p">{</span><span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">targets</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_prob</span><span class="p">,</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">initial_state</span><span class="p">:</span> <span class="n">new_state</span><span class="p">}</span>
            <span class="n">batch_loss</span><span class="p">,</span> <span class="n">new_state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> 
                                                 <span class="n">model</span><span class="o">.</span><span class="n">final_state</span><span class="p">,</span> 
                                                 <span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="p">],</span> 
                                                 <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>
            
            <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch: </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">... &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">),</span>
                  <span class="s1">&#39;Training Step: </span><span class="si">{}</span><span class="s1">... &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">counter</span><span class="p">),</span>
                  <span class="s1">&#39;Training loss: </span><span class="si">{:.4f}</span><span class="s1">... &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">batch_loss</span><span class="p">),</span>
                  <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1"> sec/batch&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="p">)))</span>
        
            <span class="k">if</span> <span class="p">(</span><span class="n">counter</span> <span class="o">%</span> <span class="n">save_every_n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s2">&quot;checkpoints/i</span><span class="si">{}</span><span class="s2">_l</span><span class="si">{}</span><span class="s2">.ckpt&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">))</span>
    
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s2">&quot;checkpoints/i</span><span class="si">{}</span><span class="s2">_l</span><span class="si">{}</span><span class="s2">.ckpt&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>(1980000,)
(100, 19800)
Epoch: 1/20...  Training Step: 1...  Training loss: 4.4201...  15.6115 sec/batch
Epoch: 1/20...  Training Step: 2...  Training loss: 4.3358...  0.3634 sec/batch
Epoch: 1/20...  Training Step: 3...  Training loss: 3.8914...  0.3152 sec/batch
Epoch: 1/20...  Training Step: 4...  Training loss: 5.1393...  0.3065 sec/batch
Epoch: 1/20...  Training Step: 5...  Training loss: 4.2827...  0.3062 sec/batch
Epoch: 1/20...  Training Step: 6...  Training loss: 3.9019...  0.3072 sec/batch
Epoch: 1/20...  Training Step: 7...  Training loss: 3.7348...  0.3061 sec/batch
Epoch: 1/20...  Training Step: 8...  Training loss: 3.5976...  0.3060 sec/batch
Epoch: 1/20...  Training Step: 9...  Training loss: 3.4738...  0.3059 sec/batch
Epoch: 1/20...  Training Step: 10...  Training loss: 3.4407...  0.3063 sec/batch
Epoch: 1/20...  Training Step: 11...  Training loss: 3.4045...  0.3057 sec/batch
Epoch: 1/20...  Training Step: 12...  Training loss: 3.3857...  0.3061 sec/batch
Epoch: 1/20...  Training Step: 13...  Training loss: 3.3653...  0.3059 sec/batch
Epoch: 1/20...  Training Step: 14...  Training loss: 3.3583...  0.3062 sec/batch
Epoch: 1/20...  Training Step: 15...  Training loss: 3.3349...  0.3071 sec/batch
Epoch: 1/20...  Training Step: 16...  Training loss: 3.3012...  0.3077 sec/batch
Epoch: 1/20...  Training Step: 17...  Training loss: 3.2884...  0.3066 sec/batch
Epoch: 1/20...  Training Step: 18...  Training loss: 3.3154...  0.3054 sec/batch
Epoch: 1/20...  Training Step: 19...  Training loss: 3.2852...  0.3084 sec/batch
Epoch: 1/20...  Training Step: 20...  Training loss: 3.2341...  0.3075 sec/batch
Epoch: 1/20...  Training Step: 21...  Training loss: 3.2599...  0.3071 sec/batch
Epoch: 1/20...  Training Step: 22...  Training loss: 3.2581...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 23...  Training loss: 3.2459...  0.3068 sec/batch
Epoch: 1/20...  Training Step: 24...  Training loss: 3.2386...  0.3063 sec/batch
Epoch: 1/20...  Training Step: 25...  Training loss: 3.2251...  0.3062 sec/batch
Epoch: 1/20...  Training Step: 26...  Training loss: 3.2321...  0.3060 sec/batch
Epoch: 1/20...  Training Step: 27...  Training loss: 3.2364...  0.3058 sec/batch
Epoch: 1/20...  Training Step: 28...  Training loss: 3.2044...  0.3058 sec/batch
Epoch: 1/20...  Training Step: 29...  Training loss: 3.2081...  0.3063 sec/batch
Epoch: 1/20...  Training Step: 30...  Training loss: 3.2142...  0.3067 sec/batch
Epoch: 1/20...  Training Step: 31...  Training loss: 3.2284...  0.3062 sec/batch
Epoch: 1/20...  Training Step: 32...  Training loss: 3.2028...  0.3062 sec/batch
Epoch: 1/20...  Training Step: 33...  Training loss: 3.1896...  0.3079 sec/batch
Epoch: 1/20...  Training Step: 34...  Training loss: 3.2009...  0.3070 sec/batch
Epoch: 1/20...  Training Step: 35...  Training loss: 3.1858...  0.3068 sec/batch
Epoch: 1/20...  Training Step: 36...  Training loss: 3.2035...  0.3070 sec/batch
Epoch: 1/20...  Training Step: 37...  Training loss: 3.1686...  0.3064 sec/batch
Epoch: 1/20...  Training Step: 38...  Training loss: 3.1780...  0.3065 sec/batch
Epoch: 1/20...  Training Step: 39...  Training loss: 3.1714...  0.3073 sec/batch
Epoch: 1/20...  Training Step: 40...  Training loss: 3.1708...  0.3065 sec/batch
Epoch: 1/20...  Training Step: 41...  Training loss: 3.1614...  0.3063 sec/batch
Epoch: 1/20...  Training Step: 42...  Training loss: 3.1684...  0.3062 sec/batch
Epoch: 1/20...  Training Step: 43...  Training loss: 3.1594...  0.3060 sec/batch
Epoch: 1/20...  Training Step: 44...  Training loss: 3.1575...  0.3079 sec/batch
Epoch: 1/20...  Training Step: 45...  Training loss: 3.1563...  0.3059 sec/batch
Epoch: 1/20...  Training Step: 46...  Training loss: 3.1652...  0.3081 sec/batch
Epoch: 1/20...  Training Step: 47...  Training loss: 3.1684...  0.3071 sec/batch
Epoch: 1/20...  Training Step: 48...  Training loss: 3.1742...  0.3068 sec/batch
Epoch: 1/20...  Training Step: 49...  Training loss: 3.1718...  0.3067 sec/batch
Epoch: 1/20...  Training Step: 50...  Training loss: 3.1637...  0.3066 sec/batch
Epoch: 1/20...  Training Step: 51...  Training loss: 3.1595...  0.3072 sec/batch
Epoch: 1/20...  Training Step: 52...  Training loss: 3.1482...  0.3071 sec/batch
Epoch: 1/20...  Training Step: 53...  Training loss: 3.1532...  0.3062 sec/batch
Epoch: 1/20...  Training Step: 54...  Training loss: 3.1388...  0.3072 sec/batch
Epoch: 1/20...  Training Step: 55...  Training loss: 3.1558...  0.3070 sec/batch
Epoch: 1/20...  Training Step: 56...  Training loss: 3.1307...  0.3062 sec/batch
Epoch: 1/20...  Training Step: 57...  Training loss: 3.1470...  0.3065 sec/batch
Epoch: 1/20...  Training Step: 58...  Training loss: 3.1430...  0.3066 sec/batch
Epoch: 1/20...  Training Step: 59...  Training loss: 3.1308...  0.3075 sec/batch
Epoch: 1/20...  Training Step: 60...  Training loss: 3.1443...  0.3062 sec/batch
Epoch: 1/20...  Training Step: 61...  Training loss: 3.1420...  0.3070 sec/batch
Epoch: 1/20...  Training Step: 62...  Training loss: 3.1622...  0.3061 sec/batch
Epoch: 1/20...  Training Step: 63...  Training loss: 3.1675...  0.3068 sec/batch
Epoch: 1/20...  Training Step: 64...  Training loss: 3.1239...  0.3064 sec/batch
Epoch: 1/20...  Training Step: 65...  Training loss: 3.1294...  0.3067 sec/batch
Epoch: 1/20...  Training Step: 66...  Training loss: 3.1570...  0.3074 sec/batch
Epoch: 1/20...  Training Step: 67...  Training loss: 3.1414...  0.3065 sec/batch
Epoch: 1/20...  Training Step: 68...  Training loss: 3.1008...  0.3063 sec/batch
Epoch: 1/20...  Training Step: 69...  Training loss: 3.1170...  0.3058 sec/batch
Epoch: 1/20...  Training Step: 70...  Training loss: 3.1378...  0.3064 sec/batch
Epoch: 1/20...  Training Step: 71...  Training loss: 3.1305...  0.3068 sec/batch
Epoch: 1/20...  Training Step: 72...  Training loss: 3.1427...  0.3068 sec/batch
Epoch: 1/20...  Training Step: 73...  Training loss: 3.1230...  0.3073 sec/batch
Epoch: 1/20...  Training Step: 74...  Training loss: 3.1285...  0.3059 sec/batch
Epoch: 1/20...  Training Step: 75...  Training loss: 3.1338...  0.3062 sec/batch
Epoch: 1/20...  Training Step: 76...  Training loss: 3.1376...  0.3066 sec/batch
Epoch: 1/20...  Training Step: 77...  Training loss: 3.1363...  0.3072 sec/batch
Epoch: 1/20...  Training Step: 78...  Training loss: 3.1243...  0.3064 sec/batch
Epoch: 1/20...  Training Step: 79...  Training loss: 3.1157...  0.3073 sec/batch
Epoch: 1/20...  Training Step: 80...  Training loss: 3.1072...  0.3065 sec/batch
Epoch: 1/20...  Training Step: 81...  Training loss: 3.1050...  0.3063 sec/batch
Epoch: 1/20...  Training Step: 82...  Training loss: 3.1225...  0.3071 sec/batch
Epoch: 1/20...  Training Step: 83...  Training loss: 3.1806...  0.3066 sec/batch
Epoch: 1/20...  Training Step: 84...  Training loss: 3.3340...  0.3067 sec/batch
Epoch: 1/20...  Training Step: 85...  Training loss: 3.3388...  0.3062 sec/batch
Epoch: 1/20...  Training Step: 86...  Training loss: 3.3467...  0.3064 sec/batch
Epoch: 1/20...  Training Step: 87...  Training loss: 3.3183...  0.3066 sec/batch
Epoch: 1/20...  Training Step: 88...  Training loss: 3.3118...  0.3071 sec/batch
Epoch: 1/20...  Training Step: 89...  Training loss: 3.3054...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 90...  Training loss: 3.2887...  0.3072 sec/batch
Epoch: 1/20...  Training Step: 91...  Training loss: 3.2752...  0.3071 sec/batch
Epoch: 1/20...  Training Step: 92...  Training loss: 3.2257...  0.3077 sec/batch
Epoch: 1/20...  Training Step: 93...  Training loss: 3.2325...  0.3066 sec/batch
Epoch: 1/20...  Training Step: 94...  Training loss: 3.2162...  0.3072 sec/batch
Epoch: 1/20...  Training Step: 95...  Training loss: 3.1831...  0.3073 sec/batch
Epoch: 1/20...  Training Step: 96...  Training loss: 3.1749...  0.3066 sec/batch
Epoch: 1/20...  Training Step: 97...  Training loss: 3.1619...  0.3067 sec/batch
Epoch: 1/20...  Training Step: 98...  Training loss: 3.1442...  0.3065 sec/batch
Epoch: 1/20...  Training Step: 99...  Training loss: 3.1460...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 100...  Training loss: 3.1334...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 101...  Training loss: 3.1406...  0.3070 sec/batch
Epoch: 1/20...  Training Step: 102...  Training loss: 3.1381...  0.3066 sec/batch
Epoch: 1/20...  Training Step: 103...  Training loss: 3.1411...  0.3071 sec/batch
Epoch: 1/20...  Training Step: 104...  Training loss: 3.1281...  0.3099 sec/batch
Epoch: 1/20...  Training Step: 105...  Training loss: 3.1302...  0.3066 sec/batch
Epoch: 1/20...  Training Step: 106...  Training loss: 3.1330...  0.3063 sec/batch
Epoch: 1/20...  Training Step: 107...  Training loss: 3.1033...  0.3065 sec/batch
Epoch: 1/20...  Training Step: 108...  Training loss: 3.1101...  0.3066 sec/batch
Epoch: 1/20...  Training Step: 109...  Training loss: 3.1227...  0.3066 sec/batch
Epoch: 1/20...  Training Step: 110...  Training loss: 3.0870...  0.3063 sec/batch
Epoch: 1/20...  Training Step: 111...  Training loss: 3.0983...  0.3078 sec/batch
Epoch: 1/20...  Training Step: 112...  Training loss: 3.1025...  0.3072 sec/batch
Epoch: 1/20...  Training Step: 113...  Training loss: 3.0921...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 114...  Training loss: 3.0879...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 115...  Training loss: 3.0791...  0.3067 sec/batch
Epoch: 1/20...  Training Step: 116...  Training loss: 3.0806...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 117...  Training loss: 3.0874...  0.3111 sec/batch
Epoch: 1/20...  Training Step: 118...  Training loss: 3.0953...  0.3074 sec/batch
Epoch: 1/20...  Training Step: 119...  Training loss: 3.0936...  0.3076 sec/batch
Epoch: 1/20...  Training Step: 120...  Training loss: 3.0670...  0.3079 sec/batch
Epoch: 1/20...  Training Step: 121...  Training loss: 3.1071...  0.3072 sec/batch
Epoch: 1/20...  Training Step: 122...  Training loss: 3.0890...  0.3079 sec/batch
Epoch: 1/20...  Training Step: 123...  Training loss: 3.0845...  0.3073 sec/batch
Epoch: 1/20...  Training Step: 124...  Training loss: 3.0844...  0.3059 sec/batch
Epoch: 1/20...  Training Step: 125...  Training loss: 3.0589...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 126...  Training loss: 3.0461...  0.3061 sec/batch
Epoch: 1/20...  Training Step: 127...  Training loss: 3.0663...  0.3064 sec/batch
Epoch: 1/20...  Training Step: 128...  Training loss: 3.0659...  0.3064 sec/batch
Epoch: 1/20...  Training Step: 129...  Training loss: 3.0369...  0.3071 sec/batch
Epoch: 1/20...  Training Step: 130...  Training loss: 3.0439...  0.3085 sec/batch
Epoch: 1/20...  Training Step: 131...  Training loss: 3.0488...  0.3083 sec/batch
Epoch: 1/20...  Training Step: 132...  Training loss: 3.0549...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 133...  Training loss: 3.0885...  0.3058 sec/batch
Epoch: 1/20...  Training Step: 134...  Training loss: 3.0580...  0.3059 sec/batch
Epoch: 1/20...  Training Step: 135...  Training loss: 3.0098...  0.3064 sec/batch
Epoch: 1/20...  Training Step: 136...  Training loss: 3.0150...  0.3067 sec/batch
Epoch: 1/20...  Training Step: 137...  Training loss: 3.0432...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 138...  Training loss: 3.0257...  0.3065 sec/batch
Epoch: 1/20...  Training Step: 139...  Training loss: 3.0411...  0.3070 sec/batch
Epoch: 1/20...  Training Step: 140...  Training loss: 3.0304...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 141...  Training loss: 3.0373...  0.3060 sec/batch
Epoch: 1/20...  Training Step: 142...  Training loss: 3.0031...  0.3075 sec/batch
Epoch: 1/20...  Training Step: 143...  Training loss: 3.0086...  0.3093 sec/batch
Epoch: 1/20...  Training Step: 144...  Training loss: 3.0127...  0.3075 sec/batch
Epoch: 1/20...  Training Step: 145...  Training loss: 3.0127...  0.3064 sec/batch
Epoch: 1/20...  Training Step: 146...  Training loss: 3.0095...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 147...  Training loss: 3.0118...  0.3068 sec/batch
Epoch: 1/20...  Training Step: 148...  Training loss: 3.0136...  0.3066 sec/batch
Epoch: 1/20...  Training Step: 149...  Training loss: 2.9715...  0.3067 sec/batch
Epoch: 1/20...  Training Step: 150...  Training loss: 2.9749...  0.3064 sec/batch
Epoch: 1/20...  Training Step: 151...  Training loss: 2.9961...  0.3067 sec/batch
Epoch: 1/20...  Training Step: 152...  Training loss: 2.9942...  0.3062 sec/batch
Epoch: 1/20...  Training Step: 153...  Training loss: 2.9563...  0.3068 sec/batch
Epoch: 1/20...  Training Step: 154...  Training loss: 2.9532...  0.3066 sec/batch
Epoch: 1/20...  Training Step: 155...  Training loss: 2.9249...  0.3075 sec/batch
Epoch: 1/20...  Training Step: 156...  Training loss: 2.9307...  0.3104 sec/batch
Epoch: 1/20...  Training Step: 157...  Training loss: 2.9047...  0.3073 sec/batch
Epoch: 1/20...  Training Step: 158...  Training loss: 2.9105...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 159...  Training loss: 2.8774...  0.3075 sec/batch
Epoch: 1/20...  Training Step: 160...  Training loss: 2.8922...  0.3083 sec/batch
Epoch: 1/20...  Training Step: 161...  Training loss: 2.8872...  0.3073 sec/batch
Epoch: 1/20...  Training Step: 162...  Training loss: 2.8504...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 163...  Training loss: 2.8421...  0.3067 sec/batch
Epoch: 1/20...  Training Step: 164...  Training loss: 2.8623...  0.3078 sec/batch
Epoch: 1/20...  Training Step: 165...  Training loss: 2.8622...  0.3072 sec/batch
Epoch: 1/20...  Training Step: 166...  Training loss: 2.8377...  0.3083 sec/batch
Epoch: 1/20...  Training Step: 167...  Training loss: 2.8429...  0.3076 sec/batch
Epoch: 1/20...  Training Step: 168...  Training loss: 2.8268...  0.3066 sec/batch
Epoch: 1/20...  Training Step: 169...  Training loss: 2.8230...  0.3076 sec/batch
Epoch: 1/20...  Training Step: 170...  Training loss: 2.8004...  0.3074 sec/batch
Epoch: 1/20...  Training Step: 171...  Training loss: 2.8218...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 172...  Training loss: 2.8302...  0.3081 sec/batch
Epoch: 1/20...  Training Step: 173...  Training loss: 2.8344...  0.3067 sec/batch
Epoch: 1/20...  Training Step: 174...  Training loss: 2.8165...  0.3077 sec/batch
Epoch: 1/20...  Training Step: 175...  Training loss: 2.7956...  0.3061 sec/batch
Epoch: 1/20...  Training Step: 176...  Training loss: 2.7670...  0.3065 sec/batch
Epoch: 1/20...  Training Step: 177...  Training loss: 2.7752...  0.3080 sec/batch
Epoch: 1/20...  Training Step: 178...  Training loss: 2.7365...  0.3068 sec/batch
Epoch: 1/20...  Training Step: 179...  Training loss: 2.7321...  0.3073 sec/batch
Epoch: 1/20...  Training Step: 180...  Training loss: 2.7055...  0.3071 sec/batch
Epoch: 1/20...  Training Step: 181...  Training loss: 2.7282...  0.3070 sec/batch
Epoch: 1/20...  Training Step: 182...  Training loss: 2.7142...  0.3070 sec/batch
Epoch: 1/20...  Training Step: 183...  Training loss: 2.6991...  0.3075 sec/batch
Epoch: 1/20...  Training Step: 184...  Training loss: 2.7001...  0.3069 sec/batch
Epoch: 1/20...  Training Step: 185...  Training loss: 2.7330...  0.3063 sec/batch
Epoch: 1/20...  Training Step: 186...  Training loss: 2.6703...  0.3072 sec/batch
Epoch: 1/20...  Training Step: 187...  Training loss: 2.6582...  0.3071 sec/batch
Epoch: 1/20...  Training Step: 188...  Training loss: 2.6441...  0.3077 sec/batch
Epoch: 1/20...  Training Step: 189...  Training loss: 2.6557...  0.3080 sec/batch
Epoch: 1/20...  Training Step: 190...  Training loss: 2.6412...  0.3073 sec/batch
Epoch: 1/20...  Training Step: 191...  Training loss: 2.6331...  0.3076 sec/batch
Epoch: 1/20...  Training Step: 192...  Training loss: 2.6050...  0.3076 sec/batch
Epoch: 1/20...  Training Step: 193...  Training loss: 2.6285...  0.3086 sec/batch
Epoch: 1/20...  Training Step: 194...  Training loss: 2.6152...  0.3081 sec/batch
Epoch: 1/20...  Training Step: 195...  Training loss: 2.5947...  0.3073 sec/batch
Epoch: 1/20...  Training Step: 196...  Training loss: 2.5976...  0.3078 sec/batch
Epoch: 1/20...  Training Step: 197...  Training loss: 2.5850...  0.3062 sec/batch
Epoch: 1/20...  Training Step: 198...  Training loss: 2.5790...  0.3076 sec/batch
(1980000,)
(100, 19800)
Epoch: 2/20...  Training Step: 199...  Training loss: 2.6785...  0.3071 sec/batch
Epoch: 2/20...  Training Step: 200...  Training loss: 2.5542...  0.3078 sec/batch
Epoch: 2/20...  Training Step: 201...  Training loss: 2.5660...  0.3070 sec/batch
Epoch: 2/20...  Training Step: 202...  Training loss: 2.5833...  0.3070 sec/batch
Epoch: 2/20...  Training Step: 203...  Training loss: 2.5675...  0.3062 sec/batch
Epoch: 2/20...  Training Step: 204...  Training loss: 2.5715...  0.3080 sec/batch
Epoch: 2/20...  Training Step: 205...  Training loss: 2.5696...  0.3085 sec/batch
Epoch: 2/20...  Training Step: 206...  Training loss: 2.5699...  0.3069 sec/batch
Epoch: 2/20...  Training Step: 207...  Training loss: 2.5820...  0.3065 sec/batch
Epoch: 2/20...  Training Step: 208...  Training loss: 2.5400...  0.3074 sec/batch
Epoch: 2/20...  Training Step: 209...  Training loss: 2.5447...  0.3068 sec/batch
Epoch: 2/20...  Training Step: 210...  Training loss: 2.5521...  0.3071 sec/batch
Epoch: 2/20...  Training Step: 211...  Training loss: 2.5417...  0.3077 sec/batch
Epoch: 2/20...  Training Step: 212...  Training loss: 2.5701...  0.3081 sec/batch
Epoch: 2/20...  Training Step: 213...  Training loss: 2.5449...  0.3079 sec/batch
Epoch: 2/20...  Training Step: 214...  Training loss: 2.5432...  0.3087 sec/batch
Epoch: 2/20...  Training Step: 215...  Training loss: 2.5332...  0.3066 sec/batch
Epoch: 2/20...  Training Step: 216...  Training loss: 2.5725...  0.3073 sec/batch
Epoch: 2/20...  Training Step: 217...  Training loss: 2.5303...  0.3072 sec/batch
Epoch: 2/20...  Training Step: 218...  Training loss: 2.4998...  0.3064 sec/batch
Epoch: 2/20...  Training Step: 219...  Training loss: 2.5064...  0.3070 sec/batch
Epoch: 2/20...  Training Step: 220...  Training loss: 2.5411...  0.3077 sec/batch
Epoch: 2/20...  Training Step: 221...  Training loss: 2.5167...  0.3072 sec/batch
Epoch: 2/20...  Training Step: 222...  Training loss: 2.5032...  0.3069 sec/batch
Epoch: 2/20...  Training Step: 223...  Training loss: 2.4840...  0.3078 sec/batch
Epoch: 2/20...  Training Step: 224...  Training loss: 2.5124...  0.3077 sec/batch
Epoch: 2/20...  Training Step: 225...  Training loss: 2.4943...  0.3066 sec/batch
Epoch: 2/20...  Training Step: 226...  Training loss: 2.4956...  0.3077 sec/batch
Epoch: 2/20...  Training Step: 227...  Training loss: 2.5068...  0.3072 sec/batch
Epoch: 2/20...  Training Step: 228...  Training loss: 2.4914...  0.3077 sec/batch
Epoch: 2/20...  Training Step: 229...  Training loss: 2.5000...  0.3075 sec/batch
Epoch: 2/20...  Training Step: 230...  Training loss: 2.4749...  0.3067 sec/batch
Epoch: 2/20...  Training Step: 231...  Training loss: 2.4629...  0.3070 sec/batch
Epoch: 2/20...  Training Step: 232...  Training loss: 2.4934...  0.3070 sec/batch
Epoch: 2/20...  Training Step: 233...  Training loss: 2.4611...  0.3067 sec/batch
Epoch: 2/20...  Training Step: 234...  Training loss: 2.4781...  0.3080 sec/batch
Epoch: 2/20...  Training Step: 235...  Training loss: 2.4572...  0.3067 sec/batch
Epoch: 2/20...  Training Step: 236...  Training loss: 2.4322...  0.3073 sec/batch
Epoch: 2/20...  Training Step: 237...  Training loss: 2.4461...  0.3069 sec/batch
Epoch: 2/20...  Training Step: 238...  Training loss: 2.4606...  0.3068 sec/batch
Epoch: 2/20...  Training Step: 239...  Training loss: 2.4536...  0.3077 sec/batch
Epoch: 2/20...  Training Step: 240...  Training loss: 2.4444...  0.3070 sec/batch
Epoch: 2/20...  Training Step: 241...  Training loss: 2.4375...  0.3075 sec/batch
Epoch: 2/20...  Training Step: 242...  Training loss: 2.4343...  0.3076 sec/batch
Epoch: 2/20...  Training Step: 243...  Training loss: 2.4307...  0.3072 sec/batch
Epoch: 2/20...  Training Step: 244...  Training loss: 2.4082...  0.3062 sec/batch
Epoch: 2/20...  Training Step: 245...  Training loss: 2.4548...  0.3072 sec/batch
Epoch: 2/20...  Training Step: 246...  Training loss: 2.4285...  0.3062 sec/batch
Epoch: 2/20...  Training Step: 247...  Training loss: 2.4337...  0.3085 sec/batch
Epoch: 2/20...  Training Step: 248...  Training loss: 2.4527...  0.3080 sec/batch
Epoch: 2/20...  Training Step: 249...  Training loss: 2.4202...  0.3079 sec/batch
Epoch: 2/20...  Training Step: 250...  Training loss: 2.4329...  0.3067 sec/batch
Epoch: 2/20...  Training Step: 251...  Training loss: 2.4152...  0.3072 sec/batch
Epoch: 2/20...  Training Step: 252...  Training loss: 2.4054...  0.3069 sec/batch
Epoch: 2/20...  Training Step: 253...  Training loss: 2.4078...  0.3072 sec/batch
Epoch: 2/20...  Training Step: 254...  Training loss: 2.4206...  0.3072 sec/batch
Epoch: 2/20...  Training Step: 255...  Training loss: 2.4117...  0.3074 sec/batch
Epoch: 2/20...  Training Step: 256...  Training loss: 2.3957...  0.3070 sec/batch
Epoch: 2/20...  Training Step: 257...  Training loss: 2.3948...  0.3073 sec/batch
Epoch: 2/20...  Training Step: 258...  Training loss: 2.4234...  0.3079 sec/batch
Epoch: 2/20...  Training Step: 259...  Training loss: 2.3994...  0.3066 sec/batch
Epoch: 2/20...  Training Step: 260...  Training loss: 2.4148...  0.3066 sec/batch
Epoch: 2/20...  Training Step: 261...  Training loss: 2.4176...  0.3068 sec/batch
Epoch: 2/20...  Training Step: 262...  Training loss: 2.3895...  0.3080 sec/batch
Epoch: 2/20...  Training Step: 263...  Training loss: 2.3857...  0.3069 sec/batch
Epoch: 2/20...  Training Step: 264...  Training loss: 2.4076...  0.3078 sec/batch
Epoch: 2/20...  Training Step: 265...  Training loss: 2.3895...  0.3078 sec/batch
Epoch: 2/20...  Training Step: 266...  Training loss: 2.3511...  0.3071 sec/batch
Epoch: 2/20...  Training Step: 267...  Training loss: 2.3619...  0.3066 sec/batch
Epoch: 2/20...  Training Step: 268...  Training loss: 2.3847...  0.3069 sec/batch
Epoch: 2/20...  Training Step: 269...  Training loss: 2.3933...  0.3061 sec/batch
Epoch: 2/20...  Training Step: 270...  Training loss: 2.3822...  0.3070 sec/batch
Epoch: 2/20...  Training Step: 271...  Training loss: 2.3796...  0.3072 sec/batch
Epoch: 2/20...  Training Step: 272...  Training loss: 2.3656...  0.3065 sec/batch
Epoch: 2/20...  Training Step: 273...  Training loss: 2.3610...  0.3071 sec/batch
Epoch: 2/20...  Training Step: 274...  Training loss: 2.4130...  0.3065 sec/batch
Epoch: 2/20...  Training Step: 275...  Training loss: 2.3611...  0.3076 sec/batch
Epoch: 2/20...  Training Step: 276...  Training loss: 2.3756...  0.3071 sec/batch
Epoch: 2/20...  Training Step: 277...  Training loss: 2.3639...  0.3067 sec/batch
Epoch: 2/20...  Training Step: 278...  Training loss: 2.3597...  0.3081 sec/batch
Epoch: 2/20...  Training Step: 279...  Training loss: 2.3469...  0.3073 sec/batch
Epoch: 2/20...  Training Step: 280...  Training loss: 2.3797...  0.3061 sec/batch
Epoch: 2/20...  Training Step: 281...  Training loss: 2.3476...  0.3082 sec/batch
Epoch: 2/20...  Training Step: 282...  Training loss: 2.3373...  0.3067 sec/batch
Epoch: 2/20...  Training Step: 283...  Training loss: 2.3113...  0.3064 sec/batch
Epoch: 2/20...  Training Step: 284...  Training loss: 2.3347...  0.3073 sec/batch
Epoch: 2/20...  Training Step: 285...  Training loss: 2.3428...  0.3079 sec/batch
Epoch: 2/20...  Training Step: 286...  Training loss: 2.3409...  0.3074 sec/batch
Epoch: 2/20...  Training Step: 287...  Training loss: 2.3147...  0.3073 sec/batch
Epoch: 2/20...  Training Step: 288...  Training loss: 2.3465...  0.3068 sec/batch
Epoch: 2/20...  Training Step: 289...  Training loss: 2.3223...  0.3067 sec/batch
Epoch: 2/20...  Training Step: 290...  Training loss: 2.3401...  0.3073 sec/batch
Epoch: 2/20...  Training Step: 291...  Training loss: 2.3189...  0.3073 sec/batch
Epoch: 2/20...  Training Step: 292...  Training loss: 2.3137...  0.3086 sec/batch
Epoch: 2/20...  Training Step: 293...  Training loss: 2.3142...  0.3067 sec/batch
Epoch: 2/20...  Training Step: 294...  Training loss: 2.3036...  0.3078 sec/batch
Epoch: 2/20...  Training Step: 295...  Training loss: 2.3234...  0.3072 sec/batch
Epoch: 2/20...  Training Step: 296...  Training loss: 2.3211...  0.3076 sec/batch
Epoch: 2/20...  Training Step: 297...  Training loss: 2.3047...  0.3065 sec/batch
Epoch: 2/20...  Training Step: 298...  Training loss: 2.2959...  0.3079 sec/batch
Epoch: 2/20...  Training Step: 299...  Training loss: 2.3296...  0.3071 sec/batch
Epoch: 2/20...  Training Step: 300...  Training loss: 2.3158...  0.3063 sec/batch
Epoch: 2/20...  Training Step: 301...  Training loss: 2.2911...  0.3075 sec/batch
Epoch: 2/20...  Training Step: 302...  Training loss: 2.2902...  0.3074 sec/batch
Epoch: 2/20...  Training Step: 303...  Training loss: 2.3015...  0.3069 sec/batch
Epoch: 2/20...  Training Step: 304...  Training loss: 2.2935...  0.3063 sec/batch
Epoch: 2/20...  Training Step: 305...  Training loss: 2.2969...  0.3083 sec/batch
Epoch: 2/20...  Training Step: 306...  Training loss: 2.3237...  0.3071 sec/batch
Epoch: 2/20...  Training Step: 307...  Training loss: 2.3081...  0.3082 sec/batch
Epoch: 2/20...  Training Step: 308...  Training loss: 2.2811...  0.3070 sec/batch
Epoch: 2/20...  Training Step: 309...  Training loss: 2.2903...  0.3068 sec/batch
Epoch: 2/20...  Training Step: 310...  Training loss: 2.3124...  0.3074 sec/batch
Epoch: 2/20...  Training Step: 311...  Training loss: 2.2742...  0.3081 sec/batch
Epoch: 2/20...  Training Step: 312...  Training loss: 2.2755...  0.3073 sec/batch
Epoch: 2/20...  Training Step: 313...  Training loss: 2.2826...  0.3074 sec/batch
Epoch: 2/20...  Training Step: 314...  Training loss: 2.2473...  0.3071 sec/batch
Epoch: 2/20...  Training Step: 315...  Training loss: 2.2869...  0.3080 sec/batch
Epoch: 2/20...  Training Step: 316...  Training loss: 2.2783...  0.3079 sec/batch
Epoch: 2/20...  Training Step: 317...  Training loss: 2.2972...  0.3075 sec/batch
Epoch: 2/20...  Training Step: 318...  Training loss: 2.2825...  0.3075 sec/batch
Epoch: 2/20...  Training Step: 319...  Training loss: 2.2983...  0.3074 sec/batch
Epoch: 2/20...  Training Step: 320...  Training loss: 2.2601...  0.3083 sec/batch
Epoch: 2/20...  Training Step: 321...  Training loss: 2.2698...  0.3069 sec/batch
Epoch: 2/20...  Training Step: 322...  Training loss: 2.2917...  0.3074 sec/batch
Epoch: 2/20...  Training Step: 323...  Training loss: 2.2680...  0.3071 sec/batch
Epoch: 2/20...  Training Step: 324...  Training loss: 2.2418...  0.3084 sec/batch
Epoch: 2/20...  Training Step: 325...  Training loss: 2.2768...  0.3085 sec/batch
Epoch: 2/20...  Training Step: 326...  Training loss: 2.2846...  0.3076 sec/batch
Epoch: 2/20...  Training Step: 327...  Training loss: 2.2771...  0.3078 sec/batch
Epoch: 2/20...  Training Step: 328...  Training loss: 2.2642...  0.3067 sec/batch
Epoch: 2/20...  Training Step: 329...  Training loss: 2.2477...  0.3071 sec/batch
Epoch: 2/20...  Training Step: 330...  Training loss: 2.2278...  0.3082 sec/batch
Epoch: 2/20...  Training Step: 331...  Training loss: 2.2702...  0.3081 sec/batch
Epoch: 2/20...  Training Step: 332...  Training loss: 2.2732...  0.3079 sec/batch
Epoch: 2/20...  Training Step: 333...  Training loss: 2.2500...  0.3071 sec/batch
Epoch: 2/20...  Training Step: 334...  Training loss: 2.2650...  0.3071 sec/batch
Epoch: 2/20...  Training Step: 335...  Training loss: 2.2524...  0.3072 sec/batch
Epoch: 2/20...  Training Step: 336...  Training loss: 2.2504...  0.3069 sec/batch
Epoch: 2/20...  Training Step: 337...  Training loss: 2.2897...  0.3077 sec/batch
Epoch: 2/20...  Training Step: 338...  Training loss: 2.2434...  0.3077 sec/batch
Epoch: 2/20...  Training Step: 339...  Training loss: 2.2577...  0.3107 sec/batch
Epoch: 2/20...  Training Step: 340...  Training loss: 2.2317...  0.3071 sec/batch
Epoch: 2/20...  Training Step: 341...  Training loss: 2.2414...  0.3078 sec/batch
Epoch: 2/20...  Training Step: 342...  Training loss: 2.2346...  0.3068 sec/batch
Epoch: 2/20...  Training Step: 343...  Training loss: 2.2364...  0.3080 sec/batch
Epoch: 2/20...  Training Step: 344...  Training loss: 2.2701...  0.3077 sec/batch
Epoch: 2/20...  Training Step: 345...  Training loss: 2.2440...  0.3079 sec/batch
Epoch: 2/20...  Training Step: 346...  Training loss: 2.2583...  0.3081 sec/batch
Epoch: 2/20...  Training Step: 347...  Training loss: 2.2281...  0.3080 sec/batch
Epoch: 2/20...  Training Step: 348...  Training loss: 2.2137...  0.3079 sec/batch
Epoch: 2/20...  Training Step: 349...  Training loss: 2.2411...  0.3069 sec/batch
Epoch: 2/20...  Training Step: 350...  Training loss: 2.2634...  0.3071 sec/batch
Epoch: 2/20...  Training Step: 351...  Training loss: 2.2455...  0.3076 sec/batch
Epoch: 2/20...  Training Step: 352...  Training loss: 2.2366...  0.3072 sec/batch
Epoch: 2/20...  Training Step: 353...  Training loss: 2.2178...  0.3077 sec/batch
Epoch: 2/20...  Training Step: 354...  Training loss: 2.2234...  0.3082 sec/batch
Epoch: 2/20...  Training Step: 355...  Training loss: 2.2115...  0.3094 sec/batch
Epoch: 2/20...  Training Step: 356...  Training loss: 2.2127...  0.3078 sec/batch
Epoch: 2/20...  Training Step: 357...  Training loss: 2.1846...  0.3080 sec/batch
Epoch: 2/20...  Training Step: 358...  Training loss: 2.2566...  0.3072 sec/batch
Epoch: 2/20...  Training Step: 359...  Training loss: 2.2248...  0.3075 sec/batch
Epoch: 2/20...  Training Step: 360...  Training loss: 2.2034...  0.3086 sec/batch
Epoch: 2/20...  Training Step: 361...  Training loss: 2.2076...  0.3077 sec/batch
Epoch: 2/20...  Training Step: 362...  Training loss: 2.2187...  0.3076 sec/batch
Epoch: 2/20...  Training Step: 363...  Training loss: 2.2112...  0.3068 sec/batch
Epoch: 2/20...  Training Step: 364...  Training loss: 2.2085...  0.3074 sec/batch
Epoch: 2/20...  Training Step: 365...  Training loss: 2.2004...  0.3076 sec/batch
Epoch: 2/20...  Training Step: 366...  Training loss: 2.2176...  0.3070 sec/batch
Epoch: 2/20...  Training Step: 367...  Training loss: 2.2027...  0.3071 sec/batch
Epoch: 2/20...  Training Step: 368...  Training loss: 2.1800...  0.3066 sec/batch
Epoch: 2/20...  Training Step: 369...  Training loss: 2.1830...  0.3069 sec/batch
Epoch: 2/20...  Training Step: 370...  Training loss: 2.2031...  0.3074 sec/batch
Epoch: 2/20...  Training Step: 371...  Training loss: 2.2197...  0.3073 sec/batch
Epoch: 2/20...  Training Step: 372...  Training loss: 2.2050...  0.3078 sec/batch
Epoch: 2/20...  Training Step: 373...  Training loss: 2.2122...  0.3074 sec/batch
Epoch: 2/20...  Training Step: 374...  Training loss: 2.1966...  0.3076 sec/batch
Epoch: 2/20...  Training Step: 375...  Training loss: 2.1986...  0.3073 sec/batch
Epoch: 2/20...  Training Step: 376...  Training loss: 2.1934...  0.3079 sec/batch
Epoch: 2/20...  Training Step: 377...  Training loss: 2.1630...  0.3077 sec/batch
Epoch: 2/20...  Training Step: 378...  Training loss: 2.1533...  0.3074 sec/batch
Epoch: 2/20...  Training Step: 379...  Training loss: 2.1672...  0.3077 sec/batch
Epoch: 2/20...  Training Step: 380...  Training loss: 2.1859...  0.3079 sec/batch
Epoch: 2/20...  Training Step: 381...  Training loss: 2.1826...  0.3082 sec/batch
Epoch: 2/20...  Training Step: 382...  Training loss: 2.2088...  0.3079 sec/batch
Epoch: 2/20...  Training Step: 383...  Training loss: 2.1886...  0.3078 sec/batch
Epoch: 2/20...  Training Step: 384...  Training loss: 2.1729...  0.3082 sec/batch
Epoch: 2/20...  Training Step: 385...  Training loss: 2.1748...  0.3089 sec/batch
Epoch: 2/20...  Training Step: 386...  Training loss: 2.1546...  0.3087 sec/batch
Epoch: 2/20...  Training Step: 387...  Training loss: 2.1661...  0.3086 sec/batch
Epoch: 2/20...  Training Step: 388...  Training loss: 2.1606...  0.3076 sec/batch
Epoch: 2/20...  Training Step: 389...  Training loss: 2.1846...  0.3082 sec/batch
Epoch: 2/20...  Training Step: 390...  Training loss: 2.1456...  0.3090 sec/batch
Epoch: 2/20...  Training Step: 391...  Training loss: 2.1741...  0.3080 sec/batch
Epoch: 2/20...  Training Step: 392...  Training loss: 2.1526...  0.3082 sec/batch
Epoch: 2/20...  Training Step: 393...  Training loss: 2.1437...  0.3078 sec/batch
Epoch: 2/20...  Training Step: 394...  Training loss: 2.1595...  0.3080 sec/batch
Epoch: 2/20...  Training Step: 395...  Training loss: 2.1534...  0.3081 sec/batch
Epoch: 2/20...  Training Step: 396...  Training loss: 2.1441...  0.3089 sec/batch
(1980000,)
(100, 19800)
Epoch: 3/20...  Training Step: 397...  Training loss: 2.2506...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 398...  Training loss: 2.1204...  0.3073 sec/batch
Epoch: 3/20...  Training Step: 399...  Training loss: 2.1287...  0.3088 sec/batch
Epoch: 3/20...  Training Step: 400...  Training loss: 2.1277...  0.3081 sec/batch
Epoch: 3/20...  Training Step: 401...  Training loss: 2.1493...  0.3091 sec/batch
Epoch: 3/20...  Training Step: 402...  Training loss: 2.1249...  0.3073 sec/batch
Epoch: 3/20...  Training Step: 403...  Training loss: 2.1467...  0.3085 sec/batch
Epoch: 3/20...  Training Step: 404...  Training loss: 2.1381...  0.3083 sec/batch
Epoch: 3/20...  Training Step: 405...  Training loss: 2.1718...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 406...  Training loss: 2.1270...  0.3078 sec/batch
Epoch: 3/20...  Training Step: 407...  Training loss: 2.1272...  0.3094 sec/batch
Epoch: 3/20...  Training Step: 408...  Training loss: 2.1125...  0.3081 sec/batch
Epoch: 3/20...  Training Step: 409...  Training loss: 2.1362...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 410...  Training loss: 2.1710...  0.3077 sec/batch
Epoch: 3/20...  Training Step: 411...  Training loss: 2.1307...  0.3088 sec/batch
Epoch: 3/20...  Training Step: 412...  Training loss: 2.1159...  0.3087 sec/batch
Epoch: 3/20...  Training Step: 413...  Training loss: 2.1304...  0.3086 sec/batch
Epoch: 3/20...  Training Step: 414...  Training loss: 2.1635...  0.3092 sec/batch
Epoch: 3/20...  Training Step: 415...  Training loss: 2.1319...  0.3083 sec/batch
Epoch: 3/20...  Training Step: 416...  Training loss: 2.1280...  0.3071 sec/batch
Epoch: 3/20...  Training Step: 417...  Training loss: 2.1153...  0.3079 sec/batch
Epoch: 3/20...  Training Step: 418...  Training loss: 2.1758...  0.3082 sec/batch
Epoch: 3/20...  Training Step: 419...  Training loss: 2.1315...  0.3074 sec/batch
Epoch: 3/20...  Training Step: 420...  Training loss: 2.1205...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 421...  Training loss: 2.1226...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 422...  Training loss: 2.1058...  0.3085 sec/batch
Epoch: 3/20...  Training Step: 423...  Training loss: 2.0986...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 424...  Training loss: 2.1209...  0.3092 sec/batch
Epoch: 3/20...  Training Step: 425...  Training loss: 2.1454...  0.3074 sec/batch
Epoch: 3/20...  Training Step: 426...  Training loss: 2.1206...  0.3077 sec/batch
Epoch: 3/20...  Training Step: 427...  Training loss: 2.1177...  0.3081 sec/batch
Epoch: 3/20...  Training Step: 428...  Training loss: 2.0935...  0.3072 sec/batch
Epoch: 3/20...  Training Step: 429...  Training loss: 2.1068...  0.3086 sec/batch
Epoch: 3/20...  Training Step: 430...  Training loss: 2.1329...  0.3077 sec/batch
Epoch: 3/20...  Training Step: 431...  Training loss: 2.0982...  0.3082 sec/batch
Epoch: 3/20...  Training Step: 432...  Training loss: 2.1102...  0.3083 sec/batch
Epoch: 3/20...  Training Step: 433...  Training loss: 2.1028...  0.3087 sec/batch
Epoch: 3/20...  Training Step: 434...  Training loss: 2.0642...  0.3110 sec/batch
Epoch: 3/20...  Training Step: 435...  Training loss: 2.0670...  0.3073 sec/batch
Epoch: 3/20...  Training Step: 436...  Training loss: 2.0644...  0.3088 sec/batch
Epoch: 3/20...  Training Step: 437...  Training loss: 2.0775...  0.3079 sec/batch
Epoch: 3/20...  Training Step: 438...  Training loss: 2.0897...  0.3084 sec/batch
Epoch: 3/20...  Training Step: 439...  Training loss: 2.0667...  0.3073 sec/batch
Epoch: 3/20...  Training Step: 440...  Training loss: 2.0663...  0.3079 sec/batch
Epoch: 3/20...  Training Step: 441...  Training loss: 2.0952...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 442...  Training loss: 2.0367...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 443...  Training loss: 2.0880...  0.3071 sec/batch
Epoch: 3/20...  Training Step: 444...  Training loss: 2.0760...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 445...  Training loss: 2.0746...  0.3071 sec/batch
Epoch: 3/20...  Training Step: 446...  Training loss: 2.1237...  0.3072 sec/batch
Epoch: 3/20...  Training Step: 447...  Training loss: 2.0493...  0.3092 sec/batch
Epoch: 3/20...  Training Step: 448...  Training loss: 2.1184...  0.3082 sec/batch
Epoch: 3/20...  Training Step: 449...  Training loss: 2.0690...  0.3072 sec/batch
Epoch: 3/20...  Training Step: 450...  Training loss: 2.0602...  0.3089 sec/batch
Epoch: 3/20...  Training Step: 451...  Training loss: 2.0682...  0.3075 sec/batch
Epoch: 3/20...  Training Step: 452...  Training loss: 2.0826...  0.3081 sec/batch
Epoch: 3/20...  Training Step: 453...  Training loss: 2.0818...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 454...  Training loss: 2.0658...  0.3069 sec/batch
Epoch: 3/20...  Training Step: 455...  Training loss: 2.0480...  0.3075 sec/batch
Epoch: 3/20...  Training Step: 456...  Training loss: 2.1001...  0.3083 sec/batch
Epoch: 3/20...  Training Step: 457...  Training loss: 2.0631...  0.3078 sec/batch
Epoch: 3/20...  Training Step: 458...  Training loss: 2.1046...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 459...  Training loss: 2.0969...  0.3086 sec/batch
Epoch: 3/20...  Training Step: 460...  Training loss: 2.0711...  0.3074 sec/batch
Epoch: 3/20...  Training Step: 461...  Training loss: 2.0550...  0.3084 sec/batch
Epoch: 3/20...  Training Step: 462...  Training loss: 2.0910...  0.3078 sec/batch
Epoch: 3/20...  Training Step: 463...  Training loss: 2.0723...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 464...  Training loss: 2.0270...  0.3092 sec/batch
Epoch: 3/20...  Training Step: 465...  Training loss: 2.0447...  0.3095 sec/batch
Epoch: 3/20...  Training Step: 466...  Training loss: 2.0591...  0.3067 sec/batch
Epoch: 3/20...  Training Step: 467...  Training loss: 2.0933...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 468...  Training loss: 2.0585...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 469...  Training loss: 2.0681...  0.3079 sec/batch
Epoch: 3/20...  Training Step: 470...  Training loss: 2.0399...  0.3070 sec/batch
Epoch: 3/20...  Training Step: 471...  Training loss: 2.0421...  0.3072 sec/batch
Epoch: 3/20...  Training Step: 472...  Training loss: 2.1004...  0.3071 sec/batch
Epoch: 3/20...  Training Step: 473...  Training loss: 2.0445...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 474...  Training loss: 2.0624...  0.3074 sec/batch
Epoch: 3/20...  Training Step: 475...  Training loss: 2.0229...  0.3077 sec/batch
Epoch: 3/20...  Training Step: 476...  Training loss: 2.0350...  0.3073 sec/batch
Epoch: 3/20...  Training Step: 477...  Training loss: 2.0131...  0.3075 sec/batch
Epoch: 3/20...  Training Step: 478...  Training loss: 2.0727...  0.3081 sec/batch
Epoch: 3/20...  Training Step: 479...  Training loss: 2.0085...  0.3097 sec/batch
Epoch: 3/20...  Training Step: 480...  Training loss: 2.0348...  0.3073 sec/batch
Epoch: 3/20...  Training Step: 481...  Training loss: 1.9985...  0.3084 sec/batch
Epoch: 3/20...  Training Step: 482...  Training loss: 2.0206...  0.3066 sec/batch
Epoch: 3/20...  Training Step: 483...  Training loss: 2.0364...  0.3093 sec/batch
Epoch: 3/20...  Training Step: 484...  Training loss: 2.0212...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 485...  Training loss: 2.0058...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 486...  Training loss: 2.0365...  0.3082 sec/batch
Epoch: 3/20...  Training Step: 487...  Training loss: 2.0157...  0.3085 sec/batch
Epoch: 3/20...  Training Step: 488...  Training loss: 2.0311...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 489...  Training loss: 1.9928...  0.3117 sec/batch
Epoch: 3/20...  Training Step: 490...  Training loss: 2.0055...  0.3090 sec/batch
Epoch: 3/20...  Training Step: 491...  Training loss: 1.9951...  0.3073 sec/batch
Epoch: 3/20...  Training Step: 492...  Training loss: 2.0322...  0.3068 sec/batch
Epoch: 3/20...  Training Step: 493...  Training loss: 2.0211...  0.3085 sec/batch
Epoch: 3/20...  Training Step: 494...  Training loss: 1.9952...  0.3082 sec/batch
Epoch: 3/20...  Training Step: 495...  Training loss: 2.0017...  0.3098 sec/batch
Epoch: 3/20...  Training Step: 496...  Training loss: 1.9673...  0.3068 sec/batch
Epoch: 3/20...  Training Step: 497...  Training loss: 2.0313...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 498...  Training loss: 2.0218...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 499...  Training loss: 2.0027...  0.3089 sec/batch
Epoch: 3/20...  Training Step: 500...  Training loss: 1.9999...  0.3075 sec/batch
Epoch: 3/20...  Training Step: 501...  Training loss: 1.9973...  0.3077 sec/batch
Epoch: 3/20...  Training Step: 502...  Training loss: 2.0148...  0.3071 sec/batch
Epoch: 3/20...  Training Step: 503...  Training loss: 2.0076...  0.3078 sec/batch
Epoch: 3/20...  Training Step: 504...  Training loss: 2.0159...  0.3079 sec/batch
Epoch: 3/20...  Training Step: 505...  Training loss: 2.0254...  0.3066 sec/batch
Epoch: 3/20...  Training Step: 506...  Training loss: 2.0213...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 507...  Training loss: 2.0016...  0.3082 sec/batch
Epoch: 3/20...  Training Step: 508...  Training loss: 2.0013...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 509...  Training loss: 2.0047...  0.3087 sec/batch
Epoch: 3/20...  Training Step: 510...  Training loss: 1.9888...  0.3081 sec/batch
Epoch: 3/20...  Training Step: 511...  Training loss: 1.9845...  0.3077 sec/batch
Epoch: 3/20...  Training Step: 512...  Training loss: 1.9609...  0.3071 sec/batch
Epoch: 3/20...  Training Step: 513...  Training loss: 2.0064...  0.3074 sec/batch
Epoch: 3/20...  Training Step: 514...  Training loss: 1.9820...  0.3082 sec/batch
Epoch: 3/20...  Training Step: 515...  Training loss: 1.9957...  0.3090 sec/batch
Epoch: 3/20...  Training Step: 516...  Training loss: 1.9978...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 517...  Training loss: 2.0028...  0.3071 sec/batch
Epoch: 3/20...  Training Step: 518...  Training loss: 1.9689...  0.3083 sec/batch
Epoch: 3/20...  Training Step: 519...  Training loss: 1.9833...  0.3073 sec/batch
Epoch: 3/20...  Training Step: 520...  Training loss: 2.0168...  0.3074 sec/batch
Epoch: 3/20...  Training Step: 521...  Training loss: 1.9873...  0.3081 sec/batch
Epoch: 3/20...  Training Step: 522...  Training loss: 1.9431...  0.3063 sec/batch
Epoch: 3/20...  Training Step: 523...  Training loss: 2.0033...  0.3094 sec/batch
Epoch: 3/20...  Training Step: 524...  Training loss: 2.0071...  0.3095 sec/batch
Epoch: 3/20...  Training Step: 525...  Training loss: 1.9979...  0.3097 sec/batch
Epoch: 3/20...  Training Step: 526...  Training loss: 1.9876...  0.3078 sec/batch
Epoch: 3/20...  Training Step: 527...  Training loss: 1.9720...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 528...  Training loss: 1.9568...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 529...  Training loss: 1.9907...  0.3074 sec/batch
Epoch: 3/20...  Training Step: 530...  Training loss: 1.9974...  0.3077 sec/batch
Epoch: 3/20...  Training Step: 531...  Training loss: 1.9916...  0.3074 sec/batch
Epoch: 3/20...  Training Step: 532...  Training loss: 1.9980...  0.3085 sec/batch
Epoch: 3/20...  Training Step: 533...  Training loss: 1.9933...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 534...  Training loss: 1.9875...  0.3079 sec/batch
Epoch: 3/20...  Training Step: 535...  Training loss: 2.0221...  0.3079 sec/batch
Epoch: 3/20...  Training Step: 536...  Training loss: 1.9753...  0.3079 sec/batch
Epoch: 3/20...  Training Step: 537...  Training loss: 2.0113...  0.3071 sec/batch
Epoch: 3/20...  Training Step: 538...  Training loss: 1.9702...  0.3075 sec/batch
Epoch: 3/20...  Training Step: 539...  Training loss: 1.9854...  0.3085 sec/batch
Epoch: 3/20...  Training Step: 540...  Training loss: 1.9833...  0.3075 sec/batch
Epoch: 3/20...  Training Step: 541...  Training loss: 1.9655...  0.3073 sec/batch
Epoch: 3/20...  Training Step: 542...  Training loss: 1.9953...  0.3090 sec/batch
Epoch: 3/20...  Training Step: 543...  Training loss: 1.9972...  0.3082 sec/batch
Epoch: 3/20...  Training Step: 544...  Training loss: 1.9964...  0.3074 sec/batch
Epoch: 3/20...  Training Step: 545...  Training loss: 1.9847...  0.3081 sec/batch
Epoch: 3/20...  Training Step: 546...  Training loss: 1.9573...  0.3078 sec/batch
Epoch: 3/20...  Training Step: 547...  Training loss: 1.9669...  0.3081 sec/batch
Epoch: 3/20...  Training Step: 548...  Training loss: 2.0036...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 549...  Training loss: 1.9802...  0.3074 sec/batch
Epoch: 3/20...  Training Step: 550...  Training loss: 1.9827...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 551...  Training loss: 1.9643...  0.3077 sec/batch
Epoch: 3/20...  Training Step: 552...  Training loss: 1.9594...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 553...  Training loss: 1.9648...  0.3094 sec/batch
Epoch: 3/20...  Training Step: 554...  Training loss: 1.9707...  0.3077 sec/batch
Epoch: 3/20...  Training Step: 555...  Training loss: 1.9338...  0.3083 sec/batch
Epoch: 3/20...  Training Step: 556...  Training loss: 2.0015...  0.3073 sec/batch
Epoch: 3/20...  Training Step: 557...  Training loss: 1.9879...  0.3106 sec/batch
Epoch: 3/20...  Training Step: 558...  Training loss: 1.9592...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 559...  Training loss: 1.9756...  0.3075 sec/batch
Epoch: 3/20...  Training Step: 560...  Training loss: 1.9730...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 561...  Training loss: 1.9539...  0.3087 sec/batch
Epoch: 3/20...  Training Step: 562...  Training loss: 1.9567...  0.3072 sec/batch
Epoch: 3/20...  Training Step: 563...  Training loss: 1.9639...  0.3088 sec/batch
Epoch: 3/20...  Training Step: 564...  Training loss: 2.0030...  0.3077 sec/batch
Epoch: 3/20...  Training Step: 565...  Training loss: 1.9403...  0.3079 sec/batch
Epoch: 3/20...  Training Step: 566...  Training loss: 1.9569...  0.3091 sec/batch
Epoch: 3/20...  Training Step: 567...  Training loss: 1.9315...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 568...  Training loss: 1.9358...  0.3081 sec/batch
Epoch: 3/20...  Training Step: 569...  Training loss: 1.9845...  0.3076 sec/batch
Epoch: 3/20...  Training Step: 570...  Training loss: 1.9669...  0.3092 sec/batch
Epoch: 3/20...  Training Step: 571...  Training loss: 1.9622...  0.3083 sec/batch
Epoch: 3/20...  Training Step: 572...  Training loss: 1.9425...  0.3079 sec/batch
Epoch: 3/20...  Training Step: 573...  Training loss: 1.9303...  0.3071 sec/batch
Epoch: 3/20...  Training Step: 574...  Training loss: 1.9632...  0.3073 sec/batch
Epoch: 3/20...  Training Step: 575...  Training loss: 1.9243...  0.3083 sec/batch
Epoch: 3/20...  Training Step: 576...  Training loss: 1.9032...  0.3080 sec/batch
Epoch: 3/20...  Training Step: 577...  Training loss: 1.9235...  0.3074 sec/batch
Epoch: 3/20...  Training Step: 578...  Training loss: 1.9454...  0.3078 sec/batch
Epoch: 3/20...  Training Step: 579...  Training loss: 1.9521...  0.3099 sec/batch
Epoch: 3/20...  Training Step: 580...  Training loss: 1.9681...  0.3075 sec/batch
Epoch: 3/20...  Training Step: 581...  Training loss: 1.9577...  0.3086 sec/batch
Epoch: 3/20...  Training Step: 582...  Training loss: 1.9296...  0.3097 sec/batch
Epoch: 3/20...  Training Step: 583...  Training loss: 1.9369...  0.3092 sec/batch
Epoch: 3/20...  Training Step: 584...  Training loss: 1.9140...  0.3084 sec/batch
Epoch: 3/20...  Training Step: 585...  Training loss: 1.9307...  0.3095 sec/batch
Epoch: 3/20...  Training Step: 586...  Training loss: 1.9433...  0.3082 sec/batch
Epoch: 3/20...  Training Step: 587...  Training loss: 1.9469...  0.3087 sec/batch
Epoch: 3/20...  Training Step: 588...  Training loss: 1.9059...  0.3079 sec/batch
Epoch: 3/20...  Training Step: 589...  Training loss: 1.9437...  0.3070 sec/batch
Epoch: 3/20...  Training Step: 590...  Training loss: 1.9194...  0.3081 sec/batch
Epoch: 3/20...  Training Step: 591...  Training loss: 1.8991...  0.3075 sec/batch
Epoch: 3/20...  Training Step: 592...  Training loss: 1.9355...  0.3087 sec/batch
Epoch: 3/20...  Training Step: 593...  Training loss: 1.9276...  0.3071 sec/batch
Epoch: 3/20...  Training Step: 594...  Training loss: 1.9118...  0.3073 sec/batch
(1980000,)
(100, 19800)
Epoch: 4/20...  Training Step: 595...  Training loss: 2.0216...  0.3081 sec/batch
Epoch: 4/20...  Training Step: 596...  Training loss: 1.9188...  0.3077 sec/batch
Epoch: 4/20...  Training Step: 597...  Training loss: 1.9117...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 598...  Training loss: 1.9093...  0.3069 sec/batch
Epoch: 4/20...  Training Step: 599...  Training loss: 1.9186...  0.3068 sec/batch
Epoch: 4/20...  Training Step: 600...  Training loss: 1.8780...  0.3080 sec/batch
Epoch: 4/20...  Training Step: 601...  Training loss: 1.9343...  0.3080 sec/batch
Epoch: 4/20...  Training Step: 602...  Training loss: 1.9177...  0.3086 sec/batch
Epoch: 4/20...  Training Step: 603...  Training loss: 1.9486...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 604...  Training loss: 1.9174...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 605...  Training loss: 1.8956...  0.3074 sec/batch
Epoch: 4/20...  Training Step: 606...  Training loss: 1.8928...  0.3072 sec/batch
Epoch: 4/20...  Training Step: 607...  Training loss: 1.9090...  0.3085 sec/batch
Epoch: 4/20...  Training Step: 608...  Training loss: 1.9572...  0.3070 sec/batch
Epoch: 4/20...  Training Step: 609...  Training loss: 1.9073...  0.3069 sec/batch
Epoch: 4/20...  Training Step: 610...  Training loss: 1.8894...  0.3074 sec/batch
Epoch: 4/20...  Training Step: 611...  Training loss: 1.9203...  0.3084 sec/batch
Epoch: 4/20...  Training Step: 612...  Training loss: 1.9515...  0.3076 sec/batch
Epoch: 4/20...  Training Step: 613...  Training loss: 1.9192...  0.3074 sec/batch
Epoch: 4/20...  Training Step: 614...  Training loss: 1.9138...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 615...  Training loss: 1.9132...  0.3083 sec/batch
Epoch: 4/20...  Training Step: 616...  Training loss: 1.9496...  0.3072 sec/batch
Epoch: 4/20...  Training Step: 617...  Training loss: 1.9102...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 618...  Training loss: 1.8998...  0.3071 sec/batch
Epoch: 4/20...  Training Step: 619...  Training loss: 1.9018...  0.3069 sec/batch
Epoch: 4/20...  Training Step: 620...  Training loss: 1.8708...  0.3078 sec/batch
Epoch: 4/20...  Training Step: 621...  Training loss: 1.8777...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 622...  Training loss: 1.9183...  0.3081 sec/batch
Epoch: 4/20...  Training Step: 623...  Training loss: 1.9328...  0.3148 sec/batch
Epoch: 4/20...  Training Step: 624...  Training loss: 1.9122...  0.3078 sec/batch
Epoch: 4/20...  Training Step: 625...  Training loss: 1.8953...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 626...  Training loss: 1.8819...  0.3086 sec/batch
Epoch: 4/20...  Training Step: 627...  Training loss: 1.8996...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 628...  Training loss: 1.9235...  0.3070 sec/batch
Epoch: 4/20...  Training Step: 629...  Training loss: 1.8858...  0.3076 sec/batch
Epoch: 4/20...  Training Step: 630...  Training loss: 1.8859...  0.3084 sec/batch
Epoch: 4/20...  Training Step: 631...  Training loss: 1.8831...  0.3076 sec/batch
Epoch: 4/20...  Training Step: 632...  Training loss: 1.8606...  0.3093 sec/batch
Epoch: 4/20...  Training Step: 633...  Training loss: 1.8450...  0.3074 sec/batch
Epoch: 4/20...  Training Step: 634...  Training loss: 1.8583...  0.3073 sec/batch
Epoch: 4/20...  Training Step: 635...  Training loss: 1.8656...  0.3073 sec/batch
Epoch: 4/20...  Training Step: 636...  Training loss: 1.8918...  0.3080 sec/batch
Epoch: 4/20...  Training Step: 637...  Training loss: 1.8650...  0.3080 sec/batch
Epoch: 4/20...  Training Step: 638...  Training loss: 1.8478...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 639...  Training loss: 1.8948...  0.3073 sec/batch
Epoch: 4/20...  Training Step: 640...  Training loss: 1.8312...  0.3083 sec/batch
Epoch: 4/20...  Training Step: 641...  Training loss: 1.8856...  0.3094 sec/batch
Epoch: 4/20...  Training Step: 642...  Training loss: 1.8668...  0.3084 sec/batch
Epoch: 4/20...  Training Step: 643...  Training loss: 1.8781...  0.3082 sec/batch
Epoch: 4/20...  Training Step: 644...  Training loss: 1.9299...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 645...  Training loss: 1.8452...  0.3080 sec/batch
Epoch: 4/20...  Training Step: 646...  Training loss: 1.9324...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 647...  Training loss: 1.8725...  0.3086 sec/batch
Epoch: 4/20...  Training Step: 648...  Training loss: 1.8722...  0.3088 sec/batch
Epoch: 4/20...  Training Step: 649...  Training loss: 1.8652...  0.3074 sec/batch
Epoch: 4/20...  Training Step: 650...  Training loss: 1.8875...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 651...  Training loss: 1.8893...  0.3080 sec/batch
Epoch: 4/20...  Training Step: 652...  Training loss: 1.8689...  0.3085 sec/batch
Epoch: 4/20...  Training Step: 653...  Training loss: 1.8544...  0.3077 sec/batch
Epoch: 4/20...  Training Step: 654...  Training loss: 1.9091...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 655...  Training loss: 1.8746...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 656...  Training loss: 1.9193...  0.3093 sec/batch
Epoch: 4/20...  Training Step: 657...  Training loss: 1.9173...  0.3078 sec/batch
Epoch: 4/20...  Training Step: 658...  Training loss: 1.8816...  0.3078 sec/batch
Epoch: 4/20...  Training Step: 659...  Training loss: 1.8681...  0.3077 sec/batch
Epoch: 4/20...  Training Step: 660...  Training loss: 1.8968...  0.3071 sec/batch
Epoch: 4/20...  Training Step: 661...  Training loss: 1.8837...  0.3070 sec/batch
Epoch: 4/20...  Training Step: 662...  Training loss: 1.8433...  0.3072 sec/batch
Epoch: 4/20...  Training Step: 663...  Training loss: 1.8576...  0.3071 sec/batch
Epoch: 4/20...  Training Step: 664...  Training loss: 1.8596...  0.3088 sec/batch
Epoch: 4/20...  Training Step: 665...  Training loss: 1.9099...  0.3083 sec/batch
Epoch: 4/20...  Training Step: 666...  Training loss: 1.8700...  0.3077 sec/batch
Epoch: 4/20...  Training Step: 667...  Training loss: 1.8907...  0.3073 sec/batch
Epoch: 4/20...  Training Step: 668...  Training loss: 1.8507...  0.3155 sec/batch
Epoch: 4/20...  Training Step: 669...  Training loss: 1.8572...  0.3080 sec/batch
Epoch: 4/20...  Training Step: 670...  Training loss: 1.8975...  0.3093 sec/batch
Epoch: 4/20...  Training Step: 671...  Training loss: 1.8621...  0.3072 sec/batch
Epoch: 4/20...  Training Step: 672...  Training loss: 1.8683...  0.3080 sec/batch
Epoch: 4/20...  Training Step: 673...  Training loss: 1.8280...  0.3072 sec/batch
Epoch: 4/20...  Training Step: 674...  Training loss: 1.8502...  0.3074 sec/batch
Epoch: 4/20...  Training Step: 675...  Training loss: 1.8144...  0.3080 sec/batch
Epoch: 4/20...  Training Step: 676...  Training loss: 1.8702...  0.3076 sec/batch
Epoch: 4/20...  Training Step: 677...  Training loss: 1.8230...  0.3072 sec/batch
Epoch: 4/20...  Training Step: 678...  Training loss: 1.8415...  0.3081 sec/batch
Epoch: 4/20...  Training Step: 679...  Training loss: 1.8152...  0.3077 sec/batch
Epoch: 4/20...  Training Step: 680...  Training loss: 1.8331...  0.3076 sec/batch
Epoch: 4/20...  Training Step: 681...  Training loss: 1.8449...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 682...  Training loss: 1.8320...  0.3087 sec/batch
Epoch: 4/20...  Training Step: 683...  Training loss: 1.8101...  0.3072 sec/batch
Epoch: 4/20...  Training Step: 684...  Training loss: 1.8654...  0.3080 sec/batch
Epoch: 4/20...  Training Step: 685...  Training loss: 1.8162...  0.3082 sec/batch
Epoch: 4/20...  Training Step: 686...  Training loss: 1.8308...  0.3082 sec/batch
Epoch: 4/20...  Training Step: 687...  Training loss: 1.8083...  0.3084 sec/batch
Epoch: 4/20...  Training Step: 688...  Training loss: 1.8326...  0.3088 sec/batch
Epoch: 4/20...  Training Step: 689...  Training loss: 1.8175...  0.3081 sec/batch
Epoch: 4/20...  Training Step: 690...  Training loss: 1.8426...  0.3078 sec/batch
Epoch: 4/20...  Training Step: 691...  Training loss: 1.8402...  0.3109 sec/batch
Epoch: 4/20...  Training Step: 692...  Training loss: 1.8085...  0.3074 sec/batch
Epoch: 4/20...  Training Step: 693...  Training loss: 1.8149...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 694...  Training loss: 1.7976...  0.3082 sec/batch
Epoch: 4/20...  Training Step: 695...  Training loss: 1.8556...  0.3077 sec/batch
Epoch: 4/20...  Training Step: 696...  Training loss: 1.8273...  0.3077 sec/batch
Epoch: 4/20...  Training Step: 697...  Training loss: 1.8244...  0.3078 sec/batch
Epoch: 4/20...  Training Step: 698...  Training loss: 1.8317...  0.3081 sec/batch
Epoch: 4/20...  Training Step: 699...  Training loss: 1.8173...  0.3072 sec/batch
Epoch: 4/20...  Training Step: 700...  Training loss: 1.8282...  0.3088 sec/batch
Epoch: 4/20...  Training Step: 701...  Training loss: 1.8295...  0.3082 sec/batch
Epoch: 4/20...  Training Step: 702...  Training loss: 1.8382...  0.3089 sec/batch
Epoch: 4/20...  Training Step: 703...  Training loss: 1.8470...  0.3082 sec/batch
Epoch: 4/20...  Training Step: 704...  Training loss: 1.8464...  0.3082 sec/batch
Epoch: 4/20...  Training Step: 705...  Training loss: 1.8315...  0.3083 sec/batch
Epoch: 4/20...  Training Step: 706...  Training loss: 1.8169...  0.3083 sec/batch
Epoch: 4/20...  Training Step: 707...  Training loss: 1.8206...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 708...  Training loss: 1.8090...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 709...  Training loss: 1.8155...  0.3077 sec/batch
Epoch: 4/20...  Training Step: 710...  Training loss: 1.7856...  0.3084 sec/batch
Epoch: 4/20...  Training Step: 711...  Training loss: 1.8195...  0.3078 sec/batch
Epoch: 4/20...  Training Step: 712...  Training loss: 1.8116...  0.3081 sec/batch
Epoch: 4/20...  Training Step: 713...  Training loss: 1.8171...  0.3082 sec/batch
Epoch: 4/20...  Training Step: 714...  Training loss: 1.8100...  0.3069 sec/batch
Epoch: 4/20...  Training Step: 715...  Training loss: 1.8303...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 716...  Training loss: 1.7905...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 717...  Training loss: 1.7926...  0.3072 sec/batch
Epoch: 4/20...  Training Step: 718...  Training loss: 1.8337...  0.3080 sec/batch
Epoch: 4/20...  Training Step: 719...  Training loss: 1.8109...  0.3092 sec/batch
Epoch: 4/20...  Training Step: 720...  Training loss: 1.7671...  0.3074 sec/batch
Epoch: 4/20...  Training Step: 721...  Training loss: 1.8353...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 722...  Training loss: 1.8294...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 723...  Training loss: 1.8079...  0.3065 sec/batch
Epoch: 4/20...  Training Step: 724...  Training loss: 1.8092...  0.3081 sec/batch
Epoch: 4/20...  Training Step: 725...  Training loss: 1.7798...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 726...  Training loss: 1.7760...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 727...  Training loss: 1.8210...  0.3078 sec/batch
Epoch: 4/20...  Training Step: 728...  Training loss: 1.8295...  0.3071 sec/batch
Epoch: 4/20...  Training Step: 729...  Training loss: 1.8154...  0.3070 sec/batch
Epoch: 4/20...  Training Step: 730...  Training loss: 1.8173...  0.3074 sec/batch
Epoch: 4/20...  Training Step: 731...  Training loss: 1.8233...  0.3071 sec/batch
Epoch: 4/20...  Training Step: 732...  Training loss: 1.8184...  0.3082 sec/batch
Epoch: 4/20...  Training Step: 733...  Training loss: 1.8426...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 734...  Training loss: 1.7948...  0.3074 sec/batch
Epoch: 4/20...  Training Step: 735...  Training loss: 1.8570...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 736...  Training loss: 1.7971...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 737...  Training loss: 1.8182...  0.3077 sec/batch
Epoch: 4/20...  Training Step: 738...  Training loss: 1.8320...  0.3074 sec/batch
Epoch: 4/20...  Training Step: 739...  Training loss: 1.8022...  0.3071 sec/batch
Epoch: 4/20...  Training Step: 740...  Training loss: 1.8168...  0.3083 sec/batch
Epoch: 4/20...  Training Step: 741...  Training loss: 1.8341...  0.3080 sec/batch
Epoch: 4/20...  Training Step: 742...  Training loss: 1.8432...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 743...  Training loss: 1.8229...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 744...  Training loss: 1.7947...  0.3072 sec/batch
Epoch: 4/20...  Training Step: 745...  Training loss: 1.7947...  0.3080 sec/batch
Epoch: 4/20...  Training Step: 746...  Training loss: 1.8266...  0.3072 sec/batch
Epoch: 4/20...  Training Step: 747...  Training loss: 1.8124...  0.3077 sec/batch
Epoch: 4/20...  Training Step: 748...  Training loss: 1.8144...  0.3068 sec/batch
Epoch: 4/20...  Training Step: 749...  Training loss: 1.7996...  0.3067 sec/batch
Epoch: 4/20...  Training Step: 750...  Training loss: 1.8020...  0.3072 sec/batch
Epoch: 4/20...  Training Step: 751...  Training loss: 1.7990...  0.3073 sec/batch
Epoch: 4/20...  Training Step: 752...  Training loss: 1.7996...  0.3077 sec/batch
Epoch: 4/20...  Training Step: 753...  Training loss: 1.7627...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 754...  Training loss: 1.8297...  0.3072 sec/batch
Epoch: 4/20...  Training Step: 755...  Training loss: 1.8326...  0.3077 sec/batch
Epoch: 4/20...  Training Step: 756...  Training loss: 1.8004...  0.3082 sec/batch
Epoch: 4/20...  Training Step: 757...  Training loss: 1.8108...  0.3073 sec/batch
Epoch: 4/20...  Training Step: 758...  Training loss: 1.8029...  0.3084 sec/batch
Epoch: 4/20...  Training Step: 759...  Training loss: 1.7978...  0.3126 sec/batch
Epoch: 4/20...  Training Step: 760...  Training loss: 1.7911...  0.3072 sec/batch
Epoch: 4/20...  Training Step: 761...  Training loss: 1.8150...  0.3070 sec/batch
Epoch: 4/20...  Training Step: 762...  Training loss: 1.8514...  0.3066 sec/batch
Epoch: 4/20...  Training Step: 763...  Training loss: 1.7830...  0.3069 sec/batch
Epoch: 4/20...  Training Step: 764...  Training loss: 1.7930...  0.3070 sec/batch
Epoch: 4/20...  Training Step: 765...  Training loss: 1.7736...  0.3085 sec/batch
Epoch: 4/20...  Training Step: 766...  Training loss: 1.7808...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 767...  Training loss: 1.8077...  0.3081 sec/batch
Epoch: 4/20...  Training Step: 768...  Training loss: 1.7998...  0.3074 sec/batch
Epoch: 4/20...  Training Step: 769...  Training loss: 1.8030...  0.3074 sec/batch
Epoch: 4/20...  Training Step: 770...  Training loss: 1.7816...  0.3076 sec/batch
Epoch: 4/20...  Training Step: 771...  Training loss: 1.7775...  0.3076 sec/batch
Epoch: 4/20...  Training Step: 772...  Training loss: 1.8052...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 773...  Training loss: 1.7582...  0.3092 sec/batch
Epoch: 4/20...  Training Step: 774...  Training loss: 1.7554...  0.3076 sec/batch
Epoch: 4/20...  Training Step: 775...  Training loss: 1.7595...  0.3083 sec/batch
Epoch: 4/20...  Training Step: 776...  Training loss: 1.7912...  0.3077 sec/batch
Epoch: 4/20...  Training Step: 777...  Training loss: 1.7874...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 778...  Training loss: 1.8026...  0.3090 sec/batch
Epoch: 4/20...  Training Step: 779...  Training loss: 1.7966...  0.3080 sec/batch
Epoch: 4/20...  Training Step: 780...  Training loss: 1.7724...  0.3078 sec/batch
Epoch: 4/20...  Training Step: 781...  Training loss: 1.7869...  0.3090 sec/batch
Epoch: 4/20...  Training Step: 782...  Training loss: 1.7728...  0.3093 sec/batch
Epoch: 4/20...  Training Step: 783...  Training loss: 1.7775...  0.3079 sec/batch
Epoch: 4/20...  Training Step: 784...  Training loss: 1.7820...  0.3075 sec/batch
Epoch: 4/20...  Training Step: 785...  Training loss: 1.7885...  0.3078 sec/batch
Epoch: 4/20...  Training Step: 786...  Training loss: 1.7517...  0.3077 sec/batch
Epoch: 4/20...  Training Step: 787...  Training loss: 1.7867...  0.3076 sec/batch
Epoch: 4/20...  Training Step: 788...  Training loss: 1.7588...  0.3073 sec/batch
Epoch: 4/20...  Training Step: 789...  Training loss: 1.7464...  0.3073 sec/batch
Epoch: 4/20...  Training Step: 790...  Training loss: 1.7783...  0.3074 sec/batch
Epoch: 4/20...  Training Step: 791...  Training loss: 1.7733...  0.3077 sec/batch
Epoch: 4/20...  Training Step: 792...  Training loss: 1.7592...  0.3077 sec/batch
(1980000,)
(100, 19800)
Epoch: 5/20...  Training Step: 793...  Training loss: 1.8725...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 794...  Training loss: 1.7671...  0.3086 sec/batch
Epoch: 5/20...  Training Step: 795...  Training loss: 1.7594...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 796...  Training loss: 1.7729...  0.3086 sec/batch
Epoch: 5/20...  Training Step: 797...  Training loss: 1.7571...  0.3081 sec/batch
Epoch: 5/20...  Training Step: 798...  Training loss: 1.7261...  0.3083 sec/batch
Epoch: 5/20...  Training Step: 799...  Training loss: 1.7760...  0.3081 sec/batch
Epoch: 5/20...  Training Step: 800...  Training loss: 1.7534...  0.3093 sec/batch
Epoch: 5/20...  Training Step: 801...  Training loss: 1.7934...  0.3082 sec/batch
Epoch: 5/20...  Training Step: 802...  Training loss: 1.7534...  0.3101 sec/batch
Epoch: 5/20...  Training Step: 803...  Training loss: 1.7414...  0.3081 sec/batch
Epoch: 5/20...  Training Step: 804...  Training loss: 1.7505...  0.3080 sec/batch
Epoch: 5/20...  Training Step: 805...  Training loss: 1.7565...  0.3088 sec/batch
Epoch: 5/20...  Training Step: 806...  Training loss: 1.8071...  0.3074 sec/batch
Epoch: 5/20...  Training Step: 807...  Training loss: 1.7522...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 808...  Training loss: 1.7415...  0.3085 sec/batch
Epoch: 5/20...  Training Step: 809...  Training loss: 1.7685...  0.3089 sec/batch
Epoch: 5/20...  Training Step: 810...  Training loss: 1.7896...  0.3061 sec/batch
Epoch: 5/20...  Training Step: 811...  Training loss: 1.7625...  0.3065 sec/batch
Epoch: 5/20...  Training Step: 812...  Training loss: 1.7685...  0.3076 sec/batch
Epoch: 5/20...  Training Step: 813...  Training loss: 1.7490...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 814...  Training loss: 1.7881...  0.3088 sec/batch
Epoch: 5/20...  Training Step: 815...  Training loss: 1.7501...  0.3087 sec/batch
Epoch: 5/20...  Training Step: 816...  Training loss: 1.7520...  0.3084 sec/batch
Epoch: 5/20...  Training Step: 817...  Training loss: 1.7647...  0.3082 sec/batch
Epoch: 5/20...  Training Step: 818...  Training loss: 1.7182...  0.3082 sec/batch
Epoch: 5/20...  Training Step: 819...  Training loss: 1.7274...  0.3084 sec/batch
Epoch: 5/20...  Training Step: 820...  Training loss: 1.7617...  0.3095 sec/batch
Epoch: 5/20...  Training Step: 821...  Training loss: 1.7841...  0.3084 sec/batch
Epoch: 5/20...  Training Step: 822...  Training loss: 1.7619...  0.3079 sec/batch
Epoch: 5/20...  Training Step: 823...  Training loss: 1.7597...  0.3086 sec/batch
Epoch: 5/20...  Training Step: 824...  Training loss: 1.7209...  0.3087 sec/batch
Epoch: 5/20...  Training Step: 825...  Training loss: 1.7708...  0.3109 sec/batch
Epoch: 5/20...  Training Step: 826...  Training loss: 1.7704...  0.3094 sec/batch
Epoch: 5/20...  Training Step: 827...  Training loss: 1.7283...  0.3083 sec/batch
Epoch: 5/20...  Training Step: 828...  Training loss: 1.7483...  0.3077 sec/batch
Epoch: 5/20...  Training Step: 829...  Training loss: 1.7342...  0.3079 sec/batch
Epoch: 5/20...  Training Step: 830...  Training loss: 1.7073...  0.3077 sec/batch
Epoch: 5/20...  Training Step: 831...  Training loss: 1.7015...  0.3091 sec/batch
Epoch: 5/20...  Training Step: 832...  Training loss: 1.7174...  0.3083 sec/batch
Epoch: 5/20...  Training Step: 833...  Training loss: 1.7197...  0.3083 sec/batch
Epoch: 5/20...  Training Step: 834...  Training loss: 1.7673...  0.3078 sec/batch
Epoch: 5/20...  Training Step: 835...  Training loss: 1.7181...  0.3079 sec/batch
Epoch: 5/20...  Training Step: 836...  Training loss: 1.7158...  0.3082 sec/batch
Epoch: 5/20...  Training Step: 837...  Training loss: 1.7648...  0.3092 sec/batch
Epoch: 5/20...  Training Step: 838...  Training loss: 1.6910...  0.3087 sec/batch
Epoch: 5/20...  Training Step: 839...  Training loss: 1.7324...  0.3085 sec/batch
Epoch: 5/20...  Training Step: 840...  Training loss: 1.7234...  0.3076 sec/batch
Epoch: 5/20...  Training Step: 841...  Training loss: 1.7327...  0.3079 sec/batch
Epoch: 5/20...  Training Step: 842...  Training loss: 1.7749...  0.3076 sec/batch
Epoch: 5/20...  Training Step: 843...  Training loss: 1.7108...  0.3086 sec/batch
Epoch: 5/20...  Training Step: 844...  Training loss: 1.7958...  0.3079 sec/batch
Epoch: 5/20...  Training Step: 845...  Training loss: 1.7288...  0.3071 sec/batch
Epoch: 5/20...  Training Step: 846...  Training loss: 1.7356...  0.3078 sec/batch
Epoch: 5/20...  Training Step: 847...  Training loss: 1.7234...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 848...  Training loss: 1.7459...  0.3080 sec/batch
Epoch: 5/20...  Training Step: 849...  Training loss: 1.7604...  0.3082 sec/batch
Epoch: 5/20...  Training Step: 850...  Training loss: 1.7233...  0.3082 sec/batch
Epoch: 5/20...  Training Step: 851...  Training loss: 1.7134...  0.3079 sec/batch
Epoch: 5/20...  Training Step: 852...  Training loss: 1.7736...  0.3076 sec/batch
Epoch: 5/20...  Training Step: 853...  Training loss: 1.7355...  0.3074 sec/batch
Epoch: 5/20...  Training Step: 854...  Training loss: 1.7731...  0.3071 sec/batch
Epoch: 5/20...  Training Step: 855...  Training loss: 1.7601...  0.3093 sec/batch
Epoch: 5/20...  Training Step: 856...  Training loss: 1.7546...  0.3073 sec/batch
Epoch: 5/20...  Training Step: 857...  Training loss: 1.7245...  0.3085 sec/batch
Epoch: 5/20...  Training Step: 858...  Training loss: 1.7493...  0.3083 sec/batch
Epoch: 5/20...  Training Step: 859...  Training loss: 1.7453...  0.3084 sec/batch
Epoch: 5/20...  Training Step: 860...  Training loss: 1.7048...  0.3072 sec/batch
Epoch: 5/20...  Training Step: 861...  Training loss: 1.7251...  0.3080 sec/batch
Epoch: 5/20...  Training Step: 862...  Training loss: 1.7143...  0.3079 sec/batch
Epoch: 5/20...  Training Step: 863...  Training loss: 1.7813...  0.3083 sec/batch
Epoch: 5/20...  Training Step: 864...  Training loss: 1.7447...  0.3079 sec/batch
Epoch: 5/20...  Training Step: 865...  Training loss: 1.7554...  0.3089 sec/batch
Epoch: 5/20...  Training Step: 866...  Training loss: 1.7181...  0.3077 sec/batch
Epoch: 5/20...  Training Step: 867...  Training loss: 1.7181...  0.3087 sec/batch
Epoch: 5/20...  Training Step: 868...  Training loss: 1.7602...  0.3081 sec/batch
Epoch: 5/20...  Training Step: 869...  Training loss: 1.7226...  0.3078 sec/batch
Epoch: 5/20...  Training Step: 870...  Training loss: 1.7378...  0.3082 sec/batch
Epoch: 5/20...  Training Step: 871...  Training loss: 1.6842...  0.3086 sec/batch
Epoch: 5/20...  Training Step: 872...  Training loss: 1.7250...  0.3078 sec/batch
Epoch: 5/20...  Training Step: 873...  Training loss: 1.6962...  0.3078 sec/batch
Epoch: 5/20...  Training Step: 874...  Training loss: 1.7393...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 875...  Training loss: 1.6888...  0.3074 sec/batch
Epoch: 5/20...  Training Step: 876...  Training loss: 1.7166...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 877...  Training loss: 1.6884...  0.3074 sec/batch
Epoch: 5/20...  Training Step: 878...  Training loss: 1.7102...  0.3072 sec/batch
Epoch: 5/20...  Training Step: 879...  Training loss: 1.7038...  0.3086 sec/batch
Epoch: 5/20...  Training Step: 880...  Training loss: 1.6975...  0.3127 sec/batch
Epoch: 5/20...  Training Step: 881...  Training loss: 1.6744...  0.3080 sec/batch
Epoch: 5/20...  Training Step: 882...  Training loss: 1.7298...  0.3078 sec/batch
Epoch: 5/20...  Training Step: 883...  Training loss: 1.6827...  0.3074 sec/batch
Epoch: 5/20...  Training Step: 884...  Training loss: 1.7022...  0.3081 sec/batch
Epoch: 5/20...  Training Step: 885...  Training loss: 1.6883...  0.3081 sec/batch
Epoch: 5/20...  Training Step: 886...  Training loss: 1.6906...  0.3077 sec/batch
Epoch: 5/20...  Training Step: 887...  Training loss: 1.6944...  0.3083 sec/batch
Epoch: 5/20...  Training Step: 888...  Training loss: 1.7151...  0.3080 sec/batch
Epoch: 5/20...  Training Step: 889...  Training loss: 1.7065...  0.3089 sec/batch
Epoch: 5/20...  Training Step: 890...  Training loss: 1.6723...  0.3080 sec/batch
Epoch: 5/20...  Training Step: 891...  Training loss: 1.6859...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 892...  Training loss: 1.6560...  0.3079 sec/batch
Epoch: 5/20...  Training Step: 893...  Training loss: 1.7182...  0.3090 sec/batch
Epoch: 5/20...  Training Step: 894...  Training loss: 1.6960...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 895...  Training loss: 1.7009...  0.3074 sec/batch
Epoch: 5/20...  Training Step: 896...  Training loss: 1.7098...  0.3076 sec/batch
Epoch: 5/20...  Training Step: 897...  Training loss: 1.6880...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 898...  Training loss: 1.7081...  0.3073 sec/batch
Epoch: 5/20...  Training Step: 899...  Training loss: 1.7001...  0.3070 sec/batch
Epoch: 5/20...  Training Step: 900...  Training loss: 1.7055...  0.3081 sec/batch
Epoch: 5/20...  Training Step: 901...  Training loss: 1.7138...  0.3074 sec/batch
Epoch: 5/20...  Training Step: 902...  Training loss: 1.7167...  0.3078 sec/batch
Epoch: 5/20...  Training Step: 903...  Training loss: 1.6972...  0.3085 sec/batch
Epoch: 5/20...  Training Step: 904...  Training loss: 1.6913...  0.3078 sec/batch
Epoch: 5/20...  Training Step: 905...  Training loss: 1.6979...  0.3079 sec/batch
Epoch: 5/20...  Training Step: 906...  Training loss: 1.6850...  0.3094 sec/batch
Epoch: 5/20...  Training Step: 907...  Training loss: 1.6864...  0.3080 sec/batch
Epoch: 5/20...  Training Step: 908...  Training loss: 1.6608...  0.3081 sec/batch
Epoch: 5/20...  Training Step: 909...  Training loss: 1.7038...  0.3080 sec/batch
Epoch: 5/20...  Training Step: 910...  Training loss: 1.6850...  0.3073 sec/batch
Epoch: 5/20...  Training Step: 911...  Training loss: 1.6987...  0.3076 sec/batch
Epoch: 5/20...  Training Step: 912...  Training loss: 1.6888...  0.3086 sec/batch
Epoch: 5/20...  Training Step: 913...  Training loss: 1.6993...  0.3077 sec/batch
Epoch: 5/20...  Training Step: 914...  Training loss: 1.6597...  0.3077 sec/batch
Epoch: 5/20...  Training Step: 915...  Training loss: 1.6654...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 916...  Training loss: 1.7184...  0.3078 sec/batch
Epoch: 5/20...  Training Step: 917...  Training loss: 1.6860...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 918...  Training loss: 1.6448...  0.3072 sec/batch
Epoch: 5/20...  Training Step: 919...  Training loss: 1.7070...  0.3082 sec/batch
Epoch: 5/20...  Training Step: 920...  Training loss: 1.7063...  0.3077 sec/batch
Epoch: 5/20...  Training Step: 921...  Training loss: 1.6882...  0.3076 sec/batch
Epoch: 5/20...  Training Step: 922...  Training loss: 1.6765...  0.3088 sec/batch
Epoch: 5/20...  Training Step: 923...  Training loss: 1.6599...  0.3078 sec/batch
Epoch: 5/20...  Training Step: 924...  Training loss: 1.6606...  0.3063 sec/batch
Epoch: 5/20...  Training Step: 925...  Training loss: 1.7089...  0.3083 sec/batch
Epoch: 5/20...  Training Step: 926...  Training loss: 1.6937...  0.3083 sec/batch
Epoch: 5/20...  Training Step: 927...  Training loss: 1.6998...  0.3077 sec/batch
Epoch: 5/20...  Training Step: 928...  Training loss: 1.6999...  0.3078 sec/batch
Epoch: 5/20...  Training Step: 929...  Training loss: 1.7180...  0.3086 sec/batch
Epoch: 5/20...  Training Step: 930...  Training loss: 1.7026...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 931...  Training loss: 1.7132...  0.3080 sec/batch
Epoch: 5/20...  Training Step: 932...  Training loss: 1.6856...  0.3077 sec/batch
Epoch: 5/20...  Training Step: 933...  Training loss: 1.7447...  0.3093 sec/batch
Epoch: 5/20...  Training Step: 934...  Training loss: 1.6854...  0.3089 sec/batch
Epoch: 5/20...  Training Step: 935...  Training loss: 1.6873...  0.3086 sec/batch
Epoch: 5/20...  Training Step: 936...  Training loss: 1.7082...  0.3077 sec/batch
Epoch: 5/20...  Training Step: 937...  Training loss: 1.6812...  0.3089 sec/batch
Epoch: 5/20...  Training Step: 938...  Training loss: 1.7049...  0.3076 sec/batch
Epoch: 5/20...  Training Step: 939...  Training loss: 1.7031...  0.3086 sec/batch
Epoch: 5/20...  Training Step: 940...  Training loss: 1.7185...  0.3084 sec/batch
Epoch: 5/20...  Training Step: 941...  Training loss: 1.7070...  0.3076 sec/batch
Epoch: 5/20...  Training Step: 942...  Training loss: 1.6879...  0.3077 sec/batch
Epoch: 5/20...  Training Step: 943...  Training loss: 1.6615...  0.3080 sec/batch
Epoch: 5/20...  Training Step: 944...  Training loss: 1.6975...  0.3088 sec/batch
Epoch: 5/20...  Training Step: 945...  Training loss: 1.6996...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 946...  Training loss: 1.6922...  0.3078 sec/batch
Epoch: 5/20...  Training Step: 947...  Training loss: 1.6939...  0.3093 sec/batch
Epoch: 5/20...  Training Step: 948...  Training loss: 1.6826...  0.3101 sec/batch
Epoch: 5/20...  Training Step: 949...  Training loss: 1.6941...  0.3084 sec/batch
Epoch: 5/20...  Training Step: 950...  Training loss: 1.6776...  0.3078 sec/batch
Epoch: 5/20...  Training Step: 951...  Training loss: 1.6461...  0.3071 sec/batch
Epoch: 5/20...  Training Step: 952...  Training loss: 1.7101...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 953...  Training loss: 1.7137...  0.3073 sec/batch
Epoch: 5/20...  Training Step: 954...  Training loss: 1.6812...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 955...  Training loss: 1.6950...  0.3076 sec/batch
Epoch: 5/20...  Training Step: 956...  Training loss: 1.6837...  0.3080 sec/batch
Epoch: 5/20...  Training Step: 957...  Training loss: 1.6859...  0.3074 sec/batch
Epoch: 5/20...  Training Step: 958...  Training loss: 1.6805...  0.3073 sec/batch
Epoch: 5/20...  Training Step: 959...  Training loss: 1.6931...  0.3073 sec/batch
Epoch: 5/20...  Training Step: 960...  Training loss: 1.7435...  0.3087 sec/batch
Epoch: 5/20...  Training Step: 961...  Training loss: 1.6711...  0.3084 sec/batch
Epoch: 5/20...  Training Step: 962...  Training loss: 1.6683...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 963...  Training loss: 1.6663...  0.3083 sec/batch
Epoch: 5/20...  Training Step: 964...  Training loss: 1.6605...  0.3090 sec/batch
Epoch: 5/20...  Training Step: 965...  Training loss: 1.7079...  0.3082 sec/batch
Epoch: 5/20...  Training Step: 966...  Training loss: 1.6798...  0.3069 sec/batch
Epoch: 5/20...  Training Step: 967...  Training loss: 1.6964...  0.3086 sec/batch
Epoch: 5/20...  Training Step: 968...  Training loss: 1.6630...  0.3071 sec/batch
Epoch: 5/20...  Training Step: 969...  Training loss: 1.6641...  0.3079 sec/batch
Epoch: 5/20...  Training Step: 970...  Training loss: 1.7045...  0.3071 sec/batch
Epoch: 5/20...  Training Step: 971...  Training loss: 1.6489...  0.3072 sec/batch
Epoch: 5/20...  Training Step: 972...  Training loss: 1.6568...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 973...  Training loss: 1.6495...  0.3075 sec/batch
Epoch: 5/20...  Training Step: 974...  Training loss: 1.6709...  0.3085 sec/batch
Epoch: 5/20...  Training Step: 975...  Training loss: 1.6745...  0.3073 sec/batch
Epoch: 5/20...  Training Step: 976...  Training loss: 1.6794...  0.3085 sec/batch
Epoch: 5/20...  Training Step: 977...  Training loss: 1.6667...  0.3086 sec/batch
Epoch: 5/20...  Training Step: 978...  Training loss: 1.6595...  0.3083 sec/batch
Epoch: 5/20...  Training Step: 979...  Training loss: 1.6835...  0.3091 sec/batch
Epoch: 5/20...  Training Step: 980...  Training loss: 1.6581...  0.3157 sec/batch
Epoch: 5/20...  Training Step: 981...  Training loss: 1.6631...  0.3096 sec/batch
Epoch: 5/20...  Training Step: 982...  Training loss: 1.6729...  0.3070 sec/batch
Epoch: 5/20...  Training Step: 983...  Training loss: 1.6602...  0.3078 sec/batch
Epoch: 5/20...  Training Step: 984...  Training loss: 1.6476...  0.3085 sec/batch
Epoch: 5/20...  Training Step: 985...  Training loss: 1.6722...  0.3090 sec/batch
Epoch: 5/20...  Training Step: 986...  Training loss: 1.6410...  0.3076 sec/batch
Epoch: 5/20...  Training Step: 987...  Training loss: 1.6352...  0.3090 sec/batch
Epoch: 5/20...  Training Step: 988...  Training loss: 1.6770...  0.3071 sec/batch
Epoch: 5/20...  Training Step: 989...  Training loss: 1.6545...  0.3072 sec/batch
Epoch: 5/20...  Training Step: 990...  Training loss: 1.6460...  0.3077 sec/batch
(1980000,)
(100, 19800)
Epoch: 6/20...  Training Step: 991...  Training loss: 1.7712...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 992...  Training loss: 1.6567...  0.3086 sec/batch
Epoch: 6/20...  Training Step: 993...  Training loss: 1.6530...  0.3086 sec/batch
Epoch: 6/20...  Training Step: 994...  Training loss: 1.6642...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 995...  Training loss: 1.6417...  0.3086 sec/batch
Epoch: 6/20...  Training Step: 996...  Training loss: 1.6166...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 997...  Training loss: 1.6575...  0.3087 sec/batch
Epoch: 6/20...  Training Step: 998...  Training loss: 1.6339...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 999...  Training loss: 1.6803...  0.3075 sec/batch
Epoch: 6/20...  Training Step: 1000...  Training loss: 1.6503...  0.3100 sec/batch
Epoch: 6/20...  Training Step: 1001...  Training loss: 1.6325...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 1002...  Training loss: 1.6371...  0.3065 sec/batch
Epoch: 6/20...  Training Step: 1003...  Training loss: 1.6510...  0.3082 sec/batch
Epoch: 6/20...  Training Step: 1004...  Training loss: 1.6895...  0.3104 sec/batch
Epoch: 6/20...  Training Step: 1005...  Training loss: 1.6447...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 1006...  Training loss: 1.6283...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 1007...  Training loss: 1.6648...  0.3072 sec/batch
Epoch: 6/20...  Training Step: 1008...  Training loss: 1.6764...  0.3073 sec/batch
Epoch: 6/20...  Training Step: 1009...  Training loss: 1.6494...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 1010...  Training loss: 1.6762...  0.3070 sec/batch
Epoch: 6/20...  Training Step: 1011...  Training loss: 1.6351...  0.3073 sec/batch
Epoch: 6/20...  Training Step: 1012...  Training loss: 1.6862...  0.3067 sec/batch
Epoch: 6/20...  Training Step: 1013...  Training loss: 1.6486...  0.3088 sec/batch
Epoch: 6/20...  Training Step: 1014...  Training loss: 1.6619...  0.3096 sec/batch
Epoch: 6/20...  Training Step: 1015...  Training loss: 1.6624...  0.3077 sec/batch
Epoch: 6/20...  Training Step: 1016...  Training loss: 1.6186...  0.3079 sec/batch
Epoch: 6/20...  Training Step: 1017...  Training loss: 1.6108...  0.3081 sec/batch
Epoch: 6/20...  Training Step: 1018...  Training loss: 1.6570...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 1019...  Training loss: 1.6761...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 1020...  Training loss: 1.6637...  0.3081 sec/batch
Epoch: 6/20...  Training Step: 1021...  Training loss: 1.6467...  0.3079 sec/batch
Epoch: 6/20...  Training Step: 1022...  Training loss: 1.6302...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1023...  Training loss: 1.6663...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 1024...  Training loss: 1.6761...  0.3073 sec/batch
Epoch: 6/20...  Training Step: 1025...  Training loss: 1.6378...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1026...  Training loss: 1.6487...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 1027...  Training loss: 1.6236...  0.3100 sec/batch
Epoch: 6/20...  Training Step: 1028...  Training loss: 1.6010...  0.3073 sec/batch
Epoch: 6/20...  Training Step: 1029...  Training loss: 1.5943...  0.3075 sec/batch
Epoch: 6/20...  Training Step: 1030...  Training loss: 1.6174...  0.3075 sec/batch
Epoch: 6/20...  Training Step: 1031...  Training loss: 1.6161...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 1032...  Training loss: 1.6607...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1033...  Training loss: 1.6182...  0.3072 sec/batch
Epoch: 6/20...  Training Step: 1034...  Training loss: 1.6157...  0.3084 sec/batch
Epoch: 6/20...  Training Step: 1035...  Training loss: 1.6595...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1036...  Training loss: 1.6079...  0.3071 sec/batch
Epoch: 6/20...  Training Step: 1037...  Training loss: 1.6239...  0.3081 sec/batch
Epoch: 6/20...  Training Step: 1038...  Training loss: 1.6166...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 1039...  Training loss: 1.6143...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 1040...  Training loss: 1.6658...  0.3082 sec/batch
Epoch: 6/20...  Training Step: 1041...  Training loss: 1.6136...  0.3087 sec/batch
Epoch: 6/20...  Training Step: 1042...  Training loss: 1.6850...  0.3088 sec/batch
Epoch: 6/20...  Training Step: 1043...  Training loss: 1.6300...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 1044...  Training loss: 1.6417...  0.3067 sec/batch
Epoch: 6/20...  Training Step: 1045...  Training loss: 1.6327...  0.3082 sec/batch
Epoch: 6/20...  Training Step: 1046...  Training loss: 1.6506...  0.3077 sec/batch
Epoch: 6/20...  Training Step: 1047...  Training loss: 1.6628...  0.3082 sec/batch
Epoch: 6/20...  Training Step: 1048...  Training loss: 1.6274...  0.3072 sec/batch
Epoch: 6/20...  Training Step: 1049...  Training loss: 1.6194...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1050...  Training loss: 1.6786...  0.3080 sec/batch
Epoch: 6/20...  Training Step: 1051...  Training loss: 1.6352...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 1052...  Training loss: 1.6869...  0.3083 sec/batch
Epoch: 6/20...  Training Step: 1053...  Training loss: 1.6656...  0.3087 sec/batch
Epoch: 6/20...  Training Step: 1054...  Training loss: 1.6483...  0.3083 sec/batch
Epoch: 6/20...  Training Step: 1055...  Training loss: 1.6369...  0.3085 sec/batch
Epoch: 6/20...  Training Step: 1056...  Training loss: 1.6446...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1057...  Training loss: 1.6528...  0.3085 sec/batch
Epoch: 6/20...  Training Step: 1058...  Training loss: 1.6150...  0.3081 sec/batch
Epoch: 6/20...  Training Step: 1059...  Training loss: 1.6306...  0.3085 sec/batch
Epoch: 6/20...  Training Step: 1060...  Training loss: 1.6311...  0.3081 sec/batch
Epoch: 6/20...  Training Step: 1061...  Training loss: 1.6733...  0.3089 sec/batch
Epoch: 6/20...  Training Step: 1062...  Training loss: 1.6496...  0.3091 sec/batch
Epoch: 6/20...  Training Step: 1063...  Training loss: 1.6657...  0.3084 sec/batch
Epoch: 6/20...  Training Step: 1064...  Training loss: 1.6099...  0.3087 sec/batch
Epoch: 6/20...  Training Step: 1065...  Training loss: 1.6218...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1066...  Training loss: 1.6573...  0.3081 sec/batch
Epoch: 6/20...  Training Step: 1067...  Training loss: 1.6362...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1068...  Training loss: 1.6215...  0.3077 sec/batch
Epoch: 6/20...  Training Step: 1069...  Training loss: 1.5935...  0.3070 sec/batch
Epoch: 6/20...  Training Step: 1070...  Training loss: 1.6199...  0.3070 sec/batch
Epoch: 6/20...  Training Step: 1071...  Training loss: 1.5870...  0.3081 sec/batch
Epoch: 6/20...  Training Step: 1072...  Training loss: 1.6330...  0.3077 sec/batch
Epoch: 6/20...  Training Step: 1073...  Training loss: 1.5916...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 1074...  Training loss: 1.6253...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 1075...  Training loss: 1.6039...  0.3094 sec/batch
Epoch: 6/20...  Training Step: 1076...  Training loss: 1.6095...  0.3083 sec/batch
Epoch: 6/20...  Training Step: 1077...  Training loss: 1.6083...  0.3079 sec/batch
Epoch: 6/20...  Training Step: 1078...  Training loss: 1.6004...  0.3077 sec/batch
Epoch: 6/20...  Training Step: 1079...  Training loss: 1.5846...  0.3082 sec/batch
Epoch: 6/20...  Training Step: 1080...  Training loss: 1.6266...  0.3075 sec/batch
Epoch: 6/20...  Training Step: 1081...  Training loss: 1.5953...  0.3084 sec/batch
Epoch: 6/20...  Training Step: 1082...  Training loss: 1.6021...  0.3077 sec/batch
Epoch: 6/20...  Training Step: 1083...  Training loss: 1.5853...  0.3077 sec/batch
Epoch: 6/20...  Training Step: 1084...  Training loss: 1.5887...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1085...  Training loss: 1.5880...  0.3089 sec/batch
Epoch: 6/20...  Training Step: 1086...  Training loss: 1.6290...  0.3084 sec/batch
Epoch: 6/20...  Training Step: 1087...  Training loss: 1.6115...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1088...  Training loss: 1.5672...  0.3081 sec/batch
Epoch: 6/20...  Training Step: 1089...  Training loss: 1.5908...  0.3079 sec/batch
Epoch: 6/20...  Training Step: 1090...  Training loss: 1.5724...  0.3079 sec/batch
Epoch: 6/20...  Training Step: 1091...  Training loss: 1.6111...  0.3089 sec/batch
Epoch: 6/20...  Training Step: 1092...  Training loss: 1.6072...  0.3072 sec/batch
Epoch: 6/20...  Training Step: 1093...  Training loss: 1.6068...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1094...  Training loss: 1.6178...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1095...  Training loss: 1.5988...  0.3113 sec/batch
Epoch: 6/20...  Training Step: 1096...  Training loss: 1.6079...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 1097...  Training loss: 1.6115...  0.3075 sec/batch
Epoch: 6/20...  Training Step: 1098...  Training loss: 1.6041...  0.3060 sec/batch
Epoch: 6/20...  Training Step: 1099...  Training loss: 1.6096...  0.3072 sec/batch
Epoch: 6/20...  Training Step: 1100...  Training loss: 1.6190...  0.3077 sec/batch
Epoch: 6/20...  Training Step: 1101...  Training loss: 1.6041...  0.3077 sec/batch
Epoch: 6/20...  Training Step: 1102...  Training loss: 1.6006...  0.3084 sec/batch
Epoch: 6/20...  Training Step: 1103...  Training loss: 1.6108...  0.3075 sec/batch
Epoch: 6/20...  Training Step: 1104...  Training loss: 1.5980...  0.3068 sec/batch
Epoch: 6/20...  Training Step: 1105...  Training loss: 1.5781...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 1106...  Training loss: 1.5613...  0.3073 sec/batch
Epoch: 6/20...  Training Step: 1107...  Training loss: 1.6036...  0.3080 sec/batch
Epoch: 6/20...  Training Step: 1108...  Training loss: 1.6078...  0.3071 sec/batch
Epoch: 6/20...  Training Step: 1109...  Training loss: 1.5868...  0.3073 sec/batch
Epoch: 6/20...  Training Step: 1110...  Training loss: 1.5927...  0.3072 sec/batch
Epoch: 6/20...  Training Step: 1111...  Training loss: 1.5945...  0.3080 sec/batch
Epoch: 6/20...  Training Step: 1112...  Training loss: 1.5596...  0.3085 sec/batch
Epoch: 6/20...  Training Step: 1113...  Training loss: 1.5677...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1114...  Training loss: 1.6157...  0.3070 sec/batch
Epoch: 6/20...  Training Step: 1115...  Training loss: 1.5927...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 1116...  Training loss: 1.5587...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 1117...  Training loss: 1.6076...  0.3079 sec/batch
Epoch: 6/20...  Training Step: 1118...  Training loss: 1.6054...  0.3069 sec/batch
Epoch: 6/20...  Training Step: 1119...  Training loss: 1.5812...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 1120...  Training loss: 1.5763...  0.3073 sec/batch
Epoch: 6/20...  Training Step: 1121...  Training loss: 1.5524...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 1122...  Training loss: 1.5669...  0.3080 sec/batch
Epoch: 6/20...  Training Step: 1123...  Training loss: 1.6072...  0.3087 sec/batch
Epoch: 6/20...  Training Step: 1124...  Training loss: 1.5991...  0.3079 sec/batch
Epoch: 6/20...  Training Step: 1125...  Training loss: 1.5932...  0.3073 sec/batch
Epoch: 6/20...  Training Step: 1126...  Training loss: 1.6024...  0.3080 sec/batch
Epoch: 6/20...  Training Step: 1127...  Training loss: 1.6175...  0.3084 sec/batch
Epoch: 6/20...  Training Step: 1128...  Training loss: 1.6016...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 1129...  Training loss: 1.6123...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1130...  Training loss: 1.5852...  0.3082 sec/batch
Epoch: 6/20...  Training Step: 1131...  Training loss: 1.6527...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 1132...  Training loss: 1.5889...  0.3090 sec/batch
Epoch: 6/20...  Training Step: 1133...  Training loss: 1.5916...  0.3088 sec/batch
Epoch: 6/20...  Training Step: 1134...  Training loss: 1.6064...  0.3077 sec/batch
Epoch: 6/20...  Training Step: 1135...  Training loss: 1.5761...  0.3092 sec/batch
Epoch: 6/20...  Training Step: 1136...  Training loss: 1.6010...  0.3083 sec/batch
Epoch: 6/20...  Training Step: 1137...  Training loss: 1.5883...  0.3095 sec/batch
Epoch: 6/20...  Training Step: 1138...  Training loss: 1.6212...  0.3077 sec/batch
Epoch: 6/20...  Training Step: 1139...  Training loss: 1.5941...  0.3080 sec/batch
Epoch: 6/20...  Training Step: 1140...  Training loss: 1.5780...  0.3077 sec/batch
Epoch: 6/20...  Training Step: 1141...  Training loss: 1.5482...  0.3084 sec/batch
Epoch: 6/20...  Training Step: 1142...  Training loss: 1.5924...  0.3088 sec/batch
Epoch: 6/20...  Training Step: 1143...  Training loss: 1.6013...  0.3086 sec/batch
Epoch: 6/20...  Training Step: 1144...  Training loss: 1.5860...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 1145...  Training loss: 1.5955...  0.3080 sec/batch
Epoch: 6/20...  Training Step: 1146...  Training loss: 1.5905...  0.3086 sec/batch
Epoch: 6/20...  Training Step: 1147...  Training loss: 1.5892...  0.3075 sec/batch
Epoch: 6/20...  Training Step: 1148...  Training loss: 1.5837...  0.3075 sec/batch
Epoch: 6/20...  Training Step: 1149...  Training loss: 1.5489...  0.3071 sec/batch
Epoch: 6/20...  Training Step: 1150...  Training loss: 1.6091...  0.3059 sec/batch
Epoch: 6/20...  Training Step: 1151...  Training loss: 1.6244...  0.3082 sec/batch
Epoch: 6/20...  Training Step: 1152...  Training loss: 1.5848...  0.3086 sec/batch
Epoch: 6/20...  Training Step: 1153...  Training loss: 1.5960...  0.3075 sec/batch
Epoch: 6/20...  Training Step: 1154...  Training loss: 1.5898...  0.3073 sec/batch
Epoch: 6/20...  Training Step: 1155...  Training loss: 1.5774...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 1156...  Training loss: 1.5805...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1157...  Training loss: 1.6008...  0.3080 sec/batch
Epoch: 6/20...  Training Step: 1158...  Training loss: 1.6550...  0.3093 sec/batch
Epoch: 6/20...  Training Step: 1159...  Training loss: 1.5810...  0.3077 sec/batch
Epoch: 6/20...  Training Step: 1160...  Training loss: 1.5894...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 1161...  Training loss: 1.5982...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1162...  Training loss: 1.5601...  0.3081 sec/batch
Epoch: 6/20...  Training Step: 1163...  Training loss: 1.6072...  0.3075 sec/batch
Epoch: 6/20...  Training Step: 1164...  Training loss: 1.5891...  0.3079 sec/batch
Epoch: 6/20...  Training Step: 1165...  Training loss: 1.6052...  0.3092 sec/batch
Epoch: 6/20...  Training Step: 1166...  Training loss: 1.5622...  0.3078 sec/batch
Epoch: 6/20...  Training Step: 1167...  Training loss: 1.5631...  0.3081 sec/batch
Epoch: 6/20...  Training Step: 1168...  Training loss: 1.5940...  0.3082 sec/batch
Epoch: 6/20...  Training Step: 1169...  Training loss: 1.5609...  0.3077 sec/batch
Epoch: 6/20...  Training Step: 1170...  Training loss: 1.5500...  0.3093 sec/batch
Epoch: 6/20...  Training Step: 1171...  Training loss: 1.5519...  0.3075 sec/batch
Epoch: 6/20...  Training Step: 1172...  Training loss: 1.5787...  0.3081 sec/batch
Epoch: 6/20...  Training Step: 1173...  Training loss: 1.5839...  0.3073 sec/batch
Epoch: 6/20...  Training Step: 1174...  Training loss: 1.5827...  0.3073 sec/batch
Epoch: 6/20...  Training Step: 1175...  Training loss: 1.5759...  0.3069 sec/batch
Epoch: 6/20...  Training Step: 1176...  Training loss: 1.5630...  0.3074 sec/batch
Epoch: 6/20...  Training Step: 1177...  Training loss: 1.5924...  0.3073 sec/batch
Epoch: 6/20...  Training Step: 1178...  Training loss: 1.5636...  0.3089 sec/batch
Epoch: 6/20...  Training Step: 1179...  Training loss: 1.5738...  0.3083 sec/batch
Epoch: 6/20...  Training Step: 1180...  Training loss: 1.5732...  0.3085 sec/batch
Epoch: 6/20...  Training Step: 1181...  Training loss: 1.5660...  0.3070 sec/batch
Epoch: 6/20...  Training Step: 1182...  Training loss: 1.5521...  0.3087 sec/batch
Epoch: 6/20...  Training Step: 1183...  Training loss: 1.5734...  0.3073 sec/batch
Epoch: 6/20...  Training Step: 1184...  Training loss: 1.5464...  0.3085 sec/batch
Epoch: 6/20...  Training Step: 1185...  Training loss: 1.5416...  0.3077 sec/batch
Epoch: 6/20...  Training Step: 1186...  Training loss: 1.5782...  0.3073 sec/batch
Epoch: 6/20...  Training Step: 1187...  Training loss: 1.5608...  0.3076 sec/batch
Epoch: 6/20...  Training Step: 1188...  Training loss: 1.5582...  0.3075 sec/batch
(1980000,)
(100, 19800)
Epoch: 7/20...  Training Step: 1189...  Training loss: 1.7183...  0.3074 sec/batch
Epoch: 7/20...  Training Step: 1190...  Training loss: 1.5807...  0.3072 sec/batch
Epoch: 7/20...  Training Step: 1191...  Training loss: 1.5616...  0.3084 sec/batch
Epoch: 7/20...  Training Step: 1192...  Training loss: 1.5784...  0.3091 sec/batch
Epoch: 7/20...  Training Step: 1193...  Training loss: 1.5580...  0.3085 sec/batch
Epoch: 7/20...  Training Step: 1194...  Training loss: 1.5346...  0.3080 sec/batch
Epoch: 7/20...  Training Step: 1195...  Training loss: 1.5728...  0.3089 sec/batch
Epoch: 7/20...  Training Step: 1196...  Training loss: 1.5548...  0.3072 sec/batch
Epoch: 7/20...  Training Step: 1197...  Training loss: 1.5870...  0.3079 sec/batch
Epoch: 7/20...  Training Step: 1198...  Training loss: 1.5666...  0.3078 sec/batch
Epoch: 7/20...  Training Step: 1199...  Training loss: 1.5357...  0.3085 sec/batch
Epoch: 7/20...  Training Step: 1200...  Training loss: 1.5550...  0.3072 sec/batch
Epoch: 7/20...  Training Step: 1201...  Training loss: 1.5618...  0.3080 sec/batch
Epoch: 7/20...  Training Step: 1202...  Training loss: 1.5939...  0.3077 sec/batch
Epoch: 7/20...  Training Step: 1203...  Training loss: 1.5529...  0.3077 sec/batch
Epoch: 7/20...  Training Step: 1204...  Training loss: 1.5402...  0.3072 sec/batch
Epoch: 7/20...  Training Step: 1205...  Training loss: 1.5714...  0.3077 sec/batch
Epoch: 7/20...  Training Step: 1206...  Training loss: 1.5875...  0.3079 sec/batch
Epoch: 7/20...  Training Step: 1207...  Training loss: 1.5696...  0.3081 sec/batch
Epoch: 7/20...  Training Step: 1208...  Training loss: 1.5891...  0.3085 sec/batch
Epoch: 7/20...  Training Step: 1209...  Training loss: 1.5574...  0.3137 sec/batch
Epoch: 7/20...  Training Step: 1210...  Training loss: 1.5936...  0.3075 sec/batch
Epoch: 7/20...  Training Step: 1211...  Training loss: 1.5657...  0.3075 sec/batch
Epoch: 7/20...  Training Step: 1212...  Training loss: 1.5710...  0.3084 sec/batch
Epoch: 7/20...  Training Step: 1213...  Training loss: 1.5832...  0.3071 sec/batch
Epoch: 7/20...  Training Step: 1214...  Training loss: 1.5408...  0.3075 sec/batch
Epoch: 7/20...  Training Step: 1215...  Training loss: 1.5348...  0.3079 sec/batch
Epoch: 7/20...  Training Step: 1216...  Training loss: 1.5806...  0.3086 sec/batch
Epoch: 7/20...  Training Step: 1217...  Training loss: 1.5872...  0.3074 sec/batch
Epoch: 7/20...  Training Step: 1218...  Training loss: 1.5963...  0.3082 sec/batch
Epoch: 7/20...  Training Step: 1219...  Training loss: 1.5697...  0.3078 sec/batch
Epoch: 7/20...  Training Step: 1220...  Training loss: 1.5499...  0.3081 sec/batch
Epoch: 7/20...  Training Step: 1221...  Training loss: 1.5871...  0.3064 sec/batch
Epoch: 7/20...  Training Step: 1222...  Training loss: 1.5889...  0.3082 sec/batch
Epoch: 7/20...  Training Step: 1223...  Training loss: 1.5598...  0.3072 sec/batch
Epoch: 7/20...  Training Step: 1224...  Training loss: 1.5654...  0.3091 sec/batch
Epoch: 7/20...  Training Step: 1225...  Training loss: 1.5357...  0.3083 sec/batch
Epoch: 7/20...  Training Step: 1226...  Training loss: 1.5216...  0.3074 sec/batch
Epoch: 7/20...  Training Step: 1227...  Training loss: 1.5103...  0.3071 sec/batch
Epoch: 7/20...  Training Step: 1228...  Training loss: 1.5340...  0.3088 sec/batch
Epoch: 7/20...  Training Step: 1229...  Training loss: 1.5369...  0.3085 sec/batch
Epoch: 7/20...  Training Step: 1230...  Training loss: 1.5819...  0.3093 sec/batch
Epoch: 7/20...  Training Step: 1231...  Training loss: 1.5391...  0.3085 sec/batch
Epoch: 7/20...  Training Step: 1232...  Training loss: 1.5158...  0.3102 sec/batch
Epoch: 7/20...  Training Step: 1233...  Training loss: 1.5633...  0.3081 sec/batch
Epoch: 7/20...  Training Step: 1234...  Training loss: 1.5156...  0.3083 sec/batch
Epoch: 7/20...  Training Step: 1235...  Training loss: 1.5489...  0.3070 sec/batch
Epoch: 7/20...  Training Step: 1236...  Training loss: 1.5323...  0.3076 sec/batch
Epoch: 7/20...  Training Step: 1237...  Training loss: 1.5372...  0.3071 sec/batch
Epoch: 7/20...  Training Step: 1238...  Training loss: 1.5730...  0.3087 sec/batch
Epoch: 7/20...  Training Step: 1239...  Training loss: 1.5241...  0.3065 sec/batch
Epoch: 7/20...  Training Step: 1240...  Training loss: 1.5924...  0.3068 sec/batch
Epoch: 7/20...  Training Step: 1241...  Training loss: 1.5501...  0.3070 sec/batch
Epoch: 7/20...  Training Step: 1242...  Training loss: 1.5461...  0.3067 sec/batch
Epoch: 7/20...  Training Step: 1243...  Training loss: 1.5495...  0.3066 sec/batch
Epoch: 7/20...  Training Step: 1244...  Training loss: 1.5572...  0.3076 sec/batch
Epoch: 7/20...  Training Step: 1245...  Training loss: 1.5647...  0.3078 sec/batch
Epoch: 7/20...  Training Step: 1246...  Training loss: 1.5337...  0.3080 sec/batch
Epoch: 7/20...  Training Step: 1247...  Training loss: 1.5201...  0.3072 sec/batch
Epoch: 7/20...  Training Step: 1248...  Training loss: 1.5829...  0.3065 sec/batch
Epoch: 7/20...  Training Step: 1249...  Training loss: 1.5577...  0.3066 sec/batch
Epoch: 7/20...  Training Step: 1250...  Training loss: 1.6026...  0.3081 sec/batch
Epoch: 7/20...  Training Step: 1251...  Training loss: 1.5697...  0.3090 sec/batch
Epoch: 7/20...  Training Step: 1252...  Training loss: 1.5617...  0.3073 sec/batch
Epoch: 7/20...  Training Step: 1253...  Training loss: 1.5475...  0.3074 sec/batch
Epoch: 7/20...  Training Step: 1254...  Training loss: 1.5529...  0.3082 sec/batch
Epoch: 7/20...  Training Step: 1255...  Training loss: 1.5633...  0.3082 sec/batch
Epoch: 7/20...  Training Step: 1256...  Training loss: 1.5257...  0.3076 sec/batch
Epoch: 7/20...  Training Step: 1257...  Training loss: 1.5454...  0.3076 sec/batch
Epoch: 7/20...  Training Step: 1258...  Training loss: 1.5343...  0.3079 sec/batch
Epoch: 7/20...  Training Step: 1259...  Training loss: 1.5795...  0.3078 sec/batch
Epoch: 7/20...  Training Step: 1260...  Training loss: 1.5592...  0.3076 sec/batch
Epoch: 7/20...  Training Step: 1261...  Training loss: 1.5762...  0.3063 sec/batch
Epoch: 7/20...  Training Step: 1262...  Training loss: 1.5237...  0.3089 sec/batch
Epoch: 7/20...  Training Step: 1263...  Training loss: 1.5336...  0.3078 sec/batch
Epoch: 7/20...  Training Step: 1264...  Training loss: 1.5645...  0.3072 sec/batch
Epoch: 7/20...  Training Step: 1265...  Training loss: 1.5444...  0.3088 sec/batch
Epoch: 7/20...  Training Step: 1266...  Training loss: 1.5290...  0.3076 sec/batch
Epoch: 7/20...  Training Step: 1267...  Training loss: 1.4953...  0.3072 sec/batch
Epoch: 7/20...  Training Step: 1268...  Training loss: 1.5364...  0.3074 sec/batch
Epoch: 7/20...  Training Step: 1269...  Training loss: 1.4984...  0.3074 sec/batch
Epoch: 7/20...  Training Step: 1270...  Training loss: 1.5534...  0.3077 sec/batch
Epoch: 7/20...  Training Step: 1271...  Training loss: 1.5055...  0.3095 sec/batch
Epoch: 7/20...  Training Step: 1272...  Training loss: 1.5368...  0.3074 sec/batch
Epoch: 7/20...  Training Step: 1273...  Training loss: 1.5198...  0.3085 sec/batch
Epoch: 7/20...  Training Step: 1274...  Training loss: 1.5260...  0.3077 sec/batch
Epoch: 7/20...  Training Step: 1275...  Training loss: 1.5159...  0.3085 sec/batch
Epoch: 7/20...  Training Step: 1276...  Training loss: 1.5171...  0.3080 sec/batch
Epoch: 7/20...  Training Step: 1277...  Training loss: 1.5010...  0.3087 sec/batch
Epoch: 7/20...  Training Step: 1278...  Training loss: 1.5506...  0.3078 sec/batch
Epoch: 7/20...  Training Step: 1279...  Training loss: 1.5055...  0.3072 sec/batch
Epoch: 7/20...  Training Step: 1280...  Training loss: 1.5215...  0.3080 sec/batch
Epoch: 7/20...  Training Step: 1281...  Training loss: 1.5057...  0.3085 sec/batch
Epoch: 7/20...  Training Step: 1282...  Training loss: 1.5090...  0.3079 sec/batch
Epoch: 7/20...  Training Step: 1283...  Training loss: 1.5154...  0.3079 sec/batch
Epoch: 7/20...  Training Step: 1284...  Training loss: 1.5455...  0.3067 sec/batch
Epoch: 7/20...  Training Step: 1285...  Training loss: 1.5333...  0.3074 sec/batch
Epoch: 7/20...  Training Step: 1286...  Training loss: 1.4914...  0.3086 sec/batch
Epoch: 7/20...  Training Step: 1287...  Training loss: 1.5099...  0.3072 sec/batch
Epoch: 7/20...  Training Step: 1288...  Training loss: 1.5035...  0.3075 sec/batch
Epoch: 7/20...  Training Step: 1289...  Training loss: 1.5322...  0.3074 sec/batch
Epoch: 7/20...  Training Step: 1290...  Training loss: 1.5148...  0.3075 sec/batch
Epoch: 7/20...  Training Step: 1291...  Training loss: 1.5230...  0.3071 sec/batch
Epoch: 7/20...  Training Step: 1292...  Training loss: 1.5202...  0.3065 sec/batch
Epoch: 7/20...  Training Step: 1293...  Training loss: 1.5179...  0.3078 sec/batch
Epoch: 7/20...  Training Step: 1294...  Training loss: 1.5245...  0.3073 sec/batch
Epoch: 7/20...  Training Step: 1295...  Training loss: 1.5230...  0.3079 sec/batch
Epoch: 7/20...  Training Step: 1296...  Training loss: 1.5246...  0.3085 sec/batch
Epoch: 7/20...  Training Step: 1297...  Training loss: 1.5343...  0.3073 sec/batch
Epoch: 7/20...  Training Step: 1298...  Training loss: 1.5560...  0.3078 sec/batch
Epoch: 7/20...  Training Step: 1299...  Training loss: 1.5104...  0.3076 sec/batch
Epoch: 7/20...  Training Step: 1300...  Training loss: 1.5316...  0.3143 sec/batch
Epoch: 7/20...  Training Step: 1301...  Training loss: 1.5157...  0.3082 sec/batch
Epoch: 7/20...  Training Step: 1302...  Training loss: 1.5066...  0.3080 sec/batch
Epoch: 7/20...  Training Step: 1303...  Training loss: 1.5028...  0.3077 sec/batch
Epoch: 7/20...  Training Step: 1304...  Training loss: 1.4895...  0.3088 sec/batch
Epoch: 7/20...  Training Step: 1305...  Training loss: 1.5290...  0.3082 sec/batch
Epoch: 7/20...  Training Step: 1306...  Training loss: 1.5327...  0.3083 sec/batch
Epoch: 7/20...  Training Step: 1307...  Training loss: 1.5103...  0.3091 sec/batch
Epoch: 7/20...  Training Step: 1308...  Training loss: 1.5218...  0.3081 sec/batch
Epoch: 7/20...  Training Step: 1309...  Training loss: 1.5132...  0.3081 sec/batch
Epoch: 7/20...  Training Step: 1310...  Training loss: 1.4820...  0.3078 sec/batch
Epoch: 7/20...  Training Step: 1311...  Training loss: 1.4798...  0.3082 sec/batch
Epoch: 7/20...  Training Step: 1312...  Training loss: 1.5308...  0.3085 sec/batch
Epoch: 7/20...  Training Step: 1313...  Training loss: 1.5164...  0.3083 sec/batch
Epoch: 7/20...  Training Step: 1314...  Training loss: 1.4757...  0.3079 sec/batch
Epoch: 7/20...  Training Step: 1315...  Training loss: 1.5413...  0.3075 sec/batch
Epoch: 7/20...  Training Step: 1316...  Training loss: 1.5279...  0.3075 sec/batch
Epoch: 7/20...  Training Step: 1317...  Training loss: 1.5106...  0.3078 sec/batch
Epoch: 7/20...  Training Step: 1318...  Training loss: 1.4977...  0.3073 sec/batch
Epoch: 7/20...  Training Step: 1319...  Training loss: 1.4752...  0.3082 sec/batch
Epoch: 7/20...  Training Step: 1320...  Training loss: 1.4927...  0.3080 sec/batch
Epoch: 7/20...  Training Step: 1321...  Training loss: 1.5285...  0.3079 sec/batch
Epoch: 7/20...  Training Step: 1322...  Training loss: 1.5374...  0.3078 sec/batch
Epoch: 7/20...  Training Step: 1323...  Training loss: 1.5272...  0.3086 sec/batch
Epoch: 7/20...  Training Step: 1324...  Training loss: 1.5270...  0.3084 sec/batch
Epoch: 7/20...  Training Step: 1325...  Training loss: 1.5478...  0.3082 sec/batch
Epoch: 7/20...  Training Step: 1326...  Training loss: 1.5370...  0.3077 sec/batch
Epoch: 7/20...  Training Step: 1327...  Training loss: 1.5340...  0.3083 sec/batch
Epoch: 7/20...  Training Step: 1328...  Training loss: 1.5244...  0.3084 sec/batch
Epoch: 7/20...  Training Step: 1329...  Training loss: 1.5816...  0.3080 sec/batch
Epoch: 7/20...  Training Step: 1330...  Training loss: 1.5114...  0.3079 sec/batch
Epoch: 7/20...  Training Step: 1331...  Training loss: 1.5152...  0.3089 sec/batch
Epoch: 7/20...  Training Step: 1332...  Training loss: 1.5526...  0.3122 sec/batch
Epoch: 7/20...  Training Step: 1333...  Training loss: 1.5165...  0.3079 sec/batch
Epoch: 7/20...  Training Step: 1334...  Training loss: 1.5410...  0.3087 sec/batch
Epoch: 7/20...  Training Step: 1335...  Training loss: 1.5260...  0.3080 sec/batch
Epoch: 7/20...  Training Step: 1336...  Training loss: 1.5555...  0.3078 sec/batch
Epoch: 7/20...  Training Step: 1337...  Training loss: 1.5391...  0.3095 sec/batch
Epoch: 7/20...  Training Step: 1338...  Training loss: 1.5031...  0.3073 sec/batch
Epoch: 7/20...  Training Step: 1339...  Training loss: 1.4829...  0.3075 sec/batch
Epoch: 7/20...  Training Step: 1340...  Training loss: 1.5154...  0.3078 sec/batch
Epoch: 7/20...  Training Step: 1341...  Training loss: 1.5252...  0.3082 sec/batch
Epoch: 7/20...  Training Step: 1342...  Training loss: 1.5071...  0.3079 sec/batch
Epoch: 7/20...  Training Step: 1343...  Training loss: 1.5086...  0.3071 sec/batch
Epoch: 7/20...  Training Step: 1344...  Training loss: 1.5121...  0.3091 sec/batch
Epoch: 7/20...  Training Step: 1345...  Training loss: 1.5196...  0.3088 sec/batch
Epoch: 7/20...  Training Step: 1346...  Training loss: 1.5129...  0.3086 sec/batch
Epoch: 7/20...  Training Step: 1347...  Training loss: 1.4813...  0.3078 sec/batch
Epoch: 7/20...  Training Step: 1348...  Training loss: 1.5342...  0.3072 sec/batch
Epoch: 7/20...  Training Step: 1349...  Training loss: 1.5502...  0.3089 sec/batch
Epoch: 7/20...  Training Step: 1350...  Training loss: 1.5335...  0.3084 sec/batch
Epoch: 7/20...  Training Step: 1351...  Training loss: 1.5372...  0.3073 sec/batch
Epoch: 7/20...  Training Step: 1352...  Training loss: 1.5354...  0.3087 sec/batch
Epoch: 7/20...  Training Step: 1353...  Training loss: 1.5150...  0.3081 sec/batch
Epoch: 7/20...  Training Step: 1354...  Training loss: 1.5099...  0.3080 sec/batch
Epoch: 7/20...  Training Step: 1355...  Training loss: 1.5409...  0.3095 sec/batch
Epoch: 7/20...  Training Step: 1356...  Training loss: 1.5853...  0.3090 sec/batch
Epoch: 7/20...  Training Step: 1357...  Training loss: 1.5205...  0.3092 sec/batch
Epoch: 7/20...  Training Step: 1358...  Training loss: 1.5117...  0.3082 sec/batch
Epoch: 7/20...  Training Step: 1359...  Training loss: 1.5039...  0.3092 sec/batch
Epoch: 7/20...  Training Step: 1360...  Training loss: 1.4914...  0.3089 sec/batch
Epoch: 7/20...  Training Step: 1361...  Training loss: 1.5396...  0.3086 sec/batch
Epoch: 7/20...  Training Step: 1362...  Training loss: 1.5205...  0.3086 sec/batch
Epoch: 7/20...  Training Step: 1363...  Training loss: 1.5313...  0.3090 sec/batch
Epoch: 7/20...  Training Step: 1364...  Training loss: 1.4996...  0.3088 sec/batch
Epoch: 7/20...  Training Step: 1365...  Training loss: 1.4932...  0.3089 sec/batch
Epoch: 7/20...  Training Step: 1366...  Training loss: 1.5349...  0.3085 sec/batch
Epoch: 7/20...  Training Step: 1367...  Training loss: 1.4986...  0.3085 sec/batch
Epoch: 7/20...  Training Step: 1368...  Training loss: 1.4780...  0.3091 sec/batch
Epoch: 7/20...  Training Step: 1369...  Training loss: 1.4823...  0.3083 sec/batch
Epoch: 7/20...  Training Step: 1370...  Training loss: 1.5109...  0.3095 sec/batch
Epoch: 7/20...  Training Step: 1371...  Training loss: 1.5147...  0.3073 sec/batch
Epoch: 7/20...  Training Step: 1372...  Training loss: 1.5087...  0.3080 sec/batch
Epoch: 7/20...  Training Step: 1373...  Training loss: 1.5052...  0.3079 sec/batch
Epoch: 7/20...  Training Step: 1374...  Training loss: 1.4844...  0.3102 sec/batch
Epoch: 7/20...  Training Step: 1375...  Training loss: 1.5393...  0.3082 sec/batch
Epoch: 7/20...  Training Step: 1376...  Training loss: 1.4999...  0.3076 sec/batch
Epoch: 7/20...  Training Step: 1377...  Training loss: 1.5029...  0.3081 sec/batch
Epoch: 7/20...  Training Step: 1378...  Training loss: 1.5133...  0.3082 sec/batch
Epoch: 7/20...  Training Step: 1379...  Training loss: 1.4996...  0.3080 sec/batch
Epoch: 7/20...  Training Step: 1380...  Training loss: 1.4869...  0.3086 sec/batch
Epoch: 7/20...  Training Step: 1381...  Training loss: 1.4989...  0.3075 sec/batch
Epoch: 7/20...  Training Step: 1382...  Training loss: 1.4869...  0.3080 sec/batch
Epoch: 7/20...  Training Step: 1383...  Training loss: 1.4722...  0.3081 sec/batch
Epoch: 7/20...  Training Step: 1384...  Training loss: 1.5174...  0.3076 sec/batch
Epoch: 7/20...  Training Step: 1385...  Training loss: 1.5028...  0.3091 sec/batch
Epoch: 7/20...  Training Step: 1386...  Training loss: 1.4857...  0.3078 sec/batch
(1980000,)
(100, 19800)
Epoch: 8/20...  Training Step: 1387...  Training loss: 1.6677...  0.3073 sec/batch
Epoch: 8/20...  Training Step: 1388...  Training loss: 1.5057...  0.3088 sec/batch
Epoch: 8/20...  Training Step: 1389...  Training loss: 1.5065...  0.3099 sec/batch
Epoch: 8/20...  Training Step: 1390...  Training loss: 1.5196...  0.3078 sec/batch
Epoch: 8/20...  Training Step: 1391...  Training loss: 1.4905...  0.3082 sec/batch
Epoch: 8/20...  Training Step: 1392...  Training loss: 1.4761...  0.3081 sec/batch
Epoch: 8/20...  Training Step: 1393...  Training loss: 1.5083...  0.3078 sec/batch
Epoch: 8/20...  Training Step: 1394...  Training loss: 1.4906...  0.3082 sec/batch
Epoch: 8/20...  Training Step: 1395...  Training loss: 1.5220...  0.3083 sec/batch
Epoch: 8/20...  Training Step: 1396...  Training loss: 1.4938...  0.3087 sec/batch
Epoch: 8/20...  Training Step: 1397...  Training loss: 1.4856...  0.3112 sec/batch
Epoch: 8/20...  Training Step: 1398...  Training loss: 1.4943...  0.3082 sec/batch
Epoch: 8/20...  Training Step: 1399...  Training loss: 1.5096...  0.3085 sec/batch
Epoch: 8/20...  Training Step: 1400...  Training loss: 1.5313...  0.3071 sec/batch
Epoch: 8/20...  Training Step: 1401...  Training loss: 1.5019...  0.3077 sec/batch
Epoch: 8/20...  Training Step: 1402...  Training loss: 1.4827...  0.3081 sec/batch
Epoch: 8/20...  Training Step: 1403...  Training loss: 1.5076...  0.3078 sec/batch
Epoch: 8/20...  Training Step: 1404...  Training loss: 1.5299...  0.3077 sec/batch
Epoch: 8/20...  Training Step: 1405...  Training loss: 1.5028...  0.3077 sec/batch
Epoch: 8/20...  Training Step: 1406...  Training loss: 1.5242...  0.3079 sec/batch
Epoch: 8/20...  Training Step: 1407...  Training loss: 1.4890...  0.3098 sec/batch
Epoch: 8/20...  Training Step: 1408...  Training loss: 1.5221...  0.3086 sec/batch
Epoch: 8/20...  Training Step: 1409...  Training loss: 1.4880...  0.3081 sec/batch
Epoch: 8/20...  Training Step: 1410...  Training loss: 1.5097...  0.3078 sec/batch
Epoch: 8/20...  Training Step: 1411...  Training loss: 1.5018...  0.3081 sec/batch
Epoch: 8/20...  Training Step: 1412...  Training loss: 1.4623...  0.3082 sec/batch
Epoch: 8/20...  Training Step: 1413...  Training loss: 1.4659...  0.3083 sec/batch
Epoch: 8/20...  Training Step: 1414...  Training loss: 1.5263...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1415...  Training loss: 1.5127...  0.3088 sec/batch
Epoch: 8/20...  Training Step: 1416...  Training loss: 1.5046...  0.3076 sec/batch
Epoch: 8/20...  Training Step: 1417...  Training loss: 1.4951...  0.3085 sec/batch
Epoch: 8/20...  Training Step: 1418...  Training loss: 1.4641...  0.3083 sec/batch
Epoch: 8/20...  Training Step: 1419...  Training loss: 1.5129...  0.3085 sec/batch
Epoch: 8/20...  Training Step: 1420...  Training loss: 1.5098...  0.3085 sec/batch
Epoch: 8/20...  Training Step: 1421...  Training loss: 1.4935...  0.3078 sec/batch
Epoch: 8/20...  Training Step: 1422...  Training loss: 1.4919...  0.3087 sec/batch
Epoch: 8/20...  Training Step: 1423...  Training loss: 1.4677...  0.3085 sec/batch
Epoch: 8/20...  Training Step: 1424...  Training loss: 1.4476...  0.3107 sec/batch
Epoch: 8/20...  Training Step: 1425...  Training loss: 1.4418...  0.3082 sec/batch
Epoch: 8/20...  Training Step: 1426...  Training loss: 1.4737...  0.3076 sec/batch
Epoch: 8/20...  Training Step: 1427...  Training loss: 1.4706...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1428...  Training loss: 1.5184...  0.3089 sec/batch
Epoch: 8/20...  Training Step: 1429...  Training loss: 1.4741...  0.3073 sec/batch
Epoch: 8/20...  Training Step: 1430...  Training loss: 1.4650...  0.3086 sec/batch
Epoch: 8/20...  Training Step: 1431...  Training loss: 1.4988...  0.3078 sec/batch
Epoch: 8/20...  Training Step: 1432...  Training loss: 1.4578...  0.3087 sec/batch
Epoch: 8/20...  Training Step: 1433...  Training loss: 1.4770...  0.3079 sec/batch
Epoch: 8/20...  Training Step: 1434...  Training loss: 1.4826...  0.3145 sec/batch
Epoch: 8/20...  Training Step: 1435...  Training loss: 1.4788...  0.3082 sec/batch
Epoch: 8/20...  Training Step: 1436...  Training loss: 1.5129...  0.3092 sec/batch
Epoch: 8/20...  Training Step: 1437...  Training loss: 1.4540...  0.3081 sec/batch
Epoch: 8/20...  Training Step: 1438...  Training loss: 1.5287...  0.3086 sec/batch
Epoch: 8/20...  Training Step: 1439...  Training loss: 1.4929...  0.3071 sec/batch
Epoch: 8/20...  Training Step: 1440...  Training loss: 1.5006...  0.3079 sec/batch
Epoch: 8/20...  Training Step: 1441...  Training loss: 1.4830...  0.3074 sec/batch
Epoch: 8/20...  Training Step: 1442...  Training loss: 1.4826...  0.3072 sec/batch
Epoch: 8/20...  Training Step: 1443...  Training loss: 1.5147...  0.3085 sec/batch
Epoch: 8/20...  Training Step: 1444...  Training loss: 1.4855...  0.3072 sec/batch
Epoch: 8/20...  Training Step: 1445...  Training loss: 1.4664...  0.3089 sec/batch
Epoch: 8/20...  Training Step: 1446...  Training loss: 1.5219...  0.3080 sec/batch
Epoch: 8/20...  Training Step: 1447...  Training loss: 1.4912...  0.3087 sec/batch
Epoch: 8/20...  Training Step: 1448...  Training loss: 1.5467...  0.3074 sec/batch
Epoch: 8/20...  Training Step: 1449...  Training loss: 1.5384...  0.3083 sec/batch
Epoch: 8/20...  Training Step: 1450...  Training loss: 1.5078...  0.3079 sec/batch
Epoch: 8/20...  Training Step: 1451...  Training loss: 1.4870...  0.3086 sec/batch
Epoch: 8/20...  Training Step: 1452...  Training loss: 1.5063...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1453...  Training loss: 1.5065...  0.3077 sec/batch
Epoch: 8/20...  Training Step: 1454...  Training loss: 1.4780...  0.3091 sec/batch
Epoch: 8/20...  Training Step: 1455...  Training loss: 1.4926...  0.3088 sec/batch
Epoch: 8/20...  Training Step: 1456...  Training loss: 1.4789...  0.3089 sec/batch
Epoch: 8/20...  Training Step: 1457...  Training loss: 1.5246...  0.3079 sec/batch
Epoch: 8/20...  Training Step: 1458...  Training loss: 1.5119...  0.3081 sec/batch
Epoch: 8/20...  Training Step: 1459...  Training loss: 1.5257...  0.3082 sec/batch
Epoch: 8/20...  Training Step: 1460...  Training loss: 1.4680...  0.3080 sec/batch
Epoch: 8/20...  Training Step: 1461...  Training loss: 1.4859...  0.3085 sec/batch
Epoch: 8/20...  Training Step: 1462...  Training loss: 1.5130...  0.3069 sec/batch
Epoch: 8/20...  Training Step: 1463...  Training loss: 1.4718...  0.3080 sec/batch
Epoch: 8/20...  Training Step: 1464...  Training loss: 1.4676...  0.3077 sec/batch
Epoch: 8/20...  Training Step: 1465...  Training loss: 1.4406...  0.3072 sec/batch
Epoch: 8/20...  Training Step: 1466...  Training loss: 1.4903...  0.3070 sec/batch
Epoch: 8/20...  Training Step: 1467...  Training loss: 1.4428...  0.3073 sec/batch
Epoch: 8/20...  Training Step: 1468...  Training loss: 1.4979...  0.3079 sec/batch
Epoch: 8/20...  Training Step: 1469...  Training loss: 1.4485...  0.3077 sec/batch
Epoch: 8/20...  Training Step: 1470...  Training loss: 1.4795...  0.3079 sec/batch
Epoch: 8/20...  Training Step: 1471...  Training loss: 1.4666...  0.3081 sec/batch
Epoch: 8/20...  Training Step: 1472...  Training loss: 1.4667...  0.3077 sec/batch
Epoch: 8/20...  Training Step: 1473...  Training loss: 1.4557...  0.3079 sec/batch
Epoch: 8/20...  Training Step: 1474...  Training loss: 1.4716...  0.3085 sec/batch
Epoch: 8/20...  Training Step: 1475...  Training loss: 1.4463...  0.3078 sec/batch
Epoch: 8/20...  Training Step: 1476...  Training loss: 1.4896...  0.3084 sec/batch
Epoch: 8/20...  Training Step: 1477...  Training loss: 1.4583...  0.3082 sec/batch
Epoch: 8/20...  Training Step: 1478...  Training loss: 1.4655...  0.3083 sec/batch
Epoch: 8/20...  Training Step: 1479...  Training loss: 1.4566...  0.3074 sec/batch
Epoch: 8/20...  Training Step: 1480...  Training loss: 1.4535...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1481...  Training loss: 1.4524...  0.3079 sec/batch
Epoch: 8/20...  Training Step: 1482...  Training loss: 1.4896...  0.3078 sec/batch
Epoch: 8/20...  Training Step: 1483...  Training loss: 1.4825...  0.3080 sec/batch
Epoch: 8/20...  Training Step: 1484...  Training loss: 1.4484...  0.3076 sec/batch
Epoch: 8/20...  Training Step: 1485...  Training loss: 1.4538...  0.3074 sec/batch
Epoch: 8/20...  Training Step: 1486...  Training loss: 1.4420...  0.3083 sec/batch
Epoch: 8/20...  Training Step: 1487...  Training loss: 1.4794...  0.3071 sec/batch
Epoch: 8/20...  Training Step: 1488...  Training loss: 1.4702...  0.3081 sec/batch
Epoch: 8/20...  Training Step: 1489...  Training loss: 1.4749...  0.3093 sec/batch
Epoch: 8/20...  Training Step: 1490...  Training loss: 1.4732...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1491...  Training loss: 1.4619...  0.3089 sec/batch
Epoch: 8/20...  Training Step: 1492...  Training loss: 1.4647...  0.3079 sec/batch
Epoch: 8/20...  Training Step: 1493...  Training loss: 1.4751...  0.3076 sec/batch
Epoch: 8/20...  Training Step: 1494...  Training loss: 1.4892...  0.3083 sec/batch
Epoch: 8/20...  Training Step: 1495...  Training loss: 1.4704...  0.3088 sec/batch
Epoch: 8/20...  Training Step: 1496...  Training loss: 1.4984...  0.3090 sec/batch
Epoch: 8/20...  Training Step: 1497...  Training loss: 1.4757...  0.3077 sec/batch
Epoch: 8/20...  Training Step: 1498...  Training loss: 1.4812...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1499...  Training loss: 1.4699...  0.3072 sec/batch
Epoch: 8/20...  Training Step: 1500...  Training loss: 1.4584...  0.3074 sec/batch
Epoch: 8/20...  Training Step: 1501...  Training loss: 1.4603...  0.3081 sec/batch
Epoch: 8/20...  Training Step: 1502...  Training loss: 1.4393...  0.3080 sec/batch
Epoch: 8/20...  Training Step: 1503...  Training loss: 1.4717...  0.3070 sec/batch
Epoch: 8/20...  Training Step: 1504...  Training loss: 1.4756...  0.3073 sec/batch
Epoch: 8/20...  Training Step: 1505...  Training loss: 1.4550...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1506...  Training loss: 1.4613...  0.3084 sec/batch
Epoch: 8/20...  Training Step: 1507...  Training loss: 1.4742...  0.3082 sec/batch
Epoch: 8/20...  Training Step: 1508...  Training loss: 1.4393...  0.3080 sec/batch
Epoch: 8/20...  Training Step: 1509...  Training loss: 1.4332...  0.3083 sec/batch
Epoch: 8/20...  Training Step: 1510...  Training loss: 1.4803...  0.3083 sec/batch
Epoch: 8/20...  Training Step: 1511...  Training loss: 1.4635...  0.3081 sec/batch
Epoch: 8/20...  Training Step: 1512...  Training loss: 1.4259...  0.3082 sec/batch
Epoch: 8/20...  Training Step: 1513...  Training loss: 1.4932...  0.3084 sec/batch
Epoch: 8/20...  Training Step: 1514...  Training loss: 1.4804...  0.3073 sec/batch
Epoch: 8/20...  Training Step: 1515...  Training loss: 1.4615...  0.3092 sec/batch
Epoch: 8/20...  Training Step: 1516...  Training loss: 1.4432...  0.3079 sec/batch
Epoch: 8/20...  Training Step: 1517...  Training loss: 1.4335...  0.3081 sec/batch
Epoch: 8/20...  Training Step: 1518...  Training loss: 1.4403...  0.3079 sec/batch
Epoch: 8/20...  Training Step: 1519...  Training loss: 1.4918...  0.3081 sec/batch
Epoch: 8/20...  Training Step: 1520...  Training loss: 1.4746...  0.3078 sec/batch
Epoch: 8/20...  Training Step: 1521...  Training loss: 1.4779...  0.3078 sec/batch
Epoch: 8/20...  Training Step: 1522...  Training loss: 1.4670...  0.3081 sec/batch
Epoch: 8/20...  Training Step: 1523...  Training loss: 1.4905...  0.3090 sec/batch
Epoch: 8/20...  Training Step: 1524...  Training loss: 1.4710...  0.3080 sec/batch
Epoch: 8/20...  Training Step: 1525...  Training loss: 1.4722...  0.3076 sec/batch
Epoch: 8/20...  Training Step: 1526...  Training loss: 1.4651...  0.3080 sec/batch
Epoch: 8/20...  Training Step: 1527...  Training loss: 1.5270...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1528...  Training loss: 1.4670...  0.3085 sec/batch
Epoch: 8/20...  Training Step: 1529...  Training loss: 1.4677...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1530...  Training loss: 1.4991...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1531...  Training loss: 1.4503...  0.3077 sec/batch
Epoch: 8/20...  Training Step: 1532...  Training loss: 1.4913...  0.3082 sec/batch
Epoch: 8/20...  Training Step: 1533...  Training loss: 1.4713...  0.3077 sec/batch
Epoch: 8/20...  Training Step: 1534...  Training loss: 1.5006...  0.3073 sec/batch
Epoch: 8/20...  Training Step: 1535...  Training loss: 1.4978...  0.3074 sec/batch
Epoch: 8/20...  Training Step: 1536...  Training loss: 1.4635...  0.3087 sec/batch
Epoch: 8/20...  Training Step: 1537...  Training loss: 1.4372...  0.3087 sec/batch
Epoch: 8/20...  Training Step: 1538...  Training loss: 1.4540...  0.3088 sec/batch
Epoch: 8/20...  Training Step: 1539...  Training loss: 1.4825...  0.3087 sec/batch
Epoch: 8/20...  Training Step: 1540...  Training loss: 1.4605...  0.3072 sec/batch
Epoch: 8/20...  Training Step: 1541...  Training loss: 1.4632...  0.3089 sec/batch
Epoch: 8/20...  Training Step: 1542...  Training loss: 1.4697...  0.3076 sec/batch
Epoch: 8/20...  Training Step: 1543...  Training loss: 1.4678...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1544...  Training loss: 1.4635...  0.3085 sec/batch
Epoch: 8/20...  Training Step: 1545...  Training loss: 1.4344...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1546...  Training loss: 1.4862...  0.3082 sec/batch
Epoch: 8/20...  Training Step: 1547...  Training loss: 1.4951...  0.3074 sec/batch
Epoch: 8/20...  Training Step: 1548...  Training loss: 1.4635...  0.3088 sec/batch
Epoch: 8/20...  Training Step: 1549...  Training loss: 1.4576...  0.3076 sec/batch
Epoch: 8/20...  Training Step: 1550...  Training loss: 1.4700...  0.3077 sec/batch
Epoch: 8/20...  Training Step: 1551...  Training loss: 1.4610...  0.3087 sec/batch
Epoch: 8/20...  Training Step: 1552...  Training loss: 1.4604...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1553...  Training loss: 1.4757...  0.3076 sec/batch
Epoch: 8/20...  Training Step: 1554...  Training loss: 1.5383...  0.3073 sec/batch
Epoch: 8/20...  Training Step: 1555...  Training loss: 1.4598...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1556...  Training loss: 1.4593...  0.3082 sec/batch
Epoch: 8/20...  Training Step: 1557...  Training loss: 1.4570...  0.3114 sec/batch
Epoch: 8/20...  Training Step: 1558...  Training loss: 1.4433...  0.3076 sec/batch
Epoch: 8/20...  Training Step: 1559...  Training loss: 1.4949...  0.3082 sec/batch
Epoch: 8/20...  Training Step: 1560...  Training loss: 1.4700...  0.3045 sec/batch
Epoch: 8/20...  Training Step: 1561...  Training loss: 1.4800...  0.3085 sec/batch
Epoch: 8/20...  Training Step: 1562...  Training loss: 1.4418...  0.3071 sec/batch
Epoch: 8/20...  Training Step: 1563...  Training loss: 1.4430...  0.3077 sec/batch
Epoch: 8/20...  Training Step: 1564...  Training loss: 1.4947...  0.3072 sec/batch
Epoch: 8/20...  Training Step: 1565...  Training loss: 1.4399...  0.3080 sec/batch
Epoch: 8/20...  Training Step: 1566...  Training loss: 1.4235...  0.3070 sec/batch
Epoch: 8/20...  Training Step: 1567...  Training loss: 1.4214...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1568...  Training loss: 1.4535...  0.3072 sec/batch
Epoch: 8/20...  Training Step: 1569...  Training loss: 1.4648...  0.3080 sec/batch
Epoch: 8/20...  Training Step: 1570...  Training loss: 1.4563...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1571...  Training loss: 1.4418...  0.3077 sec/batch
Epoch: 8/20...  Training Step: 1572...  Training loss: 1.4438...  0.3071 sec/batch
Epoch: 8/20...  Training Step: 1573...  Training loss: 1.4794...  0.3090 sec/batch
Epoch: 8/20...  Training Step: 1574...  Training loss: 1.4359...  0.3074 sec/batch
Epoch: 8/20...  Training Step: 1575...  Training loss: 1.4514...  0.3074 sec/batch
Epoch: 8/20...  Training Step: 1576...  Training loss: 1.4582...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1577...  Training loss: 1.4393...  0.3079 sec/batch
Epoch: 8/20...  Training Step: 1578...  Training loss: 1.4472...  0.3080 sec/batch
Epoch: 8/20...  Training Step: 1579...  Training loss: 1.4499...  0.3074 sec/batch
Epoch: 8/20...  Training Step: 1580...  Training loss: 1.4361...  0.3074 sec/batch
Epoch: 8/20...  Training Step: 1581...  Training loss: 1.4239...  0.3075 sec/batch
Epoch: 8/20...  Training Step: 1582...  Training loss: 1.4778...  0.3089 sec/batch
Epoch: 8/20...  Training Step: 1583...  Training loss: 1.4381...  0.3080 sec/batch
Epoch: 8/20...  Training Step: 1584...  Training loss: 1.4455...  0.3078 sec/batch
(1980000,)
(100, 19800)
Epoch: 9/20...  Training Step: 1585...  Training loss: 1.6525...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1586...  Training loss: 1.4778...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1587...  Training loss: 1.4501...  0.3082 sec/batch
Epoch: 9/20...  Training Step: 1588...  Training loss: 1.4783...  0.3084 sec/batch
Epoch: 9/20...  Training Step: 1589...  Training loss: 1.4334...  0.3100 sec/batch
Epoch: 9/20...  Training Step: 1590...  Training loss: 1.4307...  0.3081 sec/batch
Epoch: 9/20...  Training Step: 1591...  Training loss: 1.4645...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1592...  Training loss: 1.4549...  0.3082 sec/batch
Epoch: 9/20...  Training Step: 1593...  Training loss: 1.4668...  0.3082 sec/batch
Epoch: 9/20...  Training Step: 1594...  Training loss: 1.4620...  0.3080 sec/batch
Epoch: 9/20...  Training Step: 1595...  Training loss: 1.4347...  0.3080 sec/batch
Epoch: 9/20...  Training Step: 1596...  Training loss: 1.4488...  0.3073 sec/batch
Epoch: 9/20...  Training Step: 1597...  Training loss: 1.4633...  0.3078 sec/batch
Epoch: 9/20...  Training Step: 1598...  Training loss: 1.4828...  0.3073 sec/batch
Epoch: 9/20...  Training Step: 1599...  Training loss: 1.4598...  0.3071 sec/batch
Epoch: 9/20...  Training Step: 1600...  Training loss: 1.4322...  0.3094 sec/batch
Epoch: 9/20...  Training Step: 1601...  Training loss: 1.4729...  0.3072 sec/batch
Epoch: 9/20...  Training Step: 1602...  Training loss: 1.4792...  0.3073 sec/batch
Epoch: 9/20...  Training Step: 1603...  Training loss: 1.4629...  0.3075 sec/batch
Epoch: 9/20...  Training Step: 1604...  Training loss: 1.4805...  0.3072 sec/batch
Epoch: 9/20...  Training Step: 1605...  Training loss: 1.4396...  0.3094 sec/batch
Epoch: 9/20...  Training Step: 1606...  Training loss: 1.4714...  0.3071 sec/batch
Epoch: 9/20...  Training Step: 1607...  Training loss: 1.4488...  0.3081 sec/batch
Epoch: 9/20...  Training Step: 1608...  Training loss: 1.4641...  0.3075 sec/batch
Epoch: 9/20...  Training Step: 1609...  Training loss: 1.4600...  0.3073 sec/batch
Epoch: 9/20...  Training Step: 1610...  Training loss: 1.4102...  0.3075 sec/batch
Epoch: 9/20...  Training Step: 1611...  Training loss: 1.4241...  0.3082 sec/batch
Epoch: 9/20...  Training Step: 1612...  Training loss: 1.4717...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1613...  Training loss: 1.4711...  0.3073 sec/batch
Epoch: 9/20...  Training Step: 1614...  Training loss: 1.4647...  0.3074 sec/batch
Epoch: 9/20...  Training Step: 1615...  Training loss: 1.4424...  0.3087 sec/batch
Epoch: 9/20...  Training Step: 1616...  Training loss: 1.4230...  0.3082 sec/batch
Epoch: 9/20...  Training Step: 1617...  Training loss: 1.4609...  0.3089 sec/batch
Epoch: 9/20...  Training Step: 1618...  Training loss: 1.4583...  0.3082 sec/batch
Epoch: 9/20...  Training Step: 1619...  Training loss: 1.4374...  0.3074 sec/batch
Epoch: 9/20...  Training Step: 1620...  Training loss: 1.4488...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1621...  Training loss: 1.4327...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1622...  Training loss: 1.4004...  0.3090 sec/batch
Epoch: 9/20...  Training Step: 1623...  Training loss: 1.4031...  0.3088 sec/batch
Epoch: 9/20...  Training Step: 1624...  Training loss: 1.4157...  0.3075 sec/batch
Epoch: 9/20...  Training Step: 1625...  Training loss: 1.4311...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1626...  Training loss: 1.4784...  0.3082 sec/batch
Epoch: 9/20...  Training Step: 1627...  Training loss: 1.4254...  0.3095 sec/batch
Epoch: 9/20...  Training Step: 1628...  Training loss: 1.4181...  0.3069 sec/batch
Epoch: 9/20...  Training Step: 1629...  Training loss: 1.4509...  0.3072 sec/batch
Epoch: 9/20...  Training Step: 1630...  Training loss: 1.4134...  0.3081 sec/batch
Epoch: 9/20...  Training Step: 1631...  Training loss: 1.4402...  0.3081 sec/batch
Epoch: 9/20...  Training Step: 1632...  Training loss: 1.4327...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1633...  Training loss: 1.4340...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1634...  Training loss: 1.4753...  0.3069 sec/batch
Epoch: 9/20...  Training Step: 1635...  Training loss: 1.4266...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1636...  Training loss: 1.4918...  0.3081 sec/batch
Epoch: 9/20...  Training Step: 1637...  Training loss: 1.4466...  0.3097 sec/batch
Epoch: 9/20...  Training Step: 1638...  Training loss: 1.4514...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1639...  Training loss: 1.4545...  0.3072 sec/batch
Epoch: 9/20...  Training Step: 1640...  Training loss: 1.4477...  0.3071 sec/batch
Epoch: 9/20...  Training Step: 1641...  Training loss: 1.4749...  0.3074 sec/batch
Epoch: 9/20...  Training Step: 1642...  Training loss: 1.4419...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1643...  Training loss: 1.4306...  0.3075 sec/batch
Epoch: 9/20...  Training Step: 1644...  Training loss: 1.4783...  0.3080 sec/batch
Epoch: 9/20...  Training Step: 1645...  Training loss: 1.4498...  0.3086 sec/batch
Epoch: 9/20...  Training Step: 1646...  Training loss: 1.4992...  0.3081 sec/batch
Epoch: 9/20...  Training Step: 1647...  Training loss: 1.4782...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1648...  Training loss: 1.4473...  0.3075 sec/batch
Epoch: 9/20...  Training Step: 1649...  Training loss: 1.4437...  0.3073 sec/batch
Epoch: 9/20...  Training Step: 1650...  Training loss: 1.4556...  0.3080 sec/batch
Epoch: 9/20...  Training Step: 1651...  Training loss: 1.4581...  0.3075 sec/batch
Epoch: 9/20...  Training Step: 1652...  Training loss: 1.4282...  0.3053 sec/batch
Epoch: 9/20...  Training Step: 1653...  Training loss: 1.4431...  0.3069 sec/batch
Epoch: 9/20...  Training Step: 1654...  Training loss: 1.4242...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1655...  Training loss: 1.4949...  0.3087 sec/batch
Epoch: 9/20...  Training Step: 1656...  Training loss: 1.4591...  0.3074 sec/batch
Epoch: 9/20...  Training Step: 1657...  Training loss: 1.4808...  0.3090 sec/batch
Epoch: 9/20...  Training Step: 1658...  Training loss: 1.4280...  0.3078 sec/batch
Epoch: 9/20...  Training Step: 1659...  Training loss: 1.4407...  0.3082 sec/batch
Epoch: 9/20...  Training Step: 1660...  Training loss: 1.4620...  0.3094 sec/batch
Epoch: 9/20...  Training Step: 1661...  Training loss: 1.4355...  0.3085 sec/batch
Epoch: 9/20...  Training Step: 1662...  Training loss: 1.4318...  0.3092 sec/batch
Epoch: 9/20...  Training Step: 1663...  Training loss: 1.3979...  0.3071 sec/batch
Epoch: 9/20...  Training Step: 1664...  Training loss: 1.4344...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1665...  Training loss: 1.4019...  0.3069 sec/batch
Epoch: 9/20...  Training Step: 1666...  Training loss: 1.4359...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1667...  Training loss: 1.4130...  0.3075 sec/batch
Epoch: 9/20...  Training Step: 1668...  Training loss: 1.4350...  0.3071 sec/batch
Epoch: 9/20...  Training Step: 1669...  Training loss: 1.4155...  0.3078 sec/batch
Epoch: 9/20...  Training Step: 1670...  Training loss: 1.4343...  0.3088 sec/batch
Epoch: 9/20...  Training Step: 1671...  Training loss: 1.4112...  0.3081 sec/batch
Epoch: 9/20...  Training Step: 1672...  Training loss: 1.4188...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1673...  Training loss: 1.4110...  0.3084 sec/batch
Epoch: 9/20...  Training Step: 1674...  Training loss: 1.4484...  0.3078 sec/batch
Epoch: 9/20...  Training Step: 1675...  Training loss: 1.4077...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1676...  Training loss: 1.4225...  0.3078 sec/batch
Epoch: 9/20...  Training Step: 1677...  Training loss: 1.4102...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1678...  Training loss: 1.4128...  0.3078 sec/batch
Epoch: 9/20...  Training Step: 1679...  Training loss: 1.4131...  0.3081 sec/batch
Epoch: 9/20...  Training Step: 1680...  Training loss: 1.4496...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1681...  Training loss: 1.4418...  0.3071 sec/batch
Epoch: 9/20...  Training Step: 1682...  Training loss: 1.3972...  0.3078 sec/batch
Epoch: 9/20...  Training Step: 1683...  Training loss: 1.4150...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1684...  Training loss: 1.4010...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1685...  Training loss: 1.4368...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1686...  Training loss: 1.4261...  0.3084 sec/batch
Epoch: 9/20...  Training Step: 1687...  Training loss: 1.4408...  0.3082 sec/batch
Epoch: 9/20...  Training Step: 1688...  Training loss: 1.4265...  0.3071 sec/batch
Epoch: 9/20...  Training Step: 1689...  Training loss: 1.4290...  0.3081 sec/batch
Epoch: 9/20...  Training Step: 1690...  Training loss: 1.4230...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1691...  Training loss: 1.4284...  0.3101 sec/batch
Epoch: 9/20...  Training Step: 1692...  Training loss: 1.4400...  0.3083 sec/batch
Epoch: 9/20...  Training Step: 1693...  Training loss: 1.4249...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1694...  Training loss: 1.4498...  0.3075 sec/batch
Epoch: 9/20...  Training Step: 1695...  Training loss: 1.4223...  0.3087 sec/batch
Epoch: 9/20...  Training Step: 1696...  Training loss: 1.4369...  0.3094 sec/batch
Epoch: 9/20...  Training Step: 1697...  Training loss: 1.4264...  0.3088 sec/batch
Epoch: 9/20...  Training Step: 1698...  Training loss: 1.4140...  0.3090 sec/batch
Epoch: 9/20...  Training Step: 1699...  Training loss: 1.4106...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1700...  Training loss: 1.3886...  0.3075 sec/batch
Epoch: 9/20...  Training Step: 1701...  Training loss: 1.4388...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1702...  Training loss: 1.4411...  0.3083 sec/batch
Epoch: 9/20...  Training Step: 1703...  Training loss: 1.4275...  0.3074 sec/batch
Epoch: 9/20...  Training Step: 1704...  Training loss: 1.4201...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1705...  Training loss: 1.4152...  0.3082 sec/batch
Epoch: 9/20...  Training Step: 1706...  Training loss: 1.3972...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1707...  Training loss: 1.3842...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1708...  Training loss: 1.4336...  0.3081 sec/batch
Epoch: 9/20...  Training Step: 1709...  Training loss: 1.4178...  0.3086 sec/batch
Epoch: 9/20...  Training Step: 1710...  Training loss: 1.3831...  0.3082 sec/batch
Epoch: 9/20...  Training Step: 1711...  Training loss: 1.4415...  0.3084 sec/batch
Epoch: 9/20...  Training Step: 1712...  Training loss: 1.4316...  0.3088 sec/batch
Epoch: 9/20...  Training Step: 1713...  Training loss: 1.4103...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1714...  Training loss: 1.3885...  0.3072 sec/batch
Epoch: 9/20...  Training Step: 1715...  Training loss: 1.3818...  0.3081 sec/batch
Epoch: 9/20...  Training Step: 1716...  Training loss: 1.3943...  0.3085 sec/batch
Epoch: 9/20...  Training Step: 1717...  Training loss: 1.4457...  0.3082 sec/batch
Epoch: 9/20...  Training Step: 1718...  Training loss: 1.4322...  0.3085 sec/batch
Epoch: 9/20...  Training Step: 1719...  Training loss: 1.4308...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1720...  Training loss: 1.4247...  0.3086 sec/batch
Epoch: 9/20...  Training Step: 1721...  Training loss: 1.4466...  0.3081 sec/batch
Epoch: 9/20...  Training Step: 1722...  Training loss: 1.4379...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1723...  Training loss: 1.4380...  0.3190 sec/batch
Epoch: 9/20...  Training Step: 1724...  Training loss: 1.4414...  0.3081 sec/batch
Epoch: 9/20...  Training Step: 1725...  Training loss: 1.4905...  0.3070 sec/batch
Epoch: 9/20...  Training Step: 1726...  Training loss: 1.4290...  0.3086 sec/batch
Epoch: 9/20...  Training Step: 1727...  Training loss: 1.4347...  0.3092 sec/batch
Epoch: 9/20...  Training Step: 1728...  Training loss: 1.4621...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1729...  Training loss: 1.4156...  0.3086 sec/batch
Epoch: 9/20...  Training Step: 1730...  Training loss: 1.4483...  0.3085 sec/batch
Epoch: 9/20...  Training Step: 1731...  Training loss: 1.4415...  0.3078 sec/batch
Epoch: 9/20...  Training Step: 1732...  Training loss: 1.4609...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1733...  Training loss: 1.4602...  0.3088 sec/batch
Epoch: 9/20...  Training Step: 1734...  Training loss: 1.4245...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1735...  Training loss: 1.4005...  0.3071 sec/batch
Epoch: 9/20...  Training Step: 1736...  Training loss: 1.4250...  0.3086 sec/batch
Epoch: 9/20...  Training Step: 1737...  Training loss: 1.4434...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1738...  Training loss: 1.4407...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1739...  Training loss: 1.4132...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1740...  Training loss: 1.4440...  0.3084 sec/batch
Epoch: 9/20...  Training Step: 1741...  Training loss: 1.4377...  0.3083 sec/batch
Epoch: 9/20...  Training Step: 1742...  Training loss: 1.4294...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1743...  Training loss: 1.3935...  0.3101 sec/batch
Epoch: 9/20...  Training Step: 1744...  Training loss: 1.4493...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1745...  Training loss: 1.4579...  0.3093 sec/batch
Epoch: 9/20...  Training Step: 1746...  Training loss: 1.4337...  0.3104 sec/batch
Epoch: 9/20...  Training Step: 1747...  Training loss: 1.4338...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1748...  Training loss: 1.4294...  0.3075 sec/batch
Epoch: 9/20...  Training Step: 1749...  Training loss: 1.4364...  0.3078 sec/batch
Epoch: 9/20...  Training Step: 1750...  Training loss: 1.4229...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1751...  Training loss: 1.4531...  0.3086 sec/batch
Epoch: 9/20...  Training Step: 1752...  Training loss: 1.4957...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1753...  Training loss: 1.4388...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1754...  Training loss: 1.4278...  0.3084 sec/batch
Epoch: 9/20...  Training Step: 1755...  Training loss: 1.4178...  0.3075 sec/batch
Epoch: 9/20...  Training Step: 1756...  Training loss: 1.4122...  0.3075 sec/batch
Epoch: 9/20...  Training Step: 1757...  Training loss: 1.4549...  0.3087 sec/batch
Epoch: 9/20...  Training Step: 1758...  Training loss: 1.4301...  0.3075 sec/batch
Epoch: 9/20...  Training Step: 1759...  Training loss: 1.4506...  0.3073 sec/batch
Epoch: 9/20...  Training Step: 1760...  Training loss: 1.3985...  0.3080 sec/batch
Epoch: 9/20...  Training Step: 1761...  Training loss: 1.4127...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1762...  Training loss: 1.4546...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1763...  Training loss: 1.4029...  0.3078 sec/batch
Epoch: 9/20...  Training Step: 1764...  Training loss: 1.3956...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1765...  Training loss: 1.3911...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1766...  Training loss: 1.4144...  0.3074 sec/batch
Epoch: 9/20...  Training Step: 1767...  Training loss: 1.4221...  0.3080 sec/batch
Epoch: 9/20...  Training Step: 1768...  Training loss: 1.4060...  0.3085 sec/batch
Epoch: 9/20...  Training Step: 1769...  Training loss: 1.4247...  0.3088 sec/batch
Epoch: 9/20...  Training Step: 1770...  Training loss: 1.4137...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1771...  Training loss: 1.4368...  0.3077 sec/batch
Epoch: 9/20...  Training Step: 1772...  Training loss: 1.4087...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1773...  Training loss: 1.4114...  0.3076 sec/batch
Epoch: 9/20...  Training Step: 1774...  Training loss: 1.4248...  0.3090 sec/batch
Epoch: 9/20...  Training Step: 1775...  Training loss: 1.4057...  0.3079 sec/batch
Epoch: 9/20...  Training Step: 1776...  Training loss: 1.4005...  0.3078 sec/batch
Epoch: 9/20...  Training Step: 1777...  Training loss: 1.4155...  0.3088 sec/batch
Epoch: 9/20...  Training Step: 1778...  Training loss: 1.3915...  0.3158 sec/batch
Epoch: 9/20...  Training Step: 1779...  Training loss: 1.3995...  0.3094 sec/batch
Epoch: 9/20...  Training Step: 1780...  Training loss: 1.4224...  0.3075 sec/batch
Epoch: 9/20...  Training Step: 1781...  Training loss: 1.4142...  0.3086 sec/batch
Epoch: 9/20...  Training Step: 1782...  Training loss: 1.3972...  0.3078 sec/batch
(1980000,)
(100, 19800)
Epoch: 10/20...  Training Step: 1783...  Training loss: 1.5974...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1784...  Training loss: 1.4234...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1785...  Training loss: 1.4209...  0.3078 sec/batch
Epoch: 10/20...  Training Step: 1786...  Training loss: 1.4358...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1787...  Training loss: 1.4007...  0.3090 sec/batch
Epoch: 10/20...  Training Step: 1788...  Training loss: 1.3816...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1789...  Training loss: 1.4312...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1790...  Training loss: 1.4122...  0.3078 sec/batch
Epoch: 10/20...  Training Step: 1791...  Training loss: 1.4322...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1792...  Training loss: 1.4131...  0.3083 sec/batch
Epoch: 10/20...  Training Step: 1793...  Training loss: 1.3982...  0.3081 sec/batch
Epoch: 10/20...  Training Step: 1794...  Training loss: 1.4080...  0.3078 sec/batch
Epoch: 10/20...  Training Step: 1795...  Training loss: 1.4214...  0.3085 sec/batch
Epoch: 10/20...  Training Step: 1796...  Training loss: 1.4376...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1797...  Training loss: 1.4121...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1798...  Training loss: 1.3954...  0.3072 sec/batch
Epoch: 10/20...  Training Step: 1799...  Training loss: 1.4303...  0.3065 sec/batch
Epoch: 10/20...  Training Step: 1800...  Training loss: 1.4406...  0.3071 sec/batch
Epoch: 10/20...  Training Step: 1801...  Training loss: 1.4120...  0.3088 sec/batch
Epoch: 10/20...  Training Step: 1802...  Training loss: 1.4482...  0.3087 sec/batch
Epoch: 10/20...  Training Step: 1803...  Training loss: 1.4136...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1804...  Training loss: 1.4303...  0.3082 sec/batch
Epoch: 10/20...  Training Step: 1805...  Training loss: 1.4117...  0.3081 sec/batch
Epoch: 10/20...  Training Step: 1806...  Training loss: 1.4284...  0.3071 sec/batch
Epoch: 10/20...  Training Step: 1807...  Training loss: 1.4190...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1808...  Training loss: 1.3713...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1809...  Training loss: 1.3870...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1810...  Training loss: 1.4389...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1811...  Training loss: 1.4351...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1812...  Training loss: 1.4352...  0.3074 sec/batch
Epoch: 10/20...  Training Step: 1813...  Training loss: 1.4095...  0.3083 sec/batch
Epoch: 10/20...  Training Step: 1814...  Training loss: 1.3835...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1815...  Training loss: 1.4260...  0.3081 sec/batch
Epoch: 10/20...  Training Step: 1816...  Training loss: 1.4272...  0.3083 sec/batch
Epoch: 10/20...  Training Step: 1817...  Training loss: 1.4111...  0.3083 sec/batch
Epoch: 10/20...  Training Step: 1818...  Training loss: 1.4187...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1819...  Training loss: 1.3857...  0.3074 sec/batch
Epoch: 10/20...  Training Step: 1820...  Training loss: 1.3746...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1821...  Training loss: 1.3657...  0.3078 sec/batch
Epoch: 10/20...  Training Step: 1822...  Training loss: 1.3935...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1823...  Training loss: 1.3992...  0.3069 sec/batch
Epoch: 10/20...  Training Step: 1824...  Training loss: 1.4411...  0.3076 sec/batch
Epoch: 10/20...  Training Step: 1825...  Training loss: 1.3938...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1826...  Training loss: 1.3918...  0.3072 sec/batch
Epoch: 10/20...  Training Step: 1827...  Training loss: 1.4166...  0.3072 sec/batch
Epoch: 10/20...  Training Step: 1828...  Training loss: 1.3779...  0.3091 sec/batch
Epoch: 10/20...  Training Step: 1829...  Training loss: 1.3930...  0.3082 sec/batch
Epoch: 10/20...  Training Step: 1830...  Training loss: 1.3955...  0.3087 sec/batch
Epoch: 10/20...  Training Step: 1831...  Training loss: 1.3990...  0.3065 sec/batch
Epoch: 10/20...  Training Step: 1832...  Training loss: 1.4264...  0.3073 sec/batch
Epoch: 10/20...  Training Step: 1833...  Training loss: 1.3824...  0.3081 sec/batch
Epoch: 10/20...  Training Step: 1834...  Training loss: 1.4425...  0.3073 sec/batch
Epoch: 10/20...  Training Step: 1835...  Training loss: 1.4061...  0.3073 sec/batch
Epoch: 10/20...  Training Step: 1836...  Training loss: 1.4238...  0.3070 sec/batch
Epoch: 10/20...  Training Step: 1837...  Training loss: 1.3995...  0.3074 sec/batch
Epoch: 10/20...  Training Step: 1838...  Training loss: 1.4159...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1839...  Training loss: 1.4306...  0.3076 sec/batch
Epoch: 10/20...  Training Step: 1840...  Training loss: 1.3899...  0.3086 sec/batch
Epoch: 10/20...  Training Step: 1841...  Training loss: 1.3914...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1842...  Training loss: 1.4396...  0.3078 sec/batch
Epoch: 10/20...  Training Step: 1843...  Training loss: 1.4086...  0.3074 sec/batch
Epoch: 10/20...  Training Step: 1844...  Training loss: 1.4696...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1845...  Training loss: 1.4368...  0.3076 sec/batch
Epoch: 10/20...  Training Step: 1846...  Training loss: 1.4142...  0.3086 sec/batch
Epoch: 10/20...  Training Step: 1847...  Training loss: 1.4026...  0.3082 sec/batch
Epoch: 10/20...  Training Step: 1848...  Training loss: 1.4153...  0.3078 sec/batch
Epoch: 10/20...  Training Step: 1849...  Training loss: 1.4198...  0.3081 sec/batch
Epoch: 10/20...  Training Step: 1850...  Training loss: 1.3867...  0.3073 sec/batch
Epoch: 10/20...  Training Step: 1851...  Training loss: 1.4054...  0.3072 sec/batch
Epoch: 10/20...  Training Step: 1852...  Training loss: 1.3862...  0.3073 sec/batch
Epoch: 10/20...  Training Step: 1853...  Training loss: 1.4597...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1854...  Training loss: 1.4292...  0.3076 sec/batch
Epoch: 10/20...  Training Step: 1855...  Training loss: 1.4469...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1856...  Training loss: 1.3899...  0.3072 sec/batch
Epoch: 10/20...  Training Step: 1857...  Training loss: 1.4013...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1858...  Training loss: 1.4342...  0.3078 sec/batch
Epoch: 10/20...  Training Step: 1859...  Training loss: 1.3976...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1860...  Training loss: 1.3927...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1861...  Training loss: 1.3722...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1862...  Training loss: 1.4037...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1863...  Training loss: 1.3626...  0.3076 sec/batch
Epoch: 10/20...  Training Step: 1864...  Training loss: 1.4118...  0.3082 sec/batch
Epoch: 10/20...  Training Step: 1865...  Training loss: 1.3787...  0.3074 sec/batch
Epoch: 10/20...  Training Step: 1866...  Training loss: 1.3974...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1867...  Training loss: 1.3824...  0.3111 sec/batch
Epoch: 10/20...  Training Step: 1868...  Training loss: 1.4039...  0.3082 sec/batch
Epoch: 10/20...  Training Step: 1869...  Training loss: 1.3880...  0.3083 sec/batch
Epoch: 10/20...  Training Step: 1870...  Training loss: 1.3768...  0.3085 sec/batch
Epoch: 10/20...  Training Step: 1871...  Training loss: 1.3697...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1872...  Training loss: 1.4195...  0.3074 sec/batch
Epoch: 10/20...  Training Step: 1873...  Training loss: 1.3874...  0.3094 sec/batch
Epoch: 10/20...  Training Step: 1874...  Training loss: 1.3935...  0.3086 sec/batch
Epoch: 10/20...  Training Step: 1875...  Training loss: 1.3803...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1876...  Training loss: 1.3798...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1877...  Training loss: 1.3837...  0.3070 sec/batch
Epoch: 10/20...  Training Step: 1878...  Training loss: 1.4169...  0.3083 sec/batch
Epoch: 10/20...  Training Step: 1879...  Training loss: 1.4149...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1880...  Training loss: 1.3703...  0.3081 sec/batch
Epoch: 10/20...  Training Step: 1881...  Training loss: 1.3740...  0.3078 sec/batch
Epoch: 10/20...  Training Step: 1882...  Training loss: 1.3715...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1883...  Training loss: 1.4004...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1884...  Training loss: 1.3868...  0.3085 sec/batch
Epoch: 10/20...  Training Step: 1885...  Training loss: 1.3968...  0.3069 sec/batch
Epoch: 10/20...  Training Step: 1886...  Training loss: 1.3952...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1887...  Training loss: 1.4040...  0.3070 sec/batch
Epoch: 10/20...  Training Step: 1888...  Training loss: 1.3876...  0.3069 sec/batch
Epoch: 10/20...  Training Step: 1889...  Training loss: 1.4052...  0.3081 sec/batch
Epoch: 10/20...  Training Step: 1890...  Training loss: 1.4095...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1891...  Training loss: 1.3718...  0.3091 sec/batch
Epoch: 10/20...  Training Step: 1892...  Training loss: 1.4012...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1893...  Training loss: 1.3889...  0.3081 sec/batch
Epoch: 10/20...  Training Step: 1894...  Training loss: 1.3936...  0.3069 sec/batch
Epoch: 10/20...  Training Step: 1895...  Training loss: 1.4041...  0.3084 sec/batch
Epoch: 10/20...  Training Step: 1896...  Training loss: 1.3802...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1897...  Training loss: 1.3752...  0.3076 sec/batch
Epoch: 10/20...  Training Step: 1898...  Training loss: 1.3557...  0.3082 sec/batch
Epoch: 10/20...  Training Step: 1899...  Training loss: 1.3983...  0.3071 sec/batch
Epoch: 10/20...  Training Step: 1900...  Training loss: 1.4076...  0.3073 sec/batch
Epoch: 10/20...  Training Step: 1901...  Training loss: 1.3832...  0.3081 sec/batch
Epoch: 10/20...  Training Step: 1902...  Training loss: 1.3921...  0.3081 sec/batch
Epoch: 10/20...  Training Step: 1903...  Training loss: 1.3966...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1904...  Training loss: 1.3567...  0.3082 sec/batch
Epoch: 10/20...  Training Step: 1905...  Training loss: 1.3490...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1906...  Training loss: 1.4015...  0.3083 sec/batch
Epoch: 10/20...  Training Step: 1907...  Training loss: 1.3914...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1908...  Training loss: 1.3581...  0.3081 sec/batch
Epoch: 10/20...  Training Step: 1909...  Training loss: 1.4093...  0.3073 sec/batch
Epoch: 10/20...  Training Step: 1910...  Training loss: 1.4100...  0.3074 sec/batch
Epoch: 10/20...  Training Step: 1911...  Training loss: 1.3741...  0.3074 sec/batch
Epoch: 10/20...  Training Step: 1912...  Training loss: 1.3645...  0.3103 sec/batch
Epoch: 10/20...  Training Step: 1913...  Training loss: 1.3432...  0.3083 sec/batch
Epoch: 10/20...  Training Step: 1914...  Training loss: 1.3692...  0.3071 sec/batch
Epoch: 10/20...  Training Step: 1915...  Training loss: 1.4082...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1916...  Training loss: 1.3987...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1917...  Training loss: 1.3919...  0.3081 sec/batch
Epoch: 10/20...  Training Step: 1918...  Training loss: 1.4050...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1919...  Training loss: 1.4229...  0.3082 sec/batch
Epoch: 10/20...  Training Step: 1920...  Training loss: 1.4018...  0.3076 sec/batch
Epoch: 10/20...  Training Step: 1921...  Training loss: 1.4072...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1922...  Training loss: 1.3914...  0.3084 sec/batch
Epoch: 10/20...  Training Step: 1923...  Training loss: 1.4488...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1924...  Training loss: 1.3951...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1925...  Training loss: 1.3930...  0.3074 sec/batch
Epoch: 10/20...  Training Step: 1926...  Training loss: 1.4271...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1927...  Training loss: 1.3841...  0.3088 sec/batch
Epoch: 10/20...  Training Step: 1928...  Training loss: 1.4194...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1929...  Training loss: 1.3950...  0.3084 sec/batch
Epoch: 10/20...  Training Step: 1930...  Training loss: 1.4355...  0.3070 sec/batch
Epoch: 10/20...  Training Step: 1931...  Training loss: 1.4214...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1932...  Training loss: 1.3896...  0.3085 sec/batch
Epoch: 10/20...  Training Step: 1933...  Training loss: 1.3710...  0.3076 sec/batch
Epoch: 10/20...  Training Step: 1934...  Training loss: 1.3855...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1935...  Training loss: 1.3931...  0.3130 sec/batch
Epoch: 10/20...  Training Step: 1936...  Training loss: 1.3892...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1937...  Training loss: 1.3849...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1938...  Training loss: 1.3973...  0.3071 sec/batch
Epoch: 10/20...  Training Step: 1939...  Training loss: 1.4074...  0.3074 sec/batch
Epoch: 10/20...  Training Step: 1940...  Training loss: 1.3880...  0.3074 sec/batch
Epoch: 10/20...  Training Step: 1941...  Training loss: 1.3531...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1942...  Training loss: 1.4121...  0.3078 sec/batch
Epoch: 10/20...  Training Step: 1943...  Training loss: 1.4246...  0.3071 sec/batch
Epoch: 10/20...  Training Step: 1944...  Training loss: 1.3864...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1945...  Training loss: 1.3933...  0.3076 sec/batch
Epoch: 10/20...  Training Step: 1946...  Training loss: 1.3908...  0.3089 sec/batch
Epoch: 10/20...  Training Step: 1947...  Training loss: 1.3866...  0.3080 sec/batch
Epoch: 10/20...  Training Step: 1948...  Training loss: 1.3920...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1949...  Training loss: 1.4183...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1950...  Training loss: 1.4694...  0.3086 sec/batch
Epoch: 10/20...  Training Step: 1951...  Training loss: 1.3960...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1952...  Training loss: 1.3894...  0.3073 sec/batch
Epoch: 10/20...  Training Step: 1953...  Training loss: 1.3828...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1954...  Training loss: 1.3718...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1955...  Training loss: 1.4178...  0.3074 sec/batch
Epoch: 10/20...  Training Step: 1956...  Training loss: 1.3994...  0.3083 sec/batch
Epoch: 10/20...  Training Step: 1957...  Training loss: 1.4084...  0.3081 sec/batch
Epoch: 10/20...  Training Step: 1958...  Training loss: 1.3658...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1959...  Training loss: 1.3773...  0.3084 sec/batch
Epoch: 10/20...  Training Step: 1960...  Training loss: 1.4327...  0.3082 sec/batch
Epoch: 10/20...  Training Step: 1961...  Training loss: 1.3791...  0.3072 sec/batch
Epoch: 10/20...  Training Step: 1962...  Training loss: 1.3759...  0.3079 sec/batch
Epoch: 10/20...  Training Step: 1963...  Training loss: 1.3609...  0.3084 sec/batch
Epoch: 10/20...  Training Step: 1964...  Training loss: 1.3923...  0.3074 sec/batch
Epoch: 10/20...  Training Step: 1965...  Training loss: 1.3934...  0.3072 sec/batch
Epoch: 10/20...  Training Step: 1966...  Training loss: 1.3862...  0.3070 sec/batch
Epoch: 10/20...  Training Step: 1967...  Training loss: 1.3805...  0.3153 sec/batch
Epoch: 10/20...  Training Step: 1968...  Training loss: 1.3743...  0.3078 sec/batch
Epoch: 10/20...  Training Step: 1969...  Training loss: 1.4212...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1970...  Training loss: 1.3851...  0.3078 sec/batch
Epoch: 10/20...  Training Step: 1971...  Training loss: 1.3977...  0.3072 sec/batch
Epoch: 10/20...  Training Step: 1972...  Training loss: 1.3908...  0.3076 sec/batch
Epoch: 10/20...  Training Step: 1973...  Training loss: 1.3687...  0.3065 sec/batch
Epoch: 10/20...  Training Step: 1974...  Training loss: 1.3693...  0.3094 sec/batch
Epoch: 10/20...  Training Step: 1975...  Training loss: 1.3868...  0.3077 sec/batch
Epoch: 10/20...  Training Step: 1976...  Training loss: 1.3750...  0.3075 sec/batch
Epoch: 10/20...  Training Step: 1977...  Training loss: 1.3574...  0.3074 sec/batch
Epoch: 10/20...  Training Step: 1978...  Training loss: 1.4045...  0.3076 sec/batch
Epoch: 10/20...  Training Step: 1979...  Training loss: 1.3803...  0.3098 sec/batch
Epoch: 10/20...  Training Step: 1980...  Training loss: 1.3755...  0.3076 sec/batch
(1980000,)
(100, 19800)
Epoch: 11/20...  Training Step: 1981...  Training loss: 1.5526...  0.3085 sec/batch
Epoch: 11/20...  Training Step: 1982...  Training loss: 1.3961...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 1983...  Training loss: 1.3992...  0.3091 sec/batch
Epoch: 11/20...  Training Step: 1984...  Training loss: 1.4101...  0.3076 sec/batch
Epoch: 11/20...  Training Step: 1985...  Training loss: 1.3728...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 1986...  Training loss: 1.3653...  0.3082 sec/batch
Epoch: 11/20...  Training Step: 1987...  Training loss: 1.3980...  0.3086 sec/batch
Epoch: 11/20...  Training Step: 1988...  Training loss: 1.3683...  0.3070 sec/batch
Epoch: 11/20...  Training Step: 1989...  Training loss: 1.3874...  0.3108 sec/batch
Epoch: 11/20...  Training Step: 1990...  Training loss: 1.3819...  0.3114 sec/batch
Epoch: 11/20...  Training Step: 1991...  Training loss: 1.3666...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 1992...  Training loss: 1.3838...  0.3082 sec/batch
Epoch: 11/20...  Training Step: 1993...  Training loss: 1.3937...  0.3077 sec/batch
Epoch: 11/20...  Training Step: 1994...  Training loss: 1.4073...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 1995...  Training loss: 1.3721...  0.3078 sec/batch
Epoch: 11/20...  Training Step: 1996...  Training loss: 1.3593...  0.3081 sec/batch
Epoch: 11/20...  Training Step: 1997...  Training loss: 1.3939...  0.3088 sec/batch
Epoch: 11/20...  Training Step: 1998...  Training loss: 1.4014...  0.3078 sec/batch
Epoch: 11/20...  Training Step: 1999...  Training loss: 1.3891...  0.3084 sec/batch
Epoch: 11/20...  Training Step: 2000...  Training loss: 1.4181...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 2001...  Training loss: 1.3932...  0.3076 sec/batch
Epoch: 11/20...  Training Step: 2002...  Training loss: 1.4036...  0.3074 sec/batch
Epoch: 11/20...  Training Step: 2003...  Training loss: 1.3809...  0.3082 sec/batch
Epoch: 11/20...  Training Step: 2004...  Training loss: 1.3967...  0.3081 sec/batch
Epoch: 11/20...  Training Step: 2005...  Training loss: 1.3809...  0.3084 sec/batch
Epoch: 11/20...  Training Step: 2006...  Training loss: 1.3409...  0.3073 sec/batch
Epoch: 11/20...  Training Step: 2007...  Training loss: 1.3554...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 2008...  Training loss: 1.4011...  0.3090 sec/batch
Epoch: 11/20...  Training Step: 2009...  Training loss: 1.4002...  0.3081 sec/batch
Epoch: 11/20...  Training Step: 2010...  Training loss: 1.4112...  0.3091 sec/batch
Epoch: 11/20...  Training Step: 2011...  Training loss: 1.3847...  0.3078 sec/batch
Epoch: 11/20...  Training Step: 2012...  Training loss: 1.3552...  0.3077 sec/batch
Epoch: 11/20...  Training Step: 2013...  Training loss: 1.3924...  0.3074 sec/batch
Epoch: 11/20...  Training Step: 2014...  Training loss: 1.4012...  0.3074 sec/batch
Epoch: 11/20...  Training Step: 2015...  Training loss: 1.3747...  0.3073 sec/batch
Epoch: 11/20...  Training Step: 2016...  Training loss: 1.3901...  0.3077 sec/batch
Epoch: 11/20...  Training Step: 2017...  Training loss: 1.3588...  0.3083 sec/batch
Epoch: 11/20...  Training Step: 2018...  Training loss: 1.3363...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 2019...  Training loss: 1.3384...  0.3077 sec/batch
Epoch: 11/20...  Training Step: 2020...  Training loss: 1.3658...  0.3079 sec/batch
Epoch: 11/20...  Training Step: 2021...  Training loss: 1.3622...  0.3077 sec/batch
Epoch: 11/20...  Training Step: 2022...  Training loss: 1.4148...  0.3084 sec/batch
Epoch: 11/20...  Training Step: 2023...  Training loss: 1.3733...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 2024...  Training loss: 1.3440...  0.3082 sec/batch
Epoch: 11/20...  Training Step: 2025...  Training loss: 1.3966...  0.3078 sec/batch
Epoch: 11/20...  Training Step: 2026...  Training loss: 1.3441...  0.3077 sec/batch
Epoch: 11/20...  Training Step: 2027...  Training loss: 1.3597...  0.3072 sec/batch
Epoch: 11/20...  Training Step: 2028...  Training loss: 1.3790...  0.3074 sec/batch
Epoch: 11/20...  Training Step: 2029...  Training loss: 1.3789...  0.3076 sec/batch
Epoch: 11/20...  Training Step: 2030...  Training loss: 1.4090...  0.3074 sec/batch
Epoch: 11/20...  Training Step: 2031...  Training loss: 1.3612...  0.3079 sec/batch
Epoch: 11/20...  Training Step: 2032...  Training loss: 1.4136...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 2033...  Training loss: 1.3800...  0.3078 sec/batch
Epoch: 11/20...  Training Step: 2034...  Training loss: 1.3966...  0.3077 sec/batch
Epoch: 11/20...  Training Step: 2035...  Training loss: 1.3755...  0.3089 sec/batch
Epoch: 11/20...  Training Step: 2036...  Training loss: 1.3792...  0.3084 sec/batch
Epoch: 11/20...  Training Step: 2037...  Training loss: 1.3963...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 2038...  Training loss: 1.3577...  0.3077 sec/batch
Epoch: 11/20...  Training Step: 2039...  Training loss: 1.3604...  0.3132 sec/batch
Epoch: 11/20...  Training Step: 2040...  Training loss: 1.4190...  0.3112 sec/batch
Epoch: 11/20...  Training Step: 2041...  Training loss: 1.3852...  0.3081 sec/batch
Epoch: 11/20...  Training Step: 2042...  Training loss: 1.4331...  0.3078 sec/batch
Epoch: 11/20...  Training Step: 2043...  Training loss: 1.4023...  0.3076 sec/batch
Epoch: 11/20...  Training Step: 2044...  Training loss: 1.3915...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 2045...  Training loss: 1.3750...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 2046...  Training loss: 1.3818...  0.3087 sec/batch
Epoch: 11/20...  Training Step: 2047...  Training loss: 1.3979...  0.3085 sec/batch
Epoch: 11/20...  Training Step: 2048...  Training loss: 1.3576...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 2049...  Training loss: 1.3846...  0.3084 sec/batch
Epoch: 11/20...  Training Step: 2050...  Training loss: 1.3694...  0.3083 sec/batch
Epoch: 11/20...  Training Step: 2051...  Training loss: 1.4232...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 2052...  Training loss: 1.3965...  0.3097 sec/batch
Epoch: 11/20...  Training Step: 2053...  Training loss: 1.4106...  0.3085 sec/batch
Epoch: 11/20...  Training Step: 2054...  Training loss: 1.3523...  0.3071 sec/batch
Epoch: 11/20...  Training Step: 2055...  Training loss: 1.3772...  0.3078 sec/batch
Epoch: 11/20...  Training Step: 2056...  Training loss: 1.3955...  0.3076 sec/batch
Epoch: 11/20...  Training Step: 2057...  Training loss: 1.3745...  0.3088 sec/batch
Epoch: 11/20...  Training Step: 2058...  Training loss: 1.3735...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 2059...  Training loss: 1.3271...  0.3085 sec/batch
Epoch: 11/20...  Training Step: 2060...  Training loss: 1.3830...  0.3085 sec/batch
Epoch: 11/20...  Training Step: 2061...  Training loss: 1.3437...  0.3090 sec/batch
Epoch: 11/20...  Training Step: 2062...  Training loss: 1.3699...  0.3070 sec/batch
Epoch: 11/20...  Training Step: 2063...  Training loss: 1.3403...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 2064...  Training loss: 1.3745...  0.3073 sec/batch
Epoch: 11/20...  Training Step: 2065...  Training loss: 1.3480...  0.3069 sec/batch
Epoch: 11/20...  Training Step: 2066...  Training loss: 1.3634...  0.3072 sec/batch
Epoch: 11/20...  Training Step: 2067...  Training loss: 1.3448...  0.3086 sec/batch
Epoch: 11/20...  Training Step: 2068...  Training loss: 1.3540...  0.3076 sec/batch
Epoch: 11/20...  Training Step: 2069...  Training loss: 1.3414...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 2070...  Training loss: 1.3843...  0.3070 sec/batch
Epoch: 11/20...  Training Step: 2071...  Training loss: 1.3537...  0.3085 sec/batch
Epoch: 11/20...  Training Step: 2072...  Training loss: 1.3650...  0.3082 sec/batch
Epoch: 11/20...  Training Step: 2073...  Training loss: 1.3511...  0.3084 sec/batch
Epoch: 11/20...  Training Step: 2074...  Training loss: 1.3517...  0.3078 sec/batch
Epoch: 11/20...  Training Step: 2075...  Training loss: 1.3568...  0.3090 sec/batch
Epoch: 11/20...  Training Step: 2076...  Training loss: 1.3879...  0.3082 sec/batch
Epoch: 11/20...  Training Step: 2077...  Training loss: 1.3676...  0.3066 sec/batch
Epoch: 11/20...  Training Step: 2078...  Training loss: 1.3418...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 2079...  Training loss: 1.3512...  0.3079 sec/batch
Epoch: 11/20...  Training Step: 2080...  Training loss: 1.3422...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 2081...  Training loss: 1.3707...  0.3084 sec/batch
Epoch: 11/20...  Training Step: 2082...  Training loss: 1.3573...  0.3087 sec/batch
Epoch: 11/20...  Training Step: 2083...  Training loss: 1.3771...  0.3072 sec/batch
Epoch: 11/20...  Training Step: 2084...  Training loss: 1.3570...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 2085...  Training loss: 1.3647...  0.3076 sec/batch
Epoch: 11/20...  Training Step: 2086...  Training loss: 1.3595...  0.3081 sec/batch
Epoch: 11/20...  Training Step: 2087...  Training loss: 1.3688...  0.3074 sec/batch
Epoch: 11/20...  Training Step: 2088...  Training loss: 1.3697...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 2089...  Training loss: 1.3590...  0.3083 sec/batch
Epoch: 11/20...  Training Step: 2090...  Training loss: 1.3845...  0.3078 sec/batch
Epoch: 11/20...  Training Step: 2091...  Training loss: 1.3641...  0.3087 sec/batch
Epoch: 11/20...  Training Step: 2092...  Training loss: 1.3751...  0.3071 sec/batch
Epoch: 11/20...  Training Step: 2093...  Training loss: 1.3742...  0.3069 sec/batch
Epoch: 11/20...  Training Step: 2094...  Training loss: 1.3571...  0.3072 sec/batch
Epoch: 11/20...  Training Step: 2095...  Training loss: 1.3476...  0.3098 sec/batch
Epoch: 11/20...  Training Step: 2096...  Training loss: 1.3273...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 2097...  Training loss: 1.3713...  0.3083 sec/batch
Epoch: 11/20...  Training Step: 2098...  Training loss: 1.3754...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 2099...  Training loss: 1.3629...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 2100...  Training loss: 1.3517...  0.3078 sec/batch
Epoch: 11/20...  Training Step: 2101...  Training loss: 1.3599...  0.3074 sec/batch
Epoch: 11/20...  Training Step: 2102...  Training loss: 1.3359...  0.3090 sec/batch
Epoch: 11/20...  Training Step: 2103...  Training loss: 1.3208...  0.3078 sec/batch
Epoch: 11/20...  Training Step: 2104...  Training loss: 1.3729...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 2105...  Training loss: 1.3536...  0.3079 sec/batch
Epoch: 11/20...  Training Step: 2106...  Training loss: 1.3220...  0.3073 sec/batch
Epoch: 11/20...  Training Step: 2107...  Training loss: 1.3772...  0.3083 sec/batch
Epoch: 11/20...  Training Step: 2108...  Training loss: 1.3785...  0.3077 sec/batch
Epoch: 11/20...  Training Step: 2109...  Training loss: 1.3567...  0.3068 sec/batch
Epoch: 11/20...  Training Step: 2110...  Training loss: 1.3297...  0.3088 sec/batch
Epoch: 11/20...  Training Step: 2111...  Training loss: 1.3210...  0.3074 sec/batch
Epoch: 11/20...  Training Step: 2112...  Training loss: 1.3390...  0.3073 sec/batch
Epoch: 11/20...  Training Step: 2113...  Training loss: 1.3906...  0.3073 sec/batch
Epoch: 11/20...  Training Step: 2114...  Training loss: 1.3859...  0.3091 sec/batch
Epoch: 11/20...  Training Step: 2115...  Training loss: 1.3742...  0.3088 sec/batch
Epoch: 11/20...  Training Step: 2116...  Training loss: 1.3666...  0.3083 sec/batch
Epoch: 11/20...  Training Step: 2117...  Training loss: 1.3946...  0.3077 sec/batch
Epoch: 11/20...  Training Step: 2118...  Training loss: 1.3733...  0.3077 sec/batch
Epoch: 11/20...  Training Step: 2119...  Training loss: 1.3711...  0.3070 sec/batch
Epoch: 11/20...  Training Step: 2120...  Training loss: 1.3756...  0.3077 sec/batch
Epoch: 11/20...  Training Step: 2121...  Training loss: 1.4208...  0.3091 sec/batch
Epoch: 11/20...  Training Step: 2122...  Training loss: 1.3736...  0.3078 sec/batch
Epoch: 11/20...  Training Step: 2123...  Training loss: 1.3625...  0.3082 sec/batch
Epoch: 11/20...  Training Step: 2124...  Training loss: 1.4002...  0.3076 sec/batch
Epoch: 11/20...  Training Step: 2125...  Training loss: 1.3577...  0.3084 sec/batch
Epoch: 11/20...  Training Step: 2126...  Training loss: 1.3942...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 2127...  Training loss: 1.3787...  0.3072 sec/batch
Epoch: 11/20...  Training Step: 2128...  Training loss: 1.4008...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 2129...  Training loss: 1.3986...  0.3076 sec/batch
Epoch: 11/20...  Training Step: 2130...  Training loss: 1.3647...  0.3071 sec/batch
Epoch: 11/20...  Training Step: 2131...  Training loss: 1.3359...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 2132...  Training loss: 1.3570...  0.3087 sec/batch
Epoch: 11/20...  Training Step: 2133...  Training loss: 1.3765...  0.3079 sec/batch
Epoch: 11/20...  Training Step: 2134...  Training loss: 1.3594...  0.3073 sec/batch
Epoch: 11/20...  Training Step: 2135...  Training loss: 1.3676...  0.3074 sec/batch
Epoch: 11/20...  Training Step: 2136...  Training loss: 1.3688...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 2137...  Training loss: 1.3662...  0.3092 sec/batch
Epoch: 11/20...  Training Step: 2138...  Training loss: 1.3617...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 2139...  Training loss: 1.3277...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 2140...  Training loss: 1.3866...  0.3074 sec/batch
Epoch: 11/20...  Training Step: 2141...  Training loss: 1.3876...  0.3078 sec/batch
Epoch: 11/20...  Training Step: 2142...  Training loss: 1.3683...  0.3078 sec/batch
Epoch: 11/20...  Training Step: 2143...  Training loss: 1.3672...  0.3072 sec/batch
Epoch: 11/20...  Training Step: 2144...  Training loss: 1.3832...  0.3077 sec/batch
Epoch: 11/20...  Training Step: 2145...  Training loss: 1.3700...  0.3096 sec/batch
Epoch: 11/20...  Training Step: 2146...  Training loss: 1.3556...  0.3078 sec/batch
Epoch: 11/20...  Training Step: 2147...  Training loss: 1.3876...  0.3073 sec/batch
Epoch: 11/20...  Training Step: 2148...  Training loss: 1.4325...  0.3065 sec/batch
Epoch: 11/20...  Training Step: 2149...  Training loss: 1.3640...  0.3074 sec/batch
Epoch: 11/20...  Training Step: 2150...  Training loss: 1.3700...  0.3083 sec/batch
Epoch: 11/20...  Training Step: 2151...  Training loss: 1.3573...  0.3076 sec/batch
Epoch: 11/20...  Training Step: 2152...  Training loss: 1.3566...  0.3067 sec/batch
Epoch: 11/20...  Training Step: 2153...  Training loss: 1.3917...  0.3077 sec/batch
Epoch: 11/20...  Training Step: 2154...  Training loss: 1.3686...  0.3085 sec/batch
Epoch: 11/20...  Training Step: 2155...  Training loss: 1.3839...  0.3079 sec/batch
Epoch: 11/20...  Training Step: 2156...  Training loss: 1.3381...  0.3082 sec/batch
Epoch: 11/20...  Training Step: 2157...  Training loss: 1.3426...  0.3083 sec/batch
Epoch: 11/20...  Training Step: 2158...  Training loss: 1.3973...  0.3073 sec/batch
Epoch: 11/20...  Training Step: 2159...  Training loss: 1.3473...  0.3075 sec/batch
Epoch: 11/20...  Training Step: 2160...  Training loss: 1.3399...  0.3072 sec/batch
Epoch: 11/20...  Training Step: 2161...  Training loss: 1.3343...  0.3086 sec/batch
Epoch: 11/20...  Training Step: 2162...  Training loss: 1.3522...  0.3074 sec/batch
Epoch: 11/20...  Training Step: 2163...  Training loss: 1.3669...  0.3150 sec/batch
Epoch: 11/20...  Training Step: 2164...  Training loss: 1.3480...  0.3086 sec/batch
Epoch: 11/20...  Training Step: 2165...  Training loss: 1.3650...  0.3070 sec/batch
Epoch: 11/20...  Training Step: 2166...  Training loss: 1.3454...  0.3076 sec/batch
Epoch: 11/20...  Training Step: 2167...  Training loss: 1.3881...  0.3072 sec/batch
Epoch: 11/20...  Training Step: 2168...  Training loss: 1.3641...  0.3074 sec/batch
Epoch: 11/20...  Training Step: 2169...  Training loss: 1.3705...  0.3076 sec/batch
Epoch: 11/20...  Training Step: 2170...  Training loss: 1.3610...  0.3087 sec/batch
Epoch: 11/20...  Training Step: 2171...  Training loss: 1.3327...  0.3071 sec/batch
Epoch: 11/20...  Training Step: 2172...  Training loss: 1.3489...  0.3070 sec/batch
Epoch: 11/20...  Training Step: 2173...  Training loss: 1.3682...  0.3082 sec/batch
Epoch: 11/20...  Training Step: 2174...  Training loss: 1.3448...  0.3088 sec/batch
Epoch: 11/20...  Training Step: 2175...  Training loss: 1.3327...  0.3087 sec/batch
Epoch: 11/20...  Training Step: 2176...  Training loss: 1.3676...  0.3094 sec/batch
Epoch: 11/20...  Training Step: 2177...  Training loss: 1.3602...  0.3080 sec/batch
Epoch: 11/20...  Training Step: 2178...  Training loss: 1.3409...  0.3091 sec/batch
(1980000,)
(100, 19800)
Epoch: 12/20...  Training Step: 2179...  Training loss: 1.5476...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2180...  Training loss: 1.3658...  0.3091 sec/batch
Epoch: 12/20...  Training Step: 2181...  Training loss: 1.3671...  0.3084 sec/batch
Epoch: 12/20...  Training Step: 2182...  Training loss: 1.3729...  0.3068 sec/batch
Epoch: 12/20...  Training Step: 2183...  Training loss: 1.3399...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2184...  Training loss: 1.3364...  0.3069 sec/batch
Epoch: 12/20...  Training Step: 2185...  Training loss: 1.3689...  0.3078 sec/batch
Epoch: 12/20...  Training Step: 2186...  Training loss: 1.3544...  0.3084 sec/batch
Epoch: 12/20...  Training Step: 2187...  Training loss: 1.3756...  0.3079 sec/batch
Epoch: 12/20...  Training Step: 2188...  Training loss: 1.3621...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2189...  Training loss: 1.3294...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2190...  Training loss: 1.3570...  0.3084 sec/batch
Epoch: 12/20...  Training Step: 2191...  Training loss: 1.3558...  0.3087 sec/batch
Epoch: 12/20...  Training Step: 2192...  Training loss: 1.3730...  0.3072 sec/batch
Epoch: 12/20...  Training Step: 2193...  Training loss: 1.3481...  0.3069 sec/batch
Epoch: 12/20...  Training Step: 2194...  Training loss: 1.3357...  0.3069 sec/batch
Epoch: 12/20...  Training Step: 2195...  Training loss: 1.3712...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2196...  Training loss: 1.3858...  0.3080 sec/batch
Epoch: 12/20...  Training Step: 2197...  Training loss: 1.3565...  0.3069 sec/batch
Epoch: 12/20...  Training Step: 2198...  Training loss: 1.3918...  0.3071 sec/batch
Epoch: 12/20...  Training Step: 2199...  Training loss: 1.3543...  0.3078 sec/batch
Epoch: 12/20...  Training Step: 2200...  Training loss: 1.3758...  0.3082 sec/batch
Epoch: 12/20...  Training Step: 2201...  Training loss: 1.3534...  0.3080 sec/batch
Epoch: 12/20...  Training Step: 2202...  Training loss: 1.3717...  0.3073 sec/batch
Epoch: 12/20...  Training Step: 2203...  Training loss: 1.3626...  0.3070 sec/batch
Epoch: 12/20...  Training Step: 2204...  Training loss: 1.3127...  0.3073 sec/batch
Epoch: 12/20...  Training Step: 2205...  Training loss: 1.3279...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2206...  Training loss: 1.3785...  0.3083 sec/batch
Epoch: 12/20...  Training Step: 2207...  Training loss: 1.3764...  0.3078 sec/batch
Epoch: 12/20...  Training Step: 2208...  Training loss: 1.3781...  0.3077 sec/batch
Epoch: 12/20...  Training Step: 2209...  Training loss: 1.3429...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2210...  Training loss: 1.3263...  0.3078 sec/batch
Epoch: 12/20...  Training Step: 2211...  Training loss: 1.3681...  0.3080 sec/batch
Epoch: 12/20...  Training Step: 2212...  Training loss: 1.3673...  0.3077 sec/batch
Epoch: 12/20...  Training Step: 2213...  Training loss: 1.3471...  0.3092 sec/batch
Epoch: 12/20...  Training Step: 2214...  Training loss: 1.3723...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2215...  Training loss: 1.3290...  0.3083 sec/batch
Epoch: 12/20...  Training Step: 2216...  Training loss: 1.3153...  0.3068 sec/batch
Epoch: 12/20...  Training Step: 2217...  Training loss: 1.3023...  0.3079 sec/batch
Epoch: 12/20...  Training Step: 2218...  Training loss: 1.3398...  0.3072 sec/batch
Epoch: 12/20...  Training Step: 2219...  Training loss: 1.3440...  0.3079 sec/batch
Epoch: 12/20...  Training Step: 2220...  Training loss: 1.3948...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2221...  Training loss: 1.3444...  0.3081 sec/batch
Epoch: 12/20...  Training Step: 2222...  Training loss: 1.3262...  0.3084 sec/batch
Epoch: 12/20...  Training Step: 2223...  Training loss: 1.3650...  0.3079 sec/batch
Epoch: 12/20...  Training Step: 2224...  Training loss: 1.3330...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2225...  Training loss: 1.3390...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2226...  Training loss: 1.3526...  0.3084 sec/batch
Epoch: 12/20...  Training Step: 2227...  Training loss: 1.3490...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2228...  Training loss: 1.3657...  0.3069 sec/batch
Epoch: 12/20...  Training Step: 2229...  Training loss: 1.3255...  0.3082 sec/batch
Epoch: 12/20...  Training Step: 2230...  Training loss: 1.4023...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2231...  Training loss: 1.3599...  0.3079 sec/batch
Epoch: 12/20...  Training Step: 2232...  Training loss: 1.3784...  0.3089 sec/batch
Epoch: 12/20...  Training Step: 2233...  Training loss: 1.3534...  0.3071 sec/batch
Epoch: 12/20...  Training Step: 2234...  Training loss: 1.3564...  0.3070 sec/batch
Epoch: 12/20...  Training Step: 2235...  Training loss: 1.3690...  0.3071 sec/batch
Epoch: 12/20...  Training Step: 2236...  Training loss: 1.3424...  0.3080 sec/batch
Epoch: 12/20...  Training Step: 2237...  Training loss: 1.3417...  0.3067 sec/batch
Epoch: 12/20...  Training Step: 2238...  Training loss: 1.4020...  0.3073 sec/batch
Epoch: 12/20...  Training Step: 2239...  Training loss: 1.3682...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2240...  Training loss: 1.4089...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2241...  Training loss: 1.3823...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2242...  Training loss: 1.3661...  0.3080 sec/batch
Epoch: 12/20...  Training Step: 2243...  Training loss: 1.3608...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2244...  Training loss: 1.3614...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2245...  Training loss: 1.3797...  0.3079 sec/batch
Epoch: 12/20...  Training Step: 2246...  Training loss: 1.3353...  0.3084 sec/batch
Epoch: 12/20...  Training Step: 2247...  Training loss: 1.3643...  0.3081 sec/batch
Epoch: 12/20...  Training Step: 2248...  Training loss: 1.3383...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2249...  Training loss: 1.3952...  0.3073 sec/batch
Epoch: 12/20...  Training Step: 2250...  Training loss: 1.3683...  0.3072 sec/batch
Epoch: 12/20...  Training Step: 2251...  Training loss: 1.3859...  0.3078 sec/batch
Epoch: 12/20...  Training Step: 2252...  Training loss: 1.3311...  0.3093 sec/batch
Epoch: 12/20...  Training Step: 2253...  Training loss: 1.3519...  0.3073 sec/batch
Epoch: 12/20...  Training Step: 2254...  Training loss: 1.3715...  0.3078 sec/batch
Epoch: 12/20...  Training Step: 2255...  Training loss: 1.3498...  0.3074 sec/batch
Epoch: 12/20...  Training Step: 2256...  Training loss: 1.3414...  0.3080 sec/batch
Epoch: 12/20...  Training Step: 2257...  Training loss: 1.3059...  0.3078 sec/batch
Epoch: 12/20...  Training Step: 2258...  Training loss: 1.3618...  0.3084 sec/batch
Epoch: 12/20...  Training Step: 2259...  Training loss: 1.3194...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2260...  Training loss: 1.3486...  0.3078 sec/batch
Epoch: 12/20...  Training Step: 2261...  Training loss: 1.3187...  0.3073 sec/batch
Epoch: 12/20...  Training Step: 2262...  Training loss: 1.3380...  0.3069 sec/batch
Epoch: 12/20...  Training Step: 2263...  Training loss: 1.3268...  0.3074 sec/batch
Epoch: 12/20...  Training Step: 2264...  Training loss: 1.3419...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2265...  Training loss: 1.3228...  0.3081 sec/batch
Epoch: 12/20...  Training Step: 2266...  Training loss: 1.3315...  0.3080 sec/batch
Epoch: 12/20...  Training Step: 2267...  Training loss: 1.3157...  0.3077 sec/batch
Epoch: 12/20...  Training Step: 2268...  Training loss: 1.3578...  0.3071 sec/batch
Epoch: 12/20...  Training Step: 2269...  Training loss: 1.3210...  0.3080 sec/batch
Epoch: 12/20...  Training Step: 2270...  Training loss: 1.3457...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2271...  Training loss: 1.3212...  0.3078 sec/batch
Epoch: 12/20...  Training Step: 2272...  Training loss: 1.3227...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2273...  Training loss: 1.3263...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2274...  Training loss: 1.3666...  0.3086 sec/batch
Epoch: 12/20...  Training Step: 2275...  Training loss: 1.3629...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2276...  Training loss: 1.3106...  0.3077 sec/batch
Epoch: 12/20...  Training Step: 2277...  Training loss: 1.3255...  0.3082 sec/batch
Epoch: 12/20...  Training Step: 2278...  Training loss: 1.3274...  0.3077 sec/batch
Epoch: 12/20...  Training Step: 2279...  Training loss: 1.3572...  0.3081 sec/batch
Epoch: 12/20...  Training Step: 2280...  Training loss: 1.3338...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2281...  Training loss: 1.3515...  0.3084 sec/batch
Epoch: 12/20...  Training Step: 2282...  Training loss: 1.3415...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2283...  Training loss: 1.3469...  0.3077 sec/batch
Epoch: 12/20...  Training Step: 2284...  Training loss: 1.3528...  0.3079 sec/batch
Epoch: 12/20...  Training Step: 2285...  Training loss: 1.3465...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2286...  Training loss: 1.3440...  0.3073 sec/batch
Epoch: 12/20...  Training Step: 2287...  Training loss: 1.3395...  0.3072 sec/batch
Epoch: 12/20...  Training Step: 2288...  Training loss: 1.3609...  0.3087 sec/batch
Epoch: 12/20...  Training Step: 2289...  Training loss: 1.3341...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2290...  Training loss: 1.3519...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2291...  Training loss: 1.3517...  0.3080 sec/batch
Epoch: 12/20...  Training Step: 2292...  Training loss: 1.3381...  0.3083 sec/batch
Epoch: 12/20...  Training Step: 2293...  Training loss: 1.3210...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2294...  Training loss: 1.3050...  0.3105 sec/batch
Epoch: 12/20...  Training Step: 2295...  Training loss: 1.3454...  0.3092 sec/batch
Epoch: 12/20...  Training Step: 2296...  Training loss: 1.3599...  0.3086 sec/batch
Epoch: 12/20...  Training Step: 2297...  Training loss: 1.3367...  0.3066 sec/batch
Epoch: 12/20...  Training Step: 2298...  Training loss: 1.3367...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2299...  Training loss: 1.3473...  0.3072 sec/batch
Epoch: 12/20...  Training Step: 2300...  Training loss: 1.3117...  0.3081 sec/batch
Epoch: 12/20...  Training Step: 2301...  Training loss: 1.2941...  0.3094 sec/batch
Epoch: 12/20...  Training Step: 2302...  Training loss: 1.3576...  0.3091 sec/batch
Epoch: 12/20...  Training Step: 2303...  Training loss: 1.3324...  0.3077 sec/batch
Epoch: 12/20...  Training Step: 2304...  Training loss: 1.3060...  0.3079 sec/batch
Epoch: 12/20...  Training Step: 2305...  Training loss: 1.3596...  0.3085 sec/batch
Epoch: 12/20...  Training Step: 2306...  Training loss: 1.3475...  0.3084 sec/batch
Epoch: 12/20...  Training Step: 2307...  Training loss: 1.3289...  0.3077 sec/batch
Epoch: 12/20...  Training Step: 2308...  Training loss: 1.3082...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2309...  Training loss: 1.2957...  0.3085 sec/batch
Epoch: 12/20...  Training Step: 2310...  Training loss: 1.3249...  0.3085 sec/batch
Epoch: 12/20...  Training Step: 2311...  Training loss: 1.3628...  0.3085 sec/batch
Epoch: 12/20...  Training Step: 2312...  Training loss: 1.3595...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2313...  Training loss: 1.3476...  0.3074 sec/batch
Epoch: 12/20...  Training Step: 2314...  Training loss: 1.3500...  0.3078 sec/batch
Epoch: 12/20...  Training Step: 2315...  Training loss: 1.3677...  0.3071 sec/batch
Epoch: 12/20...  Training Step: 2316...  Training loss: 1.3546...  0.3079 sec/batch
Epoch: 12/20...  Training Step: 2317...  Training loss: 1.3596...  0.3078 sec/batch
Epoch: 12/20...  Training Step: 2318...  Training loss: 1.3475...  0.3070 sec/batch
Epoch: 12/20...  Training Step: 2319...  Training loss: 1.3991...  0.3083 sec/batch
Epoch: 12/20...  Training Step: 2320...  Training loss: 1.3537...  0.3073 sec/batch
Epoch: 12/20...  Training Step: 2321...  Training loss: 1.3426...  0.3086 sec/batch
Epoch: 12/20...  Training Step: 2322...  Training loss: 1.3801...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2323...  Training loss: 1.3285...  0.3074 sec/batch
Epoch: 12/20...  Training Step: 2324...  Training loss: 1.3659...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2325...  Training loss: 1.3475...  0.3069 sec/batch
Epoch: 12/20...  Training Step: 2326...  Training loss: 1.3946...  0.3080 sec/batch
Epoch: 12/20...  Training Step: 2327...  Training loss: 1.3679...  0.3077 sec/batch
Epoch: 12/20...  Training Step: 2328...  Training loss: 1.3386...  0.3096 sec/batch
Epoch: 12/20...  Training Step: 2329...  Training loss: 1.3164...  0.3066 sec/batch
Epoch: 12/20...  Training Step: 2330...  Training loss: 1.3276...  0.3065 sec/batch
Epoch: 12/20...  Training Step: 2331...  Training loss: 1.3511...  0.3070 sec/batch
Epoch: 12/20...  Training Step: 2332...  Training loss: 1.3328...  0.3080 sec/batch
Epoch: 12/20...  Training Step: 2333...  Training loss: 1.3437...  0.3078 sec/batch
Epoch: 12/20...  Training Step: 2334...  Training loss: 1.3477...  0.3090 sec/batch
Epoch: 12/20...  Training Step: 2335...  Training loss: 1.3560...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2336...  Training loss: 1.3315...  0.3084 sec/batch
Epoch: 12/20...  Training Step: 2337...  Training loss: 1.3039...  0.3085 sec/batch
Epoch: 12/20...  Training Step: 2338...  Training loss: 1.3597...  0.3069 sec/batch
Epoch: 12/20...  Training Step: 2339...  Training loss: 1.3649...  0.3071 sec/batch
Epoch: 12/20...  Training Step: 2340...  Training loss: 1.3397...  0.3071 sec/batch
Epoch: 12/20...  Training Step: 2341...  Training loss: 1.3429...  0.3069 sec/batch
Epoch: 12/20...  Training Step: 2342...  Training loss: 1.3423...  0.3071 sec/batch
Epoch: 12/20...  Training Step: 2343...  Training loss: 1.3516...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2344...  Training loss: 1.3448...  0.3080 sec/batch
Epoch: 12/20...  Training Step: 2345...  Training loss: 1.3756...  0.3091 sec/batch
Epoch: 12/20...  Training Step: 2346...  Training loss: 1.4179...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2347...  Training loss: 1.3479...  0.3094 sec/batch
Epoch: 12/20...  Training Step: 2348...  Training loss: 1.3416...  0.3088 sec/batch
Epoch: 12/20...  Training Step: 2349...  Training loss: 1.3420...  0.3077 sec/batch
Epoch: 12/20...  Training Step: 2350...  Training loss: 1.3276...  0.3072 sec/batch
Epoch: 12/20...  Training Step: 2351...  Training loss: 1.3692...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2352...  Training loss: 1.3486...  0.3077 sec/batch
Epoch: 12/20...  Training Step: 2353...  Training loss: 1.3515...  0.3083 sec/batch
Epoch: 12/20...  Training Step: 2354...  Training loss: 1.3242...  0.3081 sec/batch
Epoch: 12/20...  Training Step: 2355...  Training loss: 1.3235...  0.3080 sec/batch
Epoch: 12/20...  Training Step: 2356...  Training loss: 1.3570...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2357...  Training loss: 1.3244...  0.3070 sec/batch
Epoch: 12/20...  Training Step: 2358...  Training loss: 1.3127...  0.3070 sec/batch
Epoch: 12/20...  Training Step: 2359...  Training loss: 1.3080...  0.3091 sec/batch
Epoch: 12/20...  Training Step: 2360...  Training loss: 1.3338...  0.3084 sec/batch
Epoch: 12/20...  Training Step: 2361...  Training loss: 1.3260...  0.3074 sec/batch
Epoch: 12/20...  Training Step: 2362...  Training loss: 1.3341...  0.3103 sec/batch
Epoch: 12/20...  Training Step: 2363...  Training loss: 1.3344...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2364...  Training loss: 1.3159...  0.3069 sec/batch
Epoch: 12/20...  Training Step: 2365...  Training loss: 1.3651...  0.3077 sec/batch
Epoch: 12/20...  Training Step: 2366...  Training loss: 1.3359...  0.3085 sec/batch
Epoch: 12/20...  Training Step: 2367...  Training loss: 1.3366...  0.3077 sec/batch
Epoch: 12/20...  Training Step: 2368...  Training loss: 1.3350...  0.3075 sec/batch
Epoch: 12/20...  Training Step: 2369...  Training loss: 1.3192...  0.3071 sec/batch
Epoch: 12/20...  Training Step: 2370...  Training loss: 1.3180...  0.3083 sec/batch
Epoch: 12/20...  Training Step: 2371...  Training loss: 1.3380...  0.3076 sec/batch
Epoch: 12/20...  Training Step: 2372...  Training loss: 1.3237...  0.3086 sec/batch
Epoch: 12/20...  Training Step: 2373...  Training loss: 1.3063...  0.3081 sec/batch
Epoch: 12/20...  Training Step: 2374...  Training loss: 1.3567...  0.3097 sec/batch
Epoch: 12/20...  Training Step: 2375...  Training loss: 1.3243...  0.3087 sec/batch
Epoch: 12/20...  Training Step: 2376...  Training loss: 1.3252...  0.3072 sec/batch
(1980000,)
(100, 19800)
Epoch: 13/20...  Training Step: 2377...  Training loss: 1.5294...  0.3068 sec/batch
Epoch: 13/20...  Training Step: 2378...  Training loss: 1.3475...  0.3085 sec/batch
Epoch: 13/20...  Training Step: 2379...  Training loss: 1.3421...  0.3074 sec/batch
Epoch: 13/20...  Training Step: 2380...  Training loss: 1.3548...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2381...  Training loss: 1.3196...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2382...  Training loss: 1.3047...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2383...  Training loss: 1.3498...  0.3075 sec/batch
Epoch: 13/20...  Training Step: 2384...  Training loss: 1.3376...  0.3078 sec/batch
Epoch: 13/20...  Training Step: 2385...  Training loss: 1.3439...  0.3084 sec/batch
Epoch: 13/20...  Training Step: 2386...  Training loss: 1.3288...  0.3071 sec/batch
Epoch: 13/20...  Training Step: 2387...  Training loss: 1.3234...  0.3076 sec/batch
Epoch: 13/20...  Training Step: 2388...  Training loss: 1.3365...  0.3071 sec/batch
Epoch: 13/20...  Training Step: 2389...  Training loss: 1.3384...  0.3070 sec/batch
Epoch: 13/20...  Training Step: 2390...  Training loss: 1.3593...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2391...  Training loss: 1.3306...  0.3071 sec/batch
Epoch: 13/20...  Training Step: 2392...  Training loss: 1.3280...  0.3072 sec/batch
Epoch: 13/20...  Training Step: 2393...  Training loss: 1.3525...  0.3083 sec/batch
Epoch: 13/20...  Training Step: 2394...  Training loss: 1.3622...  0.3075 sec/batch
Epoch: 13/20...  Training Step: 2395...  Training loss: 1.3350...  0.3088 sec/batch
Epoch: 13/20...  Training Step: 2396...  Training loss: 1.3709...  0.3071 sec/batch
Epoch: 13/20...  Training Step: 2397...  Training loss: 1.3339...  0.3090 sec/batch
Epoch: 13/20...  Training Step: 2398...  Training loss: 1.3512...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2399...  Training loss: 1.3341...  0.3085 sec/batch
Epoch: 13/20...  Training Step: 2400...  Training loss: 1.3584...  0.3076 sec/batch
Epoch: 13/20...  Training Step: 2401...  Training loss: 1.3516...  0.3076 sec/batch
Epoch: 13/20...  Training Step: 2402...  Training loss: 1.2954...  0.3087 sec/batch
Epoch: 13/20...  Training Step: 2403...  Training loss: 1.3118...  0.3080 sec/batch
Epoch: 13/20...  Training Step: 2404...  Training loss: 1.3587...  0.3072 sec/batch
Epoch: 13/20...  Training Step: 2405...  Training loss: 1.3474...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2406...  Training loss: 1.3601...  0.3067 sec/batch
Epoch: 13/20...  Training Step: 2407...  Training loss: 1.3215...  0.3081 sec/batch
Epoch: 13/20...  Training Step: 2408...  Training loss: 1.3123...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2409...  Training loss: 1.3434...  0.3077 sec/batch
Epoch: 13/20...  Training Step: 2410...  Training loss: 1.3510...  0.3077 sec/batch
Epoch: 13/20...  Training Step: 2411...  Training loss: 1.3191...  0.3089 sec/batch
Epoch: 13/20...  Training Step: 2412...  Training loss: 1.3389...  0.3075 sec/batch
Epoch: 13/20...  Training Step: 2413...  Training loss: 1.3077...  0.3074 sec/batch
Epoch: 13/20...  Training Step: 2414...  Training loss: 1.2920...  0.3069 sec/batch
Epoch: 13/20...  Training Step: 2415...  Training loss: 1.2891...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2416...  Training loss: 1.3196...  0.3072 sec/batch
Epoch: 13/20...  Training Step: 2417...  Training loss: 1.3173...  0.3064 sec/batch
Epoch: 13/20...  Training Step: 2418...  Training loss: 1.3754...  0.3069 sec/batch
Epoch: 13/20...  Training Step: 2419...  Training loss: 1.3178...  0.3081 sec/batch
Epoch: 13/20...  Training Step: 2420...  Training loss: 1.3117...  0.3071 sec/batch
Epoch: 13/20...  Training Step: 2421...  Training loss: 1.3414...  0.3075 sec/batch
Epoch: 13/20...  Training Step: 2422...  Training loss: 1.3115...  0.3086 sec/batch
Epoch: 13/20...  Training Step: 2423...  Training loss: 1.3202...  0.3071 sec/batch
Epoch: 13/20...  Training Step: 2424...  Training loss: 1.3223...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2425...  Training loss: 1.3203...  0.3092 sec/batch
Epoch: 13/20...  Training Step: 2426...  Training loss: 1.3469...  0.3078 sec/batch
Epoch: 13/20...  Training Step: 2427...  Training loss: 1.3061...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2428...  Training loss: 1.3737...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2429...  Training loss: 1.3434...  0.3071 sec/batch
Epoch: 13/20...  Training Step: 2430...  Training loss: 1.3513...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2431...  Training loss: 1.3227...  0.3068 sec/batch
Epoch: 13/20...  Training Step: 2432...  Training loss: 1.3325...  0.3075 sec/batch
Epoch: 13/20...  Training Step: 2433...  Training loss: 1.3528...  0.3084 sec/batch
Epoch: 13/20...  Training Step: 2434...  Training loss: 1.3200...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2435...  Training loss: 1.3103...  0.3086 sec/batch
Epoch: 13/20...  Training Step: 2436...  Training loss: 1.3684...  0.3086 sec/batch
Epoch: 13/20...  Training Step: 2437...  Training loss: 1.3389...  0.3074 sec/batch
Epoch: 13/20...  Training Step: 2438...  Training loss: 1.3776...  0.3067 sec/batch
Epoch: 13/20...  Training Step: 2439...  Training loss: 1.3543...  0.3072 sec/batch
Epoch: 13/20...  Training Step: 2440...  Training loss: 1.3526...  0.3072 sec/batch
Epoch: 13/20...  Training Step: 2441...  Training loss: 1.3297...  0.3075 sec/batch
Epoch: 13/20...  Training Step: 2442...  Training loss: 1.3414...  0.3082 sec/batch
Epoch: 13/20...  Training Step: 2443...  Training loss: 1.3499...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2444...  Training loss: 1.3138...  0.3069 sec/batch
Epoch: 13/20...  Training Step: 2445...  Training loss: 1.3309...  0.3078 sec/batch
Epoch: 13/20...  Training Step: 2446...  Training loss: 1.3078...  0.3081 sec/batch
Epoch: 13/20...  Training Step: 2447...  Training loss: 1.3768...  0.3076 sec/batch
Epoch: 13/20...  Training Step: 2448...  Training loss: 1.3550...  0.3084 sec/batch
Epoch: 13/20...  Training Step: 2449...  Training loss: 1.3639...  0.3076 sec/batch
Epoch: 13/20...  Training Step: 2450...  Training loss: 1.3025...  0.3080 sec/batch
Epoch: 13/20...  Training Step: 2451...  Training loss: 1.3269...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2452...  Training loss: 1.3592...  0.3081 sec/batch
Epoch: 13/20...  Training Step: 2453...  Training loss: 1.3261...  0.3082 sec/batch
Epoch: 13/20...  Training Step: 2454...  Training loss: 1.3173...  0.3077 sec/batch
Epoch: 13/20...  Training Step: 2455...  Training loss: 1.2914...  0.3080 sec/batch
Epoch: 13/20...  Training Step: 2456...  Training loss: 1.3357...  0.3074 sec/batch
Epoch: 13/20...  Training Step: 2457...  Training loss: 1.2945...  0.3097 sec/batch
Epoch: 13/20...  Training Step: 2458...  Training loss: 1.3266...  0.3085 sec/batch
Epoch: 13/20...  Training Step: 2459...  Training loss: 1.2978...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2460...  Training loss: 1.3260...  0.3074 sec/batch
Epoch: 13/20...  Training Step: 2461...  Training loss: 1.3140...  0.3088 sec/batch
Epoch: 13/20...  Training Step: 2462...  Training loss: 1.3316...  0.3074 sec/batch
Epoch: 13/20...  Training Step: 2463...  Training loss: 1.3107...  0.3074 sec/batch
Epoch: 13/20...  Training Step: 2464...  Training loss: 1.3099...  0.3075 sec/batch
Epoch: 13/20...  Training Step: 2465...  Training loss: 1.3046...  0.3078 sec/batch
Epoch: 13/20...  Training Step: 2466...  Training loss: 1.3378...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2467...  Training loss: 1.3129...  0.3076 sec/batch
Epoch: 13/20...  Training Step: 2468...  Training loss: 1.3178...  0.3077 sec/batch
Epoch: 13/20...  Training Step: 2469...  Training loss: 1.3146...  0.3083 sec/batch
Epoch: 13/20...  Training Step: 2470...  Training loss: 1.3047...  0.3083 sec/batch
Epoch: 13/20...  Training Step: 2471...  Training loss: 1.3156...  0.3070 sec/batch
Epoch: 13/20...  Training Step: 2472...  Training loss: 1.3490...  0.3072 sec/batch
Epoch: 13/20...  Training Step: 2473...  Training loss: 1.3442...  0.3074 sec/batch
Epoch: 13/20...  Training Step: 2474...  Training loss: 1.2975...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2475...  Training loss: 1.3097...  0.3078 sec/batch
Epoch: 13/20...  Training Step: 2476...  Training loss: 1.3063...  0.3077 sec/batch
Epoch: 13/20...  Training Step: 2477...  Training loss: 1.3397...  0.3082 sec/batch
Epoch: 13/20...  Training Step: 2478...  Training loss: 1.3191...  0.3078 sec/batch
Epoch: 13/20...  Training Step: 2479...  Training loss: 1.3411...  0.3078 sec/batch
Epoch: 13/20...  Training Step: 2480...  Training loss: 1.3219...  0.3075 sec/batch
Epoch: 13/20...  Training Step: 2481...  Training loss: 1.3222...  0.3071 sec/batch
Epoch: 13/20...  Training Step: 2482...  Training loss: 1.3271...  0.3063 sec/batch
Epoch: 13/20...  Training Step: 2483...  Training loss: 1.3197...  0.3103 sec/batch
Epoch: 13/20...  Training Step: 2484...  Training loss: 1.3287...  0.3074 sec/batch
Epoch: 13/20...  Training Step: 2485...  Training loss: 1.3182...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2486...  Training loss: 1.3479...  0.3078 sec/batch
Epoch: 13/20...  Training Step: 2487...  Training loss: 1.3072...  0.3083 sec/batch
Epoch: 13/20...  Training Step: 2488...  Training loss: 1.3367...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2489...  Training loss: 1.3309...  0.3096 sec/batch
Epoch: 13/20...  Training Step: 2490...  Training loss: 1.3119...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2491...  Training loss: 1.2986...  0.3080 sec/batch
Epoch: 13/20...  Training Step: 2492...  Training loss: 1.2879...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2493...  Training loss: 1.3279...  0.3078 sec/batch
Epoch: 13/20...  Training Step: 2494...  Training loss: 1.3335...  0.3076 sec/batch
Epoch: 13/20...  Training Step: 2495...  Training loss: 1.3214...  0.3085 sec/batch
Epoch: 13/20...  Training Step: 2496...  Training loss: 1.3062...  0.3077 sec/batch
Epoch: 13/20...  Training Step: 2497...  Training loss: 1.3207...  0.3076 sec/batch
Epoch: 13/20...  Training Step: 2498...  Training loss: 1.2922...  0.3087 sec/batch
Epoch: 13/20...  Training Step: 2499...  Training loss: 1.2883...  0.3075 sec/batch
Epoch: 13/20...  Training Step: 2500...  Training loss: 1.3334...  0.3076 sec/batch
Epoch: 13/20...  Training Step: 2501...  Training loss: 1.3170...  0.3082 sec/batch
Epoch: 13/20...  Training Step: 2502...  Training loss: 1.2718...  0.3105 sec/batch
Epoch: 13/20...  Training Step: 2503...  Training loss: 1.3351...  0.3098 sec/batch
Epoch: 13/20...  Training Step: 2504...  Training loss: 1.3243...  0.3076 sec/batch
Epoch: 13/20...  Training Step: 2505...  Training loss: 1.3066...  0.3075 sec/batch
Epoch: 13/20...  Training Step: 2506...  Training loss: 1.2906...  0.3083 sec/batch
Epoch: 13/20...  Training Step: 2507...  Training loss: 1.2762...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2508...  Training loss: 1.3030...  0.3077 sec/batch
Epoch: 13/20...  Training Step: 2509...  Training loss: 1.3384...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2510...  Training loss: 1.3393...  0.3083 sec/batch
Epoch: 13/20...  Training Step: 2511...  Training loss: 1.3187...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2512...  Training loss: 1.3281...  0.3075 sec/batch
Epoch: 13/20...  Training Step: 2513...  Training loss: 1.3516...  0.3074 sec/batch
Epoch: 13/20...  Training Step: 2514...  Training loss: 1.3393...  0.3088 sec/batch
Epoch: 13/20...  Training Step: 2515...  Training loss: 1.3392...  0.3078 sec/batch
Epoch: 13/20...  Training Step: 2516...  Training loss: 1.3326...  0.3088 sec/batch
Epoch: 13/20...  Training Step: 2517...  Training loss: 1.3779...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2518...  Training loss: 1.3319...  0.3076 sec/batch
Epoch: 13/20...  Training Step: 2519...  Training loss: 1.3308...  0.3077 sec/batch
Epoch: 13/20...  Training Step: 2520...  Training loss: 1.3620...  0.3074 sec/batch
Epoch: 13/20...  Training Step: 2521...  Training loss: 1.3089...  0.3072 sec/batch
Epoch: 13/20...  Training Step: 2522...  Training loss: 1.3536...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2523...  Training loss: 1.3396...  0.3077 sec/batch
Epoch: 13/20...  Training Step: 2524...  Training loss: 1.3627...  0.3083 sec/batch
Epoch: 13/20...  Training Step: 2525...  Training loss: 1.3506...  0.3087 sec/batch
Epoch: 13/20...  Training Step: 2526...  Training loss: 1.3209...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2527...  Training loss: 1.2938...  0.3072 sec/batch
Epoch: 13/20...  Training Step: 2528...  Training loss: 1.3014...  0.3078 sec/batch
Epoch: 13/20...  Training Step: 2529...  Training loss: 1.3352...  0.3078 sec/batch
Epoch: 13/20...  Training Step: 2530...  Training loss: 1.3108...  0.3072 sec/batch
Epoch: 13/20...  Training Step: 2531...  Training loss: 1.3213...  0.3077 sec/batch
Epoch: 13/20...  Training Step: 2532...  Training loss: 1.3246...  0.3083 sec/batch
Epoch: 13/20...  Training Step: 2533...  Training loss: 1.3308...  0.3075 sec/batch
Epoch: 13/20...  Training Step: 2534...  Training loss: 1.3109...  0.3069 sec/batch
Epoch: 13/20...  Training Step: 2535...  Training loss: 1.2920...  0.3077 sec/batch
Epoch: 13/20...  Training Step: 2536...  Training loss: 1.3404...  0.3081 sec/batch
Epoch: 13/20...  Training Step: 2537...  Training loss: 1.3452...  0.3075 sec/batch
Epoch: 13/20...  Training Step: 2538...  Training loss: 1.3290...  0.3083 sec/batch
Epoch: 13/20...  Training Step: 2539...  Training loss: 1.3156...  0.3065 sec/batch
Epoch: 13/20...  Training Step: 2540...  Training loss: 1.3258...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2541...  Training loss: 1.3212...  0.3071 sec/batch
Epoch: 13/20...  Training Step: 2542...  Training loss: 1.3156...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2543...  Training loss: 1.3522...  0.3081 sec/batch
Epoch: 13/20...  Training Step: 2544...  Training loss: 1.3825...  0.3081 sec/batch
Epoch: 13/20...  Training Step: 2545...  Training loss: 1.3345...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2546...  Training loss: 1.3234...  0.3082 sec/batch
Epoch: 13/20...  Training Step: 2547...  Training loss: 1.3149...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2548...  Training loss: 1.3085...  0.3080 sec/batch
Epoch: 13/20...  Training Step: 2549...  Training loss: 1.3584...  0.3082 sec/batch
Epoch: 13/20...  Training Step: 2550...  Training loss: 1.3208...  0.3080 sec/batch
Epoch: 13/20...  Training Step: 2551...  Training loss: 1.3317...  0.3082 sec/batch
Epoch: 13/20...  Training Step: 2552...  Training loss: 1.3006...  0.3080 sec/batch
Epoch: 13/20...  Training Step: 2553...  Training loss: 1.3126...  0.3077 sec/batch
Epoch: 13/20...  Training Step: 2554...  Training loss: 1.3579...  0.3094 sec/batch
Epoch: 13/20...  Training Step: 2555...  Training loss: 1.3117...  0.3088 sec/batch
Epoch: 13/20...  Training Step: 2556...  Training loss: 1.2983...  0.3087 sec/batch
Epoch: 13/20...  Training Step: 2557...  Training loss: 1.3060...  0.3073 sec/batch
Epoch: 13/20...  Training Step: 2558...  Training loss: 1.3136...  0.3071 sec/batch
Epoch: 13/20...  Training Step: 2559...  Training loss: 1.3240...  0.3071 sec/batch
Epoch: 13/20...  Training Step: 2560...  Training loss: 1.3092...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2561...  Training loss: 1.3196...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2562...  Training loss: 1.2986...  0.3077 sec/batch
Epoch: 13/20...  Training Step: 2563...  Training loss: 1.3511...  0.3074 sec/batch
Epoch: 13/20...  Training Step: 2564...  Training loss: 1.3159...  0.3070 sec/batch
Epoch: 13/20...  Training Step: 2565...  Training loss: 1.3136...  0.3085 sec/batch
Epoch: 13/20...  Training Step: 2566...  Training loss: 1.3192...  0.3074 sec/batch
Epoch: 13/20...  Training Step: 2567...  Training loss: 1.2979...  0.3077 sec/batch
Epoch: 13/20...  Training Step: 2568...  Training loss: 1.3023...  0.3077 sec/batch
Epoch: 13/20...  Training Step: 2569...  Training loss: 1.3272...  0.3070 sec/batch
Epoch: 13/20...  Training Step: 2570...  Training loss: 1.2984...  0.3078 sec/batch
Epoch: 13/20...  Training Step: 2571...  Training loss: 1.2831...  0.3080 sec/batch
Epoch: 13/20...  Training Step: 2572...  Training loss: 1.3374...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2573...  Training loss: 1.3181...  0.3079 sec/batch
Epoch: 13/20...  Training Step: 2574...  Training loss: 1.3126...  0.3088 sec/batch
(1980000,)
(100, 19800)
Epoch: 14/20...  Training Step: 2575...  Training loss: 1.4848...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2576...  Training loss: 1.3307...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2577...  Training loss: 1.3117...  0.3087 sec/batch
Epoch: 14/20...  Training Step: 2578...  Training loss: 1.3375...  0.3079 sec/batch
Epoch: 14/20...  Training Step: 2579...  Training loss: 1.3053...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2580...  Training loss: 1.2851...  0.3080 sec/batch
Epoch: 14/20...  Training Step: 2581...  Training loss: 1.3231...  0.3081 sec/batch
Epoch: 14/20...  Training Step: 2582...  Training loss: 1.3140...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2583...  Training loss: 1.3302...  0.3083 sec/batch
Epoch: 14/20...  Training Step: 2584...  Training loss: 1.3105...  0.3076 sec/batch
Epoch: 14/20...  Training Step: 2585...  Training loss: 1.2979...  0.3073 sec/batch
Epoch: 14/20...  Training Step: 2586...  Training loss: 1.3074...  0.3071 sec/batch
Epoch: 14/20...  Training Step: 2587...  Training loss: 1.3122...  0.3084 sec/batch
Epoch: 14/20...  Training Step: 2588...  Training loss: 1.3380...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2589...  Training loss: 1.3043...  0.3089 sec/batch
Epoch: 14/20...  Training Step: 2590...  Training loss: 1.3024...  0.3070 sec/batch
Epoch: 14/20...  Training Step: 2591...  Training loss: 1.3316...  0.3073 sec/batch
Epoch: 14/20...  Training Step: 2592...  Training loss: 1.3373...  0.3068 sec/batch
Epoch: 14/20...  Training Step: 2593...  Training loss: 1.3245...  0.3110 sec/batch
Epoch: 14/20...  Training Step: 2594...  Training loss: 1.3483...  0.3089 sec/batch
Epoch: 14/20...  Training Step: 2595...  Training loss: 1.3129...  0.3071 sec/batch
Epoch: 14/20...  Training Step: 2596...  Training loss: 1.3304...  0.3080 sec/batch
Epoch: 14/20...  Training Step: 2597...  Training loss: 1.3076...  0.3070 sec/batch
Epoch: 14/20...  Training Step: 2598...  Training loss: 1.3255...  0.3067 sec/batch
Epoch: 14/20...  Training Step: 2599...  Training loss: 1.3179...  0.3083 sec/batch
Epoch: 14/20...  Training Step: 2600...  Training loss: 1.2798...  0.3069 sec/batch
Epoch: 14/20...  Training Step: 2601...  Training loss: 1.2806...  0.3071 sec/batch
Epoch: 14/20...  Training Step: 2602...  Training loss: 1.3334...  0.3080 sec/batch
Epoch: 14/20...  Training Step: 2603...  Training loss: 1.3369...  0.3085 sec/batch
Epoch: 14/20...  Training Step: 2604...  Training loss: 1.3406...  0.3076 sec/batch
Epoch: 14/20...  Training Step: 2605...  Training loss: 1.3055...  0.3074 sec/batch
Epoch: 14/20...  Training Step: 2606...  Training loss: 1.2843...  0.3079 sec/batch
Epoch: 14/20...  Training Step: 2607...  Training loss: 1.3307...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2608...  Training loss: 1.3302...  0.3074 sec/batch
Epoch: 14/20...  Training Step: 2609...  Training loss: 1.3019...  0.3069 sec/batch
Epoch: 14/20...  Training Step: 2610...  Training loss: 1.3289...  0.3067 sec/batch
Epoch: 14/20...  Training Step: 2611...  Training loss: 1.2921...  0.3087 sec/batch
Epoch: 14/20...  Training Step: 2612...  Training loss: 1.2696...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2613...  Training loss: 1.2640...  0.3087 sec/batch
Epoch: 14/20...  Training Step: 2614...  Training loss: 1.3036...  0.3073 sec/batch
Epoch: 14/20...  Training Step: 2615...  Training loss: 1.2898...  0.3067 sec/batch
Epoch: 14/20...  Training Step: 2616...  Training loss: 1.3509...  0.3072 sec/batch
Epoch: 14/20...  Training Step: 2617...  Training loss: 1.2987...  0.3070 sec/batch
Epoch: 14/20...  Training Step: 2618...  Training loss: 1.2910...  0.3080 sec/batch
Epoch: 14/20...  Training Step: 2619...  Training loss: 1.3159...  0.3080 sec/batch
Epoch: 14/20...  Training Step: 2620...  Training loss: 1.2831...  0.3070 sec/batch
Epoch: 14/20...  Training Step: 2621...  Training loss: 1.2982...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2622...  Training loss: 1.3037...  0.3071 sec/batch
Epoch: 14/20...  Training Step: 2623...  Training loss: 1.3154...  0.3070 sec/batch
Epoch: 14/20...  Training Step: 2624...  Training loss: 1.3265...  0.3090 sec/batch
Epoch: 14/20...  Training Step: 2625...  Training loss: 1.2790...  0.3078 sec/batch
Epoch: 14/20...  Training Step: 2626...  Training loss: 1.3605...  0.3082 sec/batch
Epoch: 14/20...  Training Step: 2627...  Training loss: 1.3208...  0.3084 sec/batch
Epoch: 14/20...  Training Step: 2628...  Training loss: 1.3235...  0.3076 sec/batch
Epoch: 14/20...  Training Step: 2629...  Training loss: 1.3044...  0.3083 sec/batch
Epoch: 14/20...  Training Step: 2630...  Training loss: 1.3095...  0.3074 sec/batch
Epoch: 14/20...  Training Step: 2631...  Training loss: 1.3268...  0.3073 sec/batch
Epoch: 14/20...  Training Step: 2632...  Training loss: 1.3060...  0.3091 sec/batch
Epoch: 14/20...  Training Step: 2633...  Training loss: 1.2892...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2634...  Training loss: 1.3483...  0.3073 sec/batch
Epoch: 14/20...  Training Step: 2635...  Training loss: 1.3177...  0.3084 sec/batch
Epoch: 14/20...  Training Step: 2636...  Training loss: 1.3683...  0.3076 sec/batch
Epoch: 14/20...  Training Step: 2637...  Training loss: 1.3333...  0.3071 sec/batch
Epoch: 14/20...  Training Step: 2638...  Training loss: 1.3273...  0.3080 sec/batch
Epoch: 14/20...  Training Step: 2639...  Training loss: 1.3115...  0.3076 sec/batch
Epoch: 14/20...  Training Step: 2640...  Training loss: 1.3119...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2641...  Training loss: 1.3250...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2642...  Training loss: 1.2993...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2643...  Training loss: 1.3172...  0.3066 sec/batch
Epoch: 14/20...  Training Step: 2644...  Training loss: 1.2911...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2645...  Training loss: 1.3573...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2646...  Training loss: 1.3397...  0.3082 sec/batch
Epoch: 14/20...  Training Step: 2647...  Training loss: 1.3457...  0.3076 sec/batch
Epoch: 14/20...  Training Step: 2648...  Training loss: 1.3011...  0.3072 sec/batch
Epoch: 14/20...  Training Step: 2649...  Training loss: 1.3180...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2650...  Training loss: 1.3329...  0.3076 sec/batch
Epoch: 14/20...  Training Step: 2651...  Training loss: 1.3087...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2652...  Training loss: 1.3012...  0.3071 sec/batch
Epoch: 14/20...  Training Step: 2653...  Training loss: 1.2694...  0.3089 sec/batch
Epoch: 14/20...  Training Step: 2654...  Training loss: 1.3154...  0.3081 sec/batch
Epoch: 14/20...  Training Step: 2655...  Training loss: 1.2752...  0.3071 sec/batch
Epoch: 14/20...  Training Step: 2656...  Training loss: 1.3134...  0.3104 sec/batch
Epoch: 14/20...  Training Step: 2657...  Training loss: 1.2788...  0.3071 sec/batch
Epoch: 14/20...  Training Step: 2658...  Training loss: 1.3057...  0.3074 sec/batch
Epoch: 14/20...  Training Step: 2659...  Training loss: 1.2883...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2660...  Training loss: 1.3133...  0.3076 sec/batch
Epoch: 14/20...  Training Step: 2661...  Training loss: 1.2839...  0.3074 sec/batch
Epoch: 14/20...  Training Step: 2662...  Training loss: 1.2942...  0.3085 sec/batch
Epoch: 14/20...  Training Step: 2663...  Training loss: 1.2827...  0.3096 sec/batch
Epoch: 14/20...  Training Step: 2664...  Training loss: 1.3256...  0.3090 sec/batch
Epoch: 14/20...  Training Step: 2665...  Training loss: 1.2890...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2666...  Training loss: 1.3018...  0.3094 sec/batch
Epoch: 14/20...  Training Step: 2667...  Training loss: 1.2841...  0.3086 sec/batch
Epoch: 14/20...  Training Step: 2668...  Training loss: 1.2905...  0.3083 sec/batch
Epoch: 14/20...  Training Step: 2669...  Training loss: 1.2881...  0.3081 sec/batch
Epoch: 14/20...  Training Step: 2670...  Training loss: 1.3217...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2671...  Training loss: 1.3154...  0.3072 sec/batch
Epoch: 14/20...  Training Step: 2672...  Training loss: 1.2849...  0.3080 sec/batch
Epoch: 14/20...  Training Step: 2673...  Training loss: 1.2879...  0.3081 sec/batch
Epoch: 14/20...  Training Step: 2674...  Training loss: 1.2774...  0.3085 sec/batch
Epoch: 14/20...  Training Step: 2675...  Training loss: 1.3143...  0.3092 sec/batch
Epoch: 14/20...  Training Step: 2676...  Training loss: 1.3004...  0.3085 sec/batch
Epoch: 14/20...  Training Step: 2677...  Training loss: 1.3066...  0.3090 sec/batch
Epoch: 14/20...  Training Step: 2678...  Training loss: 1.3027...  0.3080 sec/batch
Epoch: 14/20...  Training Step: 2679...  Training loss: 1.2986...  0.3081 sec/batch
Epoch: 14/20...  Training Step: 2680...  Training loss: 1.2987...  0.3082 sec/batch
Epoch: 14/20...  Training Step: 2681...  Training loss: 1.3111...  0.3079 sec/batch
Epoch: 14/20...  Training Step: 2682...  Training loss: 1.3119...  0.3082 sec/batch
Epoch: 14/20...  Training Step: 2683...  Training loss: 1.2930...  0.3074 sec/batch
Epoch: 14/20...  Training Step: 2684...  Training loss: 1.3189...  0.3089 sec/batch
Epoch: 14/20...  Training Step: 2685...  Training loss: 1.2929...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2686...  Training loss: 1.2992...  0.3081 sec/batch
Epoch: 14/20...  Training Step: 2687...  Training loss: 1.3139...  0.3079 sec/batch
Epoch: 14/20...  Training Step: 2688...  Training loss: 1.3070...  0.3079 sec/batch
Epoch: 14/20...  Training Step: 2689...  Training loss: 1.2873...  0.3079 sec/batch
Epoch: 14/20...  Training Step: 2690...  Training loss: 1.2778...  0.3086 sec/batch
Epoch: 14/20...  Training Step: 2691...  Training loss: 1.3124...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2692...  Training loss: 1.3148...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2693...  Training loss: 1.2959...  0.3086 sec/batch
Epoch: 14/20...  Training Step: 2694...  Training loss: 1.3050...  0.3082 sec/batch
Epoch: 14/20...  Training Step: 2695...  Training loss: 1.3065...  0.3093 sec/batch
Epoch: 14/20...  Training Step: 2696...  Training loss: 1.2686...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2697...  Training loss: 1.2573...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2698...  Training loss: 1.3124...  0.3071 sec/batch
Epoch: 14/20...  Training Step: 2699...  Training loss: 1.3026...  0.3078 sec/batch
Epoch: 14/20...  Training Step: 2700...  Training loss: 1.2602...  0.3089 sec/batch
Epoch: 14/20...  Training Step: 2701...  Training loss: 1.3190...  0.3088 sec/batch
Epoch: 14/20...  Training Step: 2702...  Training loss: 1.3127...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2703...  Training loss: 1.2840...  0.3081 sec/batch
Epoch: 14/20...  Training Step: 2704...  Training loss: 1.2743...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2705...  Training loss: 1.2579...  0.3068 sec/batch
Epoch: 14/20...  Training Step: 2706...  Training loss: 1.2852...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2707...  Training loss: 1.3316...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2708...  Training loss: 1.3221...  0.3079 sec/batch
Epoch: 14/20...  Training Step: 2709...  Training loss: 1.3205...  0.3078 sec/batch
Epoch: 14/20...  Training Step: 2710...  Training loss: 1.3080...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2711...  Training loss: 1.3449...  0.3085 sec/batch
Epoch: 14/20...  Training Step: 2712...  Training loss: 1.3199...  0.3081 sec/batch
Epoch: 14/20...  Training Step: 2713...  Training loss: 1.3161...  0.3074 sec/batch
Epoch: 14/20...  Training Step: 2714...  Training loss: 1.3118...  0.3079 sec/batch
Epoch: 14/20...  Training Step: 2715...  Training loss: 1.3567...  0.3086 sec/batch
Epoch: 14/20...  Training Step: 2716...  Training loss: 1.3203...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2717...  Training loss: 1.3010...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2718...  Training loss: 1.3423...  0.3087 sec/batch
Epoch: 14/20...  Training Step: 2719...  Training loss: 1.2960...  0.3090 sec/batch
Epoch: 14/20...  Training Step: 2720...  Training loss: 1.3211...  0.3072 sec/batch
Epoch: 14/20...  Training Step: 2721...  Training loss: 1.3187...  0.3080 sec/batch
Epoch: 14/20...  Training Step: 2722...  Training loss: 1.3380...  0.3073 sec/batch
Epoch: 14/20...  Training Step: 2723...  Training loss: 1.3340...  0.3076 sec/batch
Epoch: 14/20...  Training Step: 2724...  Training loss: 1.3004...  0.3098 sec/batch
Epoch: 14/20...  Training Step: 2725...  Training loss: 1.2772...  0.3087 sec/batch
Epoch: 14/20...  Training Step: 2726...  Training loss: 1.2888...  0.3072 sec/batch
Epoch: 14/20...  Training Step: 2727...  Training loss: 1.3313...  0.3092 sec/batch
Epoch: 14/20...  Training Step: 2728...  Training loss: 1.3043...  0.3072 sec/batch
Epoch: 14/20...  Training Step: 2729...  Training loss: 1.3030...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2730...  Training loss: 1.3127...  0.3076 sec/batch
Epoch: 14/20...  Training Step: 2731...  Training loss: 1.3040...  0.3085 sec/batch
Epoch: 14/20...  Training Step: 2732...  Training loss: 1.3028...  0.3073 sec/batch
Epoch: 14/20...  Training Step: 2733...  Training loss: 1.2837...  0.3081 sec/batch
Epoch: 14/20...  Training Step: 2734...  Training loss: 1.3279...  0.3072 sec/batch
Epoch: 14/20...  Training Step: 2735...  Training loss: 1.3244...  0.3072 sec/batch
Epoch: 14/20...  Training Step: 2736...  Training loss: 1.3014...  0.3090 sec/batch
Epoch: 14/20...  Training Step: 2737...  Training loss: 1.3081...  0.3076 sec/batch
Epoch: 14/20...  Training Step: 2738...  Training loss: 1.3075...  0.3074 sec/batch
Epoch: 14/20...  Training Step: 2739...  Training loss: 1.3091...  0.3076 sec/batch
Epoch: 14/20...  Training Step: 2740...  Training loss: 1.3202...  0.3078 sec/batch
Epoch: 14/20...  Training Step: 2741...  Training loss: 1.3363...  0.3076 sec/batch
Epoch: 14/20...  Training Step: 2742...  Training loss: 1.3789...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2743...  Training loss: 1.3166...  0.3073 sec/batch
Epoch: 14/20...  Training Step: 2744...  Training loss: 1.3185...  0.3075 sec/batch
Epoch: 14/20...  Training Step: 2745...  Training loss: 1.3012...  0.3076 sec/batch
Epoch: 14/20...  Training Step: 2746...  Training loss: 1.3006...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2747...  Training loss: 1.3371...  0.3081 sec/batch
Epoch: 14/20...  Training Step: 2748...  Training loss: 1.2996...  0.3081 sec/batch
Epoch: 14/20...  Training Step: 2749...  Training loss: 1.3144...  0.3074 sec/batch
Epoch: 14/20...  Training Step: 2750...  Training loss: 1.2724...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2751...  Training loss: 1.2952...  0.3080 sec/batch
Epoch: 14/20...  Training Step: 2752...  Training loss: 1.3416...  0.3081 sec/batch
Epoch: 14/20...  Training Step: 2753...  Training loss: 1.2927...  0.3073 sec/batch
Epoch: 14/20...  Training Step: 2754...  Training loss: 1.2824...  0.3089 sec/batch
Epoch: 14/20...  Training Step: 2755...  Training loss: 1.2853...  0.3076 sec/batch
Epoch: 14/20...  Training Step: 2756...  Training loss: 1.2971...  0.3084 sec/batch
Epoch: 14/20...  Training Step: 2757...  Training loss: 1.3037...  0.3085 sec/batch
Epoch: 14/20...  Training Step: 2758...  Training loss: 1.2940...  0.3073 sec/batch
Epoch: 14/20...  Training Step: 2759...  Training loss: 1.2989...  0.3071 sec/batch
Epoch: 14/20...  Training Step: 2760...  Training loss: 1.2852...  0.3072 sec/batch
Epoch: 14/20...  Training Step: 2761...  Training loss: 1.3358...  0.3068 sec/batch
Epoch: 14/20...  Training Step: 2762...  Training loss: 1.3045...  0.3085 sec/batch
Epoch: 14/20...  Training Step: 2763...  Training loss: 1.2985...  0.3073 sec/batch
Epoch: 14/20...  Training Step: 2764...  Training loss: 1.2998...  0.3083 sec/batch
Epoch: 14/20...  Training Step: 2765...  Training loss: 1.2823...  0.3079 sec/batch
Epoch: 14/20...  Training Step: 2766...  Training loss: 1.2817...  0.3090 sec/batch
Epoch: 14/20...  Training Step: 2767...  Training loss: 1.3070...  0.3077 sec/batch
Epoch: 14/20...  Training Step: 2768...  Training loss: 1.2891...  0.3074 sec/batch
Epoch: 14/20...  Training Step: 2769...  Training loss: 1.2638...  0.3087 sec/batch
Epoch: 14/20...  Training Step: 2770...  Training loss: 1.3117...  0.3087 sec/batch
Epoch: 14/20...  Training Step: 2771...  Training loss: 1.2934...  0.3073 sec/batch
Epoch: 14/20...  Training Step: 2772...  Training loss: 1.2955...  0.3094 sec/batch
(1980000,)
(100, 19800)
Epoch: 15/20...  Training Step: 2773...  Training loss: 1.4696...  0.3066 sec/batch
Epoch: 15/20...  Training Step: 2774...  Training loss: 1.3084...  0.3075 sec/batch
Epoch: 15/20...  Training Step: 2775...  Training loss: 1.3048...  0.3074 sec/batch
Epoch: 15/20...  Training Step: 2776...  Training loss: 1.3228...  0.3082 sec/batch
Epoch: 15/20...  Training Step: 2777...  Training loss: 1.2843...  0.3085 sec/batch
Epoch: 15/20...  Training Step: 2778...  Training loss: 1.2663...  0.3076 sec/batch
Epoch: 15/20...  Training Step: 2779...  Training loss: 1.3085...  0.3086 sec/batch
Epoch: 15/20...  Training Step: 2780...  Training loss: 1.2905...  0.3069 sec/batch
Epoch: 15/20...  Training Step: 2781...  Training loss: 1.3140...  0.3086 sec/batch
Epoch: 15/20...  Training Step: 2782...  Training loss: 1.3009...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2783...  Training loss: 1.2774...  0.3088 sec/batch
Epoch: 15/20...  Training Step: 2784...  Training loss: 1.2958...  0.3081 sec/batch
Epoch: 15/20...  Training Step: 2785...  Training loss: 1.3090...  0.3081 sec/batch
Epoch: 15/20...  Training Step: 2786...  Training loss: 1.3113...  0.3080 sec/batch
Epoch: 15/20...  Training Step: 2787...  Training loss: 1.2891...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2788...  Training loss: 1.2811...  0.3086 sec/batch
Epoch: 15/20...  Training Step: 2789...  Training loss: 1.3156...  0.3086 sec/batch
Epoch: 15/20...  Training Step: 2790...  Training loss: 1.3256...  0.3084 sec/batch
Epoch: 15/20...  Training Step: 2791...  Training loss: 1.2937...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2792...  Training loss: 1.3357...  0.3092 sec/batch
Epoch: 15/20...  Training Step: 2793...  Training loss: 1.2992...  0.3080 sec/batch
Epoch: 15/20...  Training Step: 2794...  Training loss: 1.3191...  0.3073 sec/batch
Epoch: 15/20...  Training Step: 2795...  Training loss: 1.2926...  0.3066 sec/batch
Epoch: 15/20...  Training Step: 2796...  Training loss: 1.3131...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2797...  Training loss: 1.3044...  0.3074 sec/batch
Epoch: 15/20...  Training Step: 2798...  Training loss: 1.2583...  0.3072 sec/batch
Epoch: 15/20...  Training Step: 2799...  Training loss: 1.2756...  0.3080 sec/batch
Epoch: 15/20...  Training Step: 2800...  Training loss: 1.3178...  0.3065 sec/batch
Epoch: 15/20...  Training Step: 2801...  Training loss: 1.3198...  0.3084 sec/batch
Epoch: 15/20...  Training Step: 2802...  Training loss: 1.3198...  0.3091 sec/batch
Epoch: 15/20...  Training Step: 2803...  Training loss: 1.2919...  0.3101 sec/batch
Epoch: 15/20...  Training Step: 2804...  Training loss: 1.2713...  0.3087 sec/batch
Epoch: 15/20...  Training Step: 2805...  Training loss: 1.2990...  0.3084 sec/batch
Epoch: 15/20...  Training Step: 2806...  Training loss: 1.3077...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2807...  Training loss: 1.2832...  0.3075 sec/batch
Epoch: 15/20...  Training Step: 2808...  Training loss: 1.3098...  0.3081 sec/batch
Epoch: 15/20...  Training Step: 2809...  Training loss: 1.2794...  0.3077 sec/batch
Epoch: 15/20...  Training Step: 2810...  Training loss: 1.2562...  0.3075 sec/batch
Epoch: 15/20...  Training Step: 2811...  Training loss: 1.2565...  0.3083 sec/batch
Epoch: 15/20...  Training Step: 2812...  Training loss: 1.2886...  0.3077 sec/batch
Epoch: 15/20...  Training Step: 2813...  Training loss: 1.2692...  0.3075 sec/batch
Epoch: 15/20...  Training Step: 2814...  Training loss: 1.3275...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2815...  Training loss: 1.2928...  0.3080 sec/batch
Epoch: 15/20...  Training Step: 2816...  Training loss: 1.2705...  0.3070 sec/batch
Epoch: 15/20...  Training Step: 2817...  Training loss: 1.3046...  0.3072 sec/batch
Epoch: 15/20...  Training Step: 2818...  Training loss: 1.2773...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2819...  Training loss: 1.2830...  0.3077 sec/batch
Epoch: 15/20...  Training Step: 2820...  Training loss: 1.2910...  0.3073 sec/batch
Epoch: 15/20...  Training Step: 2821...  Training loss: 1.2926...  0.3074 sec/batch
Epoch: 15/20...  Training Step: 2822...  Training loss: 1.3096...  0.3076 sec/batch
Epoch: 15/20...  Training Step: 2823...  Training loss: 1.2593...  0.3073 sec/batch
Epoch: 15/20...  Training Step: 2824...  Training loss: 1.3351...  0.3070 sec/batch
Epoch: 15/20...  Training Step: 2825...  Training loss: 1.3043...  0.3082 sec/batch
Epoch: 15/20...  Training Step: 2826...  Training loss: 1.3119...  0.3069 sec/batch
Epoch: 15/20...  Training Step: 2827...  Training loss: 1.2907...  0.3077 sec/batch
Epoch: 15/20...  Training Step: 2828...  Training loss: 1.2905...  0.3077 sec/batch
Epoch: 15/20...  Training Step: 2829...  Training loss: 1.3097...  0.3081 sec/batch
Epoch: 15/20...  Training Step: 2830...  Training loss: 1.2841...  0.3067 sec/batch
Epoch: 15/20...  Training Step: 2831...  Training loss: 1.2763...  0.3072 sec/batch
Epoch: 15/20...  Training Step: 2832...  Training loss: 1.3270...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2833...  Training loss: 1.3017...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2834...  Training loss: 1.3580...  0.3067 sec/batch
Epoch: 15/20...  Training Step: 2835...  Training loss: 1.3189...  0.3071 sec/batch
Epoch: 15/20...  Training Step: 2836...  Training loss: 1.3127...  0.3089 sec/batch
Epoch: 15/20...  Training Step: 2837...  Training loss: 1.3031...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2838...  Training loss: 1.3104...  0.3070 sec/batch
Epoch: 15/20...  Training Step: 2839...  Training loss: 1.3195...  0.3083 sec/batch
Epoch: 15/20...  Training Step: 2840...  Training loss: 1.2800...  0.3081 sec/batch
Epoch: 15/20...  Training Step: 2841...  Training loss: 1.3093...  0.3084 sec/batch
Epoch: 15/20...  Training Step: 2842...  Training loss: 1.2817...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2843...  Training loss: 1.3372...  0.3077 sec/batch
Epoch: 15/20...  Training Step: 2844...  Training loss: 1.3170...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2845...  Training loss: 1.3376...  0.3065 sec/batch
Epoch: 15/20...  Training Step: 2846...  Training loss: 1.2707...  0.3074 sec/batch
Epoch: 15/20...  Training Step: 2847...  Training loss: 1.2982...  0.3076 sec/batch
Epoch: 15/20...  Training Step: 2848...  Training loss: 1.3208...  0.3126 sec/batch
Epoch: 15/20...  Training Step: 2849...  Training loss: 1.3009...  0.3077 sec/batch
Epoch: 15/20...  Training Step: 2850...  Training loss: 1.2944...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2851...  Training loss: 1.2571...  0.3074 sec/batch
Epoch: 15/20...  Training Step: 2852...  Training loss: 1.3082...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2853...  Training loss: 1.2640...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2854...  Training loss: 1.3039...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2855...  Training loss: 1.2670...  0.3090 sec/batch
Epoch: 15/20...  Training Step: 2856...  Training loss: 1.2981...  0.3075 sec/batch
Epoch: 15/20...  Training Step: 2857...  Training loss: 1.2705...  0.3089 sec/batch
Epoch: 15/20...  Training Step: 2858...  Training loss: 1.2951...  0.3116 sec/batch
Epoch: 15/20...  Training Step: 2859...  Training loss: 1.2675...  0.3085 sec/batch
Epoch: 15/20...  Training Step: 2860...  Training loss: 1.2886...  0.3073 sec/batch
Epoch: 15/20...  Training Step: 2861...  Training loss: 1.2579...  0.3073 sec/batch
Epoch: 15/20...  Training Step: 2862...  Training loss: 1.3027...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2863...  Training loss: 1.2803...  0.3074 sec/batch
Epoch: 15/20...  Training Step: 2864...  Training loss: 1.2841...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2865...  Training loss: 1.2756...  0.3077 sec/batch
Epoch: 15/20...  Training Step: 2866...  Training loss: 1.2725...  0.3073 sec/batch
Epoch: 15/20...  Training Step: 2867...  Training loss: 1.2805...  0.3082 sec/batch
Epoch: 15/20...  Training Step: 2868...  Training loss: 1.3064...  0.3086 sec/batch
Epoch: 15/20...  Training Step: 2869...  Training loss: 1.3071...  0.3073 sec/batch
Epoch: 15/20...  Training Step: 2870...  Training loss: 1.2553...  0.3083 sec/batch
Epoch: 15/20...  Training Step: 2871...  Training loss: 1.2781...  0.3089 sec/batch
Epoch: 15/20...  Training Step: 2872...  Training loss: 1.2718...  0.3076 sec/batch
Epoch: 15/20...  Training Step: 2873...  Training loss: 1.2985...  0.3083 sec/batch
Epoch: 15/20...  Training Step: 2874...  Training loss: 1.2785...  0.3070 sec/batch
Epoch: 15/20...  Training Step: 2875...  Training loss: 1.2908...  0.3069 sec/batch
Epoch: 15/20...  Training Step: 2876...  Training loss: 1.2865...  0.3080 sec/batch
Epoch: 15/20...  Training Step: 2877...  Training loss: 1.2871...  0.3077 sec/batch
Epoch: 15/20...  Training Step: 2878...  Training loss: 1.2834...  0.3081 sec/batch
Epoch: 15/20...  Training Step: 2879...  Training loss: 1.2974...  0.3080 sec/batch
Epoch: 15/20...  Training Step: 2880...  Training loss: 1.2987...  0.3073 sec/batch
Epoch: 15/20...  Training Step: 2881...  Training loss: 1.2829...  0.3082 sec/batch
Epoch: 15/20...  Training Step: 2882...  Training loss: 1.3121...  0.3073 sec/batch
Epoch: 15/20...  Training Step: 2883...  Training loss: 1.2779...  0.3087 sec/batch
Epoch: 15/20...  Training Step: 2884...  Training loss: 1.3028...  0.3080 sec/batch
Epoch: 15/20...  Training Step: 2885...  Training loss: 1.3051...  0.3073 sec/batch
Epoch: 15/20...  Training Step: 2886...  Training loss: 1.2822...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2887...  Training loss: 1.2750...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2888...  Training loss: 1.2622...  0.3073 sec/batch
Epoch: 15/20...  Training Step: 2889...  Training loss: 1.2966...  0.3076 sec/batch
Epoch: 15/20...  Training Step: 2890...  Training loss: 1.2996...  0.3073 sec/batch
Epoch: 15/20...  Training Step: 2891...  Training loss: 1.2869...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2892...  Training loss: 1.2862...  0.3075 sec/batch
Epoch: 15/20...  Training Step: 2893...  Training loss: 1.2922...  0.3080 sec/batch
Epoch: 15/20...  Training Step: 2894...  Training loss: 1.2586...  0.3074 sec/batch
Epoch: 15/20...  Training Step: 2895...  Training loss: 1.2547...  0.3080 sec/batch
Epoch: 15/20...  Training Step: 2896...  Training loss: 1.2973...  0.3077 sec/batch
Epoch: 15/20...  Training Step: 2897...  Training loss: 1.2855...  0.3074 sec/batch
Epoch: 15/20...  Training Step: 2898...  Training loss: 1.2500...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2899...  Training loss: 1.2980...  0.3087 sec/batch
Epoch: 15/20...  Training Step: 2900...  Training loss: 1.2931...  0.3075 sec/batch
Epoch: 15/20...  Training Step: 2901...  Training loss: 1.2732...  0.3072 sec/batch
Epoch: 15/20...  Training Step: 2902...  Training loss: 1.2557...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2903...  Training loss: 1.2405...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2904...  Training loss: 1.2637...  0.3093 sec/batch
Epoch: 15/20...  Training Step: 2905...  Training loss: 1.3088...  0.3075 sec/batch
Epoch: 15/20...  Training Step: 2906...  Training loss: 1.2980...  0.3072 sec/batch
Epoch: 15/20...  Training Step: 2907...  Training loss: 1.2956...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2908...  Training loss: 1.2879...  0.3085 sec/batch
Epoch: 15/20...  Training Step: 2909...  Training loss: 1.3164...  0.3073 sec/batch
Epoch: 15/20...  Training Step: 2910...  Training loss: 1.3105...  0.3074 sec/batch
Epoch: 15/20...  Training Step: 2911...  Training loss: 1.2827...  0.3069 sec/batch
Epoch: 15/20...  Training Step: 2912...  Training loss: 1.2935...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2913...  Training loss: 1.3365...  0.3077 sec/batch
Epoch: 15/20...  Training Step: 2914...  Training loss: 1.3108...  0.3073 sec/batch
Epoch: 15/20...  Training Step: 2915...  Training loss: 1.2928...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2916...  Training loss: 1.3219...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2917...  Training loss: 1.2811...  0.3081 sec/batch
Epoch: 15/20...  Training Step: 2918...  Training loss: 1.3105...  0.3083 sec/batch
Epoch: 15/20...  Training Step: 2919...  Training loss: 1.3041...  0.3081 sec/batch
Epoch: 15/20...  Training Step: 2920...  Training loss: 1.3256...  0.3075 sec/batch
Epoch: 15/20...  Training Step: 2921...  Training loss: 1.3220...  0.3075 sec/batch
Epoch: 15/20...  Training Step: 2922...  Training loss: 1.2886...  0.3080 sec/batch
Epoch: 15/20...  Training Step: 2923...  Training loss: 1.2546...  0.3087 sec/batch
Epoch: 15/20...  Training Step: 2924...  Training loss: 1.2711...  0.3071 sec/batch
Epoch: 15/20...  Training Step: 2925...  Training loss: 1.3022...  0.3082 sec/batch
Epoch: 15/20...  Training Step: 2926...  Training loss: 1.2889...  0.3081 sec/batch
Epoch: 15/20...  Training Step: 2927...  Training loss: 1.2857...  0.3072 sec/batch
Epoch: 15/20...  Training Step: 2928...  Training loss: 1.2948...  0.3087 sec/batch
Epoch: 15/20...  Training Step: 2929...  Training loss: 1.2920...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2930...  Training loss: 1.2903...  0.3087 sec/batch
Epoch: 15/20...  Training Step: 2931...  Training loss: 1.2614...  0.3074 sec/batch
Epoch: 15/20...  Training Step: 2932...  Training loss: 1.3132...  0.3082 sec/batch
Epoch: 15/20...  Training Step: 2933...  Training loss: 1.3097...  0.3087 sec/batch
Epoch: 15/20...  Training Step: 2934...  Training loss: 1.2955...  0.3075 sec/batch
Epoch: 15/20...  Training Step: 2935...  Training loss: 1.2918...  0.3081 sec/batch
Epoch: 15/20...  Training Step: 2936...  Training loss: 1.2913...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2937...  Training loss: 1.2908...  0.3086 sec/batch
Epoch: 15/20...  Training Step: 2938...  Training loss: 1.2897...  0.3081 sec/batch
Epoch: 15/20...  Training Step: 2939...  Training loss: 1.3165...  0.3106 sec/batch
Epoch: 15/20...  Training Step: 2940...  Training loss: 1.3539...  0.3072 sec/batch
Epoch: 15/20...  Training Step: 2941...  Training loss: 1.2973...  0.3080 sec/batch
Epoch: 15/20...  Training Step: 2942...  Training loss: 1.3082...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2943...  Training loss: 1.2759...  0.3072 sec/batch
Epoch: 15/20...  Training Step: 2944...  Training loss: 1.2784...  0.3072 sec/batch
Epoch: 15/20...  Training Step: 2945...  Training loss: 1.3088...  0.3085 sec/batch
Epoch: 15/20...  Training Step: 2946...  Training loss: 1.2936...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2947...  Training loss: 1.3003...  0.3072 sec/batch
Epoch: 15/20...  Training Step: 2948...  Training loss: 1.2637...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2949...  Training loss: 1.2870...  0.3068 sec/batch
Epoch: 15/20...  Training Step: 2950...  Training loss: 1.3174...  0.3091 sec/batch
Epoch: 15/20...  Training Step: 2951...  Training loss: 1.2657...  0.3088 sec/batch
Epoch: 15/20...  Training Step: 2952...  Training loss: 1.2636...  0.3083 sec/batch
Epoch: 15/20...  Training Step: 2953...  Training loss: 1.2671...  0.3084 sec/batch
Epoch: 15/20...  Training Step: 2954...  Training loss: 1.2763...  0.3079 sec/batch
Epoch: 15/20...  Training Step: 2955...  Training loss: 1.2993...  0.3076 sec/batch
Epoch: 15/20...  Training Step: 2956...  Training loss: 1.2833...  0.3081 sec/batch
Epoch: 15/20...  Training Step: 2957...  Training loss: 1.2769...  0.3074 sec/batch
Epoch: 15/20...  Training Step: 2958...  Training loss: 1.2794...  0.3074 sec/batch
Epoch: 15/20...  Training Step: 2959...  Training loss: 1.3156...  0.3078 sec/batch
Epoch: 15/20...  Training Step: 2960...  Training loss: 1.2875...  0.3080 sec/batch
Epoch: 15/20...  Training Step: 2961...  Training loss: 1.2896...  0.3083 sec/batch
Epoch: 15/20...  Training Step: 2962...  Training loss: 1.2827...  0.3077 sec/batch
Epoch: 15/20...  Training Step: 2963...  Training loss: 1.2602...  0.3072 sec/batch
Epoch: 15/20...  Training Step: 2964...  Training loss: 1.2646...  0.3074 sec/batch
Epoch: 15/20...  Training Step: 2965...  Training loss: 1.2869...  0.3082 sec/batch
Epoch: 15/20...  Training Step: 2966...  Training loss: 1.2721...  0.3074 sec/batch
Epoch: 15/20...  Training Step: 2967...  Training loss: 1.2569...  0.3076 sec/batch
Epoch: 15/20...  Training Step: 2968...  Training loss: 1.2985...  0.3074 sec/batch
Epoch: 15/20...  Training Step: 2969...  Training loss: 1.2770...  0.3082 sec/batch
Epoch: 15/20...  Training Step: 2970...  Training loss: 1.2696...  0.3074 sec/batch
(1980000,)
(100, 19800)
Epoch: 16/20...  Training Step: 2971...  Training loss: 1.4409...  0.3073 sec/batch
Epoch: 16/20...  Training Step: 2972...  Training loss: 1.2964...  0.3068 sec/batch
Epoch: 16/20...  Training Step: 2973...  Training loss: 1.2937...  0.3080 sec/batch
Epoch: 16/20...  Training Step: 2974...  Training loss: 1.3090...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 2975...  Training loss: 1.2719...  0.3078 sec/batch
Epoch: 16/20...  Training Step: 2976...  Training loss: 1.2607...  0.3079 sec/batch
Epoch: 16/20...  Training Step: 2977...  Training loss: 1.2931...  0.3074 sec/batch
Epoch: 16/20...  Training Step: 2978...  Training loss: 1.2815...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 2979...  Training loss: 1.2887...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 2980...  Training loss: 1.2805...  0.3084 sec/batch
Epoch: 16/20...  Training Step: 2981...  Training loss: 1.2715...  0.3079 sec/batch
Epoch: 16/20...  Training Step: 2982...  Training loss: 1.2846...  0.3095 sec/batch
Epoch: 16/20...  Training Step: 2983...  Training loss: 1.2906...  0.3078 sec/batch
Epoch: 16/20...  Training Step: 2984...  Training loss: 1.3059...  0.3094 sec/batch
Epoch: 16/20...  Training Step: 2985...  Training loss: 1.2750...  0.3078 sec/batch
Epoch: 16/20...  Training Step: 2986...  Training loss: 1.2716...  0.3077 sec/batch
Epoch: 16/20...  Training Step: 2987...  Training loss: 1.3049...  0.3079 sec/batch
Epoch: 16/20...  Training Step: 2988...  Training loss: 1.3047...  0.3082 sec/batch
Epoch: 16/20...  Training Step: 2989...  Training loss: 1.2843...  0.3078 sec/batch
Epoch: 16/20...  Training Step: 2990...  Training loss: 1.3148...  0.3072 sec/batch
Epoch: 16/20...  Training Step: 2991...  Training loss: 1.2854...  0.3074 sec/batch
Epoch: 16/20...  Training Step: 2992...  Training loss: 1.3108...  0.3073 sec/batch
Epoch: 16/20...  Training Step: 2993...  Training loss: 1.2919...  0.3073 sec/batch
Epoch: 16/20...  Training Step: 2994...  Training loss: 1.3055...  0.3078 sec/batch
Epoch: 16/20...  Training Step: 2995...  Training loss: 1.2872...  0.3073 sec/batch
Epoch: 16/20...  Training Step: 2996...  Training loss: 1.2409...  0.3070 sec/batch
Epoch: 16/20...  Training Step: 2997...  Training loss: 1.2655...  0.3070 sec/batch
Epoch: 16/20...  Training Step: 2998...  Training loss: 1.3004...  0.3084 sec/batch
Epoch: 16/20...  Training Step: 2999...  Training loss: 1.3042...  0.3073 sec/batch
Epoch: 16/20...  Training Step: 3000...  Training loss: 1.3023...  0.3071 sec/batch
Epoch: 16/20...  Training Step: 3001...  Training loss: 1.2703...  0.3083 sec/batch
Epoch: 16/20...  Training Step: 3002...  Training loss: 1.2547...  0.3078 sec/batch
Epoch: 16/20...  Training Step: 3003...  Training loss: 1.2958...  0.3088 sec/batch
Epoch: 16/20...  Training Step: 3004...  Training loss: 1.2925...  0.3069 sec/batch
Epoch: 16/20...  Training Step: 3005...  Training loss: 1.2678...  0.3079 sec/batch
Epoch: 16/20...  Training Step: 3006...  Training loss: 1.2906...  0.3088 sec/batch
Epoch: 16/20...  Training Step: 3007...  Training loss: 1.2593...  0.3059 sec/batch
Epoch: 16/20...  Training Step: 3008...  Training loss: 1.2487...  0.3086 sec/batch
Epoch: 16/20...  Training Step: 3009...  Training loss: 1.2449...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 3010...  Training loss: 1.2711...  0.3072 sec/batch
Epoch: 16/20...  Training Step: 3011...  Training loss: 1.2618...  0.3084 sec/batch
Epoch: 16/20...  Training Step: 3012...  Training loss: 1.3259...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 3013...  Training loss: 1.2735...  0.3084 sec/batch
Epoch: 16/20...  Training Step: 3014...  Training loss: 1.2539...  0.3073 sec/batch
Epoch: 16/20...  Training Step: 3015...  Training loss: 1.2934...  0.3070 sec/batch
Epoch: 16/20...  Training Step: 3016...  Training loss: 1.2556...  0.3069 sec/batch
Epoch: 16/20...  Training Step: 3017...  Training loss: 1.2702...  0.3072 sec/batch
Epoch: 16/20...  Training Step: 3018...  Training loss: 1.2795...  0.3107 sec/batch
Epoch: 16/20...  Training Step: 3019...  Training loss: 1.2775...  0.3073 sec/batch
Epoch: 16/20...  Training Step: 3020...  Training loss: 1.2978...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 3021...  Training loss: 1.2499...  0.3078 sec/batch
Epoch: 16/20...  Training Step: 3022...  Training loss: 1.3242...  0.3086 sec/batch
Epoch: 16/20...  Training Step: 3023...  Training loss: 1.2899...  0.3067 sec/batch
Epoch: 16/20...  Training Step: 3024...  Training loss: 1.2933...  0.3080 sec/batch
Epoch: 16/20...  Training Step: 3025...  Training loss: 1.2794...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 3026...  Training loss: 1.2857...  0.3080 sec/batch
Epoch: 16/20...  Training Step: 3027...  Training loss: 1.2925...  0.3073 sec/batch
Epoch: 16/20...  Training Step: 3028...  Training loss: 1.2705...  0.3077 sec/batch
Epoch: 16/20...  Training Step: 3029...  Training loss: 1.2625...  0.3076 sec/batch
Epoch: 16/20...  Training Step: 3030...  Training loss: 1.3180...  0.3076 sec/batch
Epoch: 16/20...  Training Step: 3031...  Training loss: 1.2881...  0.3105 sec/batch
Epoch: 16/20...  Training Step: 3032...  Training loss: 1.3340...  0.3076 sec/batch
Epoch: 16/20...  Training Step: 3033...  Training loss: 1.2974...  0.3080 sec/batch
Epoch: 16/20...  Training Step: 3034...  Training loss: 1.2957...  0.3062 sec/batch
Epoch: 16/20...  Training Step: 3035...  Training loss: 1.2853...  0.3076 sec/batch
Epoch: 16/20...  Training Step: 3036...  Training loss: 1.2841...  0.3091 sec/batch
Epoch: 16/20...  Training Step: 3037...  Training loss: 1.2999...  0.3083 sec/batch
Epoch: 16/20...  Training Step: 3038...  Training loss: 1.2608...  0.3082 sec/batch
Epoch: 16/20...  Training Step: 3039...  Training loss: 1.2850...  0.3081 sec/batch
Epoch: 16/20...  Training Step: 3040...  Training loss: 1.2653...  0.3085 sec/batch
Epoch: 16/20...  Training Step: 3041...  Training loss: 1.3163...  0.3081 sec/batch
Epoch: 16/20...  Training Step: 3042...  Training loss: 1.3059...  0.3093 sec/batch
Epoch: 16/20...  Training Step: 3043...  Training loss: 1.3137...  0.3094 sec/batch
Epoch: 16/20...  Training Step: 3044...  Training loss: 1.2610...  0.3082 sec/batch
Epoch: 16/20...  Training Step: 3045...  Training loss: 1.2937...  0.3078 sec/batch
Epoch: 16/20...  Training Step: 3046...  Training loss: 1.3114...  0.3084 sec/batch
Epoch: 16/20...  Training Step: 3047...  Training loss: 1.2829...  0.3090 sec/batch
Epoch: 16/20...  Training Step: 3048...  Training loss: 1.2760...  0.3084 sec/batch
Epoch: 16/20...  Training Step: 3049...  Training loss: 1.2371...  0.3078 sec/batch
Epoch: 16/20...  Training Step: 3050...  Training loss: 1.2804...  0.3113 sec/batch
Epoch: 16/20...  Training Step: 3051...  Training loss: 1.2482...  0.3080 sec/batch
Epoch: 16/20...  Training Step: 3052...  Training loss: 1.2818...  0.3074 sec/batch
Epoch: 16/20...  Training Step: 3053...  Training loss: 1.2466...  0.3076 sec/batch
Epoch: 16/20...  Training Step: 3054...  Training loss: 1.2723...  0.3078 sec/batch
Epoch: 16/20...  Training Step: 3055...  Training loss: 1.2597...  0.3076 sec/batch
Epoch: 16/20...  Training Step: 3056...  Training loss: 1.2767...  0.3081 sec/batch
Epoch: 16/20...  Training Step: 3057...  Training loss: 1.2553...  0.3081 sec/batch
Epoch: 16/20...  Training Step: 3058...  Training loss: 1.2690...  0.3076 sec/batch
Epoch: 16/20...  Training Step: 3059...  Training loss: 1.2448...  0.3071 sec/batch
Epoch: 16/20...  Training Step: 3060...  Training loss: 1.2912...  0.3071 sec/batch
Epoch: 16/20...  Training Step: 3061...  Training loss: 1.2635...  0.3074 sec/batch
Epoch: 16/20...  Training Step: 3062...  Training loss: 1.2652...  0.3074 sec/batch
Epoch: 16/20...  Training Step: 3063...  Training loss: 1.2514...  0.3136 sec/batch
Epoch: 16/20...  Training Step: 3064...  Training loss: 1.2562...  0.3087 sec/batch
Epoch: 16/20...  Training Step: 3065...  Training loss: 1.2613...  0.3073 sec/batch
Epoch: 16/20...  Training Step: 3066...  Training loss: 1.2964...  0.3073 sec/batch
Epoch: 16/20...  Training Step: 3067...  Training loss: 1.2928...  0.3078 sec/batch
Epoch: 16/20...  Training Step: 3068...  Training loss: 1.2511...  0.3077 sec/batch
Epoch: 16/20...  Training Step: 3069...  Training loss: 1.2560...  0.3081 sec/batch
Epoch: 16/20...  Training Step: 3070...  Training loss: 1.2532...  0.3083 sec/batch
Epoch: 16/20...  Training Step: 3071...  Training loss: 1.2854...  0.3070 sec/batch
Epoch: 16/20...  Training Step: 3072...  Training loss: 1.2661...  0.3076 sec/batch
Epoch: 16/20...  Training Step: 3073...  Training loss: 1.2760...  0.3091 sec/batch
Epoch: 16/20...  Training Step: 3074...  Training loss: 1.2700...  0.3083 sec/batch
Epoch: 16/20...  Training Step: 3075...  Training loss: 1.2739...  0.3076 sec/batch
Epoch: 16/20...  Training Step: 3076...  Training loss: 1.2747...  0.3074 sec/batch
Epoch: 16/20...  Training Step: 3077...  Training loss: 1.2832...  0.3082 sec/batch
Epoch: 16/20...  Training Step: 3078...  Training loss: 1.2770...  0.3084 sec/batch
Epoch: 16/20...  Training Step: 3079...  Training loss: 1.2672...  0.3085 sec/batch
Epoch: 16/20...  Training Step: 3080...  Training loss: 1.2968...  0.3073 sec/batch
Epoch: 16/20...  Training Step: 3081...  Training loss: 1.2642...  0.3081 sec/batch
Epoch: 16/20...  Training Step: 3082...  Training loss: 1.2904...  0.3072 sec/batch
Epoch: 16/20...  Training Step: 3083...  Training loss: 1.2859...  0.3080 sec/batch
Epoch: 16/20...  Training Step: 3084...  Training loss: 1.2707...  0.3076 sec/batch
Epoch: 16/20...  Training Step: 3085...  Training loss: 1.2569...  0.3073 sec/batch
Epoch: 16/20...  Training Step: 3086...  Training loss: 1.2569...  0.3079 sec/batch
Epoch: 16/20...  Training Step: 3087...  Training loss: 1.2754...  0.3070 sec/batch
Epoch: 16/20...  Training Step: 3088...  Training loss: 1.2862...  0.3086 sec/batch
Epoch: 16/20...  Training Step: 3089...  Training loss: 1.2759...  0.3078 sec/batch
Epoch: 16/20...  Training Step: 3090...  Training loss: 1.2708...  0.3072 sec/batch
Epoch: 16/20...  Training Step: 3091...  Training loss: 1.2783...  0.3081 sec/batch
Epoch: 16/20...  Training Step: 3092...  Training loss: 1.2422...  0.3070 sec/batch
Epoch: 16/20...  Training Step: 3093...  Training loss: 1.2358...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 3094...  Training loss: 1.2840...  0.3092 sec/batch
Epoch: 16/20...  Training Step: 3095...  Training loss: 1.2730...  0.3092 sec/batch
Epoch: 16/20...  Training Step: 3096...  Training loss: 1.2296...  0.3072 sec/batch
Epoch: 16/20...  Training Step: 3097...  Training loss: 1.2890...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 3098...  Training loss: 1.2806...  0.3080 sec/batch
Epoch: 16/20...  Training Step: 3099...  Training loss: 1.2634...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 3100...  Training loss: 1.2419...  0.3072 sec/batch
Epoch: 16/20...  Training Step: 3101...  Training loss: 1.2355...  0.3084 sec/batch
Epoch: 16/20...  Training Step: 3102...  Training loss: 1.2503...  0.3072 sec/batch
Epoch: 16/20...  Training Step: 3103...  Training loss: 1.2983...  0.3072 sec/batch
Epoch: 16/20...  Training Step: 3104...  Training loss: 1.2786...  0.3076 sec/batch
Epoch: 16/20...  Training Step: 3105...  Training loss: 1.2863...  0.3082 sec/batch
Epoch: 16/20...  Training Step: 3106...  Training loss: 1.2815...  0.3093 sec/batch
Epoch: 16/20...  Training Step: 3107...  Training loss: 1.2998...  0.3064 sec/batch
Epoch: 16/20...  Training Step: 3108...  Training loss: 1.2907...  0.3092 sec/batch
Epoch: 16/20...  Training Step: 3109...  Training loss: 1.2901...  0.3079 sec/batch
Epoch: 16/20...  Training Step: 3110...  Training loss: 1.2838...  0.3074 sec/batch
Epoch: 16/20...  Training Step: 3111...  Training loss: 1.3340...  0.3083 sec/batch
Epoch: 16/20...  Training Step: 3112...  Training loss: 1.2898...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 3113...  Training loss: 1.2762...  0.3074 sec/batch
Epoch: 16/20...  Training Step: 3114...  Training loss: 1.3061...  0.3081 sec/batch
Epoch: 16/20...  Training Step: 3115...  Training loss: 1.2708...  0.3087 sec/batch
Epoch: 16/20...  Training Step: 3116...  Training loss: 1.3024...  0.3079 sec/batch
Epoch: 16/20...  Training Step: 3117...  Training loss: 1.2937...  0.3078 sec/batch
Epoch: 16/20...  Training Step: 3118...  Training loss: 1.3176...  0.3095 sec/batch
Epoch: 16/20...  Training Step: 3119...  Training loss: 1.3048...  0.3081 sec/batch
Epoch: 16/20...  Training Step: 3120...  Training loss: 1.2731...  0.3085 sec/batch
Epoch: 16/20...  Training Step: 3121...  Training loss: 1.2491...  0.3071 sec/batch
Epoch: 16/20...  Training Step: 3122...  Training loss: 1.2479...  0.3070 sec/batch
Epoch: 16/20...  Training Step: 3123...  Training loss: 1.2868...  0.3080 sec/batch
Epoch: 16/20...  Training Step: 3124...  Training loss: 1.2707...  0.3080 sec/batch
Epoch: 16/20...  Training Step: 3125...  Training loss: 1.2746...  0.3081 sec/batch
Epoch: 16/20...  Training Step: 3126...  Training loss: 1.2753...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 3127...  Training loss: 1.2868...  0.3079 sec/batch
Epoch: 16/20...  Training Step: 3128...  Training loss: 1.2700...  0.3077 sec/batch
Epoch: 16/20...  Training Step: 3129...  Training loss: 1.2436...  0.3076 sec/batch
Epoch: 16/20...  Training Step: 3130...  Training loss: 1.2919...  0.3073 sec/batch
Epoch: 16/20...  Training Step: 3131...  Training loss: 1.2964...  0.3099 sec/batch
Epoch: 16/20...  Training Step: 3132...  Training loss: 1.2798...  0.3085 sec/batch
Epoch: 16/20...  Training Step: 3133...  Training loss: 1.2737...  0.3074 sec/batch
Epoch: 16/20...  Training Step: 3134...  Training loss: 1.2787...  0.3082 sec/batch
Epoch: 16/20...  Training Step: 3135...  Training loss: 1.2762...  0.3079 sec/batch
Epoch: 16/20...  Training Step: 3136...  Training loss: 1.2732...  0.3077 sec/batch
Epoch: 16/20...  Training Step: 3137...  Training loss: 1.3001...  0.3074 sec/batch
Epoch: 16/20...  Training Step: 3138...  Training loss: 1.3331...  0.3071 sec/batch
Epoch: 16/20...  Training Step: 3139...  Training loss: 1.2929...  0.3072 sec/batch
Epoch: 16/20...  Training Step: 3140...  Training loss: 1.2887...  0.3074 sec/batch
Epoch: 16/20...  Training Step: 3141...  Training loss: 1.2786...  0.3151 sec/batch
Epoch: 16/20...  Training Step: 3142...  Training loss: 1.2576...  0.3085 sec/batch
Epoch: 16/20...  Training Step: 3143...  Training loss: 1.3105...  0.3078 sec/batch
Epoch: 16/20...  Training Step: 3144...  Training loss: 1.2782...  0.3076 sec/batch
Epoch: 16/20...  Training Step: 3145...  Training loss: 1.2815...  0.3072 sec/batch
Epoch: 16/20...  Training Step: 3146...  Training loss: 1.2511...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 3147...  Training loss: 1.2700...  0.3071 sec/batch
Epoch: 16/20...  Training Step: 3148...  Training loss: 1.3052...  0.3070 sec/batch
Epoch: 16/20...  Training Step: 3149...  Training loss: 1.2512...  0.3077 sec/batch
Epoch: 16/20...  Training Step: 3150...  Training loss: 1.2505...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 3151...  Training loss: 1.2561...  0.3072 sec/batch
Epoch: 16/20...  Training Step: 3152...  Training loss: 1.2716...  0.3071 sec/batch
Epoch: 16/20...  Training Step: 3153...  Training loss: 1.2784...  0.3079 sec/batch
Epoch: 16/20...  Training Step: 3154...  Training loss: 1.2672...  0.3098 sec/batch
Epoch: 16/20...  Training Step: 3155...  Training loss: 1.2651...  0.3072 sec/batch
Epoch: 16/20...  Training Step: 3156...  Training loss: 1.2550...  0.3080 sec/batch
Epoch: 16/20...  Training Step: 3157...  Training loss: 1.3102...  0.3071 sec/batch
Epoch: 16/20...  Training Step: 3158...  Training loss: 1.2650...  0.3084 sec/batch
Epoch: 16/20...  Training Step: 3159...  Training loss: 1.2668...  0.3078 sec/batch
Epoch: 16/20...  Training Step: 3160...  Training loss: 1.2764...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 3161...  Training loss: 1.2587...  0.3075 sec/batch
Epoch: 16/20...  Training Step: 3162...  Training loss: 1.2605...  0.3074 sec/batch
Epoch: 16/20...  Training Step: 3163...  Training loss: 1.2854...  0.3074 sec/batch
Epoch: 16/20...  Training Step: 3164...  Training loss: 1.2589...  0.3072 sec/batch
Epoch: 16/20...  Training Step: 3165...  Training loss: 1.2368...  0.3074 sec/batch
Epoch: 16/20...  Training Step: 3166...  Training loss: 1.2773...  0.3077 sec/batch
Epoch: 16/20...  Training Step: 3167...  Training loss: 1.2656...  0.3081 sec/batch
Epoch: 16/20...  Training Step: 3168...  Training loss: 1.2567...  0.3071 sec/batch
(1980000,)
(100, 19800)
Epoch: 17/20...  Training Step: 3169...  Training loss: 1.4372...  0.3068 sec/batch
Epoch: 17/20...  Training Step: 3170...  Training loss: 1.2870...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3171...  Training loss: 1.2767...  0.3079 sec/batch
Epoch: 17/20...  Training Step: 3172...  Training loss: 1.2957...  0.3072 sec/batch
Epoch: 17/20...  Training Step: 3173...  Training loss: 1.2581...  0.3076 sec/batch
Epoch: 17/20...  Training Step: 3174...  Training loss: 1.2410...  0.3073 sec/batch
Epoch: 17/20...  Training Step: 3175...  Training loss: 1.2901...  0.3074 sec/batch
Epoch: 17/20...  Training Step: 3176...  Training loss: 1.2672...  0.3081 sec/batch
Epoch: 17/20...  Training Step: 3177...  Training loss: 1.2780...  0.3074 sec/batch
Epoch: 17/20...  Training Step: 3178...  Training loss: 1.2700...  0.3073 sec/batch
Epoch: 17/20...  Training Step: 3179...  Training loss: 1.2555...  0.3083 sec/batch
Epoch: 17/20...  Training Step: 3180...  Training loss: 1.2710...  0.3082 sec/batch
Epoch: 17/20...  Training Step: 3181...  Training loss: 1.2827...  0.3087 sec/batch
Epoch: 17/20...  Training Step: 3182...  Training loss: 1.2869...  0.3072 sec/batch
Epoch: 17/20...  Training Step: 3183...  Training loss: 1.2529...  0.3075 sec/batch
Epoch: 17/20...  Training Step: 3184...  Training loss: 1.2499...  0.3076 sec/batch
Epoch: 17/20...  Training Step: 3185...  Training loss: 1.2875...  0.3086 sec/batch
Epoch: 17/20...  Training Step: 3186...  Training loss: 1.2891...  0.3074 sec/batch
Epoch: 17/20...  Training Step: 3187...  Training loss: 1.2725...  0.3073 sec/batch
Epoch: 17/20...  Training Step: 3188...  Training loss: 1.3051...  0.3087 sec/batch
Epoch: 17/20...  Training Step: 3189...  Training loss: 1.2685...  0.3078 sec/batch
Epoch: 17/20...  Training Step: 3190...  Training loss: 1.2741...  0.3081 sec/batch
Epoch: 17/20...  Training Step: 3191...  Training loss: 1.2656...  0.3088 sec/batch
Epoch: 17/20...  Training Step: 3192...  Training loss: 1.2866...  0.3079 sec/batch
Epoch: 17/20...  Training Step: 3193...  Training loss: 1.2735...  0.3076 sec/batch
Epoch: 17/20...  Training Step: 3194...  Training loss: 1.2367...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3195...  Training loss: 1.2396...  0.3084 sec/batch
Epoch: 17/20...  Training Step: 3196...  Training loss: 1.2933...  0.3079 sec/batch
Epoch: 17/20...  Training Step: 3197...  Training loss: 1.2775...  0.3078 sec/batch
Epoch: 17/20...  Training Step: 3198...  Training loss: 1.2931...  0.3082 sec/batch
Epoch: 17/20...  Training Step: 3199...  Training loss: 1.2620...  0.3088 sec/batch
Epoch: 17/20...  Training Step: 3200...  Training loss: 1.2444...  0.3091 sec/batch
Epoch: 17/20...  Training Step: 3201...  Training loss: 1.2763...  0.3062 sec/batch
Epoch: 17/20...  Training Step: 3202...  Training loss: 1.2875...  0.3074 sec/batch
Epoch: 17/20...  Training Step: 3203...  Training loss: 1.2599...  0.3069 sec/batch
Epoch: 17/20...  Training Step: 3204...  Training loss: 1.2834...  0.3074 sec/batch
Epoch: 17/20...  Training Step: 3205...  Training loss: 1.2496...  0.3072 sec/batch
Epoch: 17/20...  Training Step: 3206...  Training loss: 1.2256...  0.3075 sec/batch
Epoch: 17/20...  Training Step: 3207...  Training loss: 1.2423...  0.3075 sec/batch
Epoch: 17/20...  Training Step: 3208...  Training loss: 1.2623...  0.3091 sec/batch
Epoch: 17/20...  Training Step: 3209...  Training loss: 1.2523...  0.3094 sec/batch
Epoch: 17/20...  Training Step: 3210...  Training loss: 1.3110...  0.3086 sec/batch
Epoch: 17/20...  Training Step: 3211...  Training loss: 1.2628...  0.3087 sec/batch
Epoch: 17/20...  Training Step: 3212...  Training loss: 1.2426...  0.3083 sec/batch
Epoch: 17/20...  Training Step: 3213...  Training loss: 1.2798...  0.3085 sec/batch
Epoch: 17/20...  Training Step: 3214...  Training loss: 1.2455...  0.3087 sec/batch
Epoch: 17/20...  Training Step: 3215...  Training loss: 1.2582...  0.3075 sec/batch
Epoch: 17/20...  Training Step: 3216...  Training loss: 1.2659...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3217...  Training loss: 1.2613...  0.3085 sec/batch
Epoch: 17/20...  Training Step: 3218...  Training loss: 1.2887...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3219...  Training loss: 1.2477...  0.3076 sec/batch
Epoch: 17/20...  Training Step: 3220...  Training loss: 1.3126...  0.3099 sec/batch
Epoch: 17/20...  Training Step: 3221...  Training loss: 1.2800...  0.3079 sec/batch
Epoch: 17/20...  Training Step: 3222...  Training loss: 1.2767...  0.3092 sec/batch
Epoch: 17/20...  Training Step: 3223...  Training loss: 1.2676...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3224...  Training loss: 1.2707...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3225...  Training loss: 1.2789...  0.3075 sec/batch
Epoch: 17/20...  Training Step: 3226...  Training loss: 1.2637...  0.3081 sec/batch
Epoch: 17/20...  Training Step: 3227...  Training loss: 1.2511...  0.3090 sec/batch
Epoch: 17/20...  Training Step: 3228...  Training loss: 1.3020...  0.3082 sec/batch
Epoch: 17/20...  Training Step: 3229...  Training loss: 1.2795...  0.3075 sec/batch
Epoch: 17/20...  Training Step: 3230...  Training loss: 1.3210...  0.3074 sec/batch
Epoch: 17/20...  Training Step: 3231...  Training loss: 1.2888...  0.3069 sec/batch
Epoch: 17/20...  Training Step: 3232...  Training loss: 1.2735...  0.3092 sec/batch
Epoch: 17/20...  Training Step: 3233...  Training loss: 1.2704...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3234...  Training loss: 1.2868...  0.3095 sec/batch
Epoch: 17/20...  Training Step: 3235...  Training loss: 1.2911...  0.3088 sec/batch
Epoch: 17/20...  Training Step: 3236...  Training loss: 1.2530...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3237...  Training loss: 1.2763...  0.3076 sec/batch
Epoch: 17/20...  Training Step: 3238...  Training loss: 1.2507...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3239...  Training loss: 1.3146...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3240...  Training loss: 1.2896...  0.3088 sec/batch
Epoch: 17/20...  Training Step: 3241...  Training loss: 1.2952...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3242...  Training loss: 1.2476...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3243...  Training loss: 1.2800...  0.3084 sec/batch
Epoch: 17/20...  Training Step: 3244...  Training loss: 1.2925...  0.3073 sec/batch
Epoch: 17/20...  Training Step: 3245...  Training loss: 1.2663...  0.3079 sec/batch
Epoch: 17/20...  Training Step: 3246...  Training loss: 1.2615...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3247...  Training loss: 1.2249...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3248...  Training loss: 1.2722...  0.3081 sec/batch
Epoch: 17/20...  Training Step: 3249...  Training loss: 1.2399...  0.3078 sec/batch
Epoch: 17/20...  Training Step: 3250...  Training loss: 1.2747...  0.3076 sec/batch
Epoch: 17/20...  Training Step: 3251...  Training loss: 1.2442...  0.3076 sec/batch
Epoch: 17/20...  Training Step: 3252...  Training loss: 1.2583...  0.3083 sec/batch
Epoch: 17/20...  Training Step: 3253...  Training loss: 1.2458...  0.3091 sec/batch
Epoch: 17/20...  Training Step: 3254...  Training loss: 1.2703...  0.3076 sec/batch
Epoch: 17/20...  Training Step: 3255...  Training loss: 1.2450...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3256...  Training loss: 1.2548...  0.3078 sec/batch
Epoch: 17/20...  Training Step: 3257...  Training loss: 1.2334...  0.3079 sec/batch
Epoch: 17/20...  Training Step: 3258...  Training loss: 1.2706...  0.3082 sec/batch
Epoch: 17/20...  Training Step: 3259...  Training loss: 1.2507...  0.3070 sec/batch
Epoch: 17/20...  Training Step: 3260...  Training loss: 1.2630...  0.3072 sec/batch
Epoch: 17/20...  Training Step: 3261...  Training loss: 1.2424...  0.3071 sec/batch
Epoch: 17/20...  Training Step: 3262...  Training loss: 1.2398...  0.3072 sec/batch
Epoch: 17/20...  Training Step: 3263...  Training loss: 1.2515...  0.3083 sec/batch
Epoch: 17/20...  Training Step: 3264...  Training loss: 1.2801...  0.3079 sec/batch
Epoch: 17/20...  Training Step: 3265...  Training loss: 1.2796...  0.3083 sec/batch
Epoch: 17/20...  Training Step: 3266...  Training loss: 1.2315...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3267...  Training loss: 1.2503...  0.3083 sec/batch
Epoch: 17/20...  Training Step: 3268...  Training loss: 1.2435...  0.3072 sec/batch
Epoch: 17/20...  Training Step: 3269...  Training loss: 1.2689...  0.3083 sec/batch
Epoch: 17/20...  Training Step: 3270...  Training loss: 1.2468...  0.3081 sec/batch
Epoch: 17/20...  Training Step: 3271...  Training loss: 1.2655...  0.3084 sec/batch
Epoch: 17/20...  Training Step: 3272...  Training loss: 1.2599...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3273...  Training loss: 1.2646...  0.3078 sec/batch
Epoch: 17/20...  Training Step: 3274...  Training loss: 1.2568...  0.3074 sec/batch
Epoch: 17/20...  Training Step: 3275...  Training loss: 1.2680...  0.3081 sec/batch
Epoch: 17/20...  Training Step: 3276...  Training loss: 1.2711...  0.3076 sec/batch
Epoch: 17/20...  Training Step: 3277...  Training loss: 1.2524...  0.3074 sec/batch
Epoch: 17/20...  Training Step: 3278...  Training loss: 1.2853...  0.3082 sec/batch
Epoch: 17/20...  Training Step: 3279...  Training loss: 1.2521...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3280...  Training loss: 1.2736...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3281...  Training loss: 1.2748...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3282...  Training loss: 1.2613...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3283...  Training loss: 1.2450...  0.3079 sec/batch
Epoch: 17/20...  Training Step: 3284...  Training loss: 1.2337...  0.3087 sec/batch
Epoch: 17/20...  Training Step: 3285...  Training loss: 1.2697...  0.3076 sec/batch
Epoch: 17/20...  Training Step: 3286...  Training loss: 1.2733...  0.3081 sec/batch
Epoch: 17/20...  Training Step: 3287...  Training loss: 1.2601...  0.3084 sec/batch
Epoch: 17/20...  Training Step: 3288...  Training loss: 1.2604...  0.3099 sec/batch
Epoch: 17/20...  Training Step: 3289...  Training loss: 1.2648...  0.3091 sec/batch
Epoch: 17/20...  Training Step: 3290...  Training loss: 1.2272...  0.3075 sec/batch
Epoch: 17/20...  Training Step: 3291...  Training loss: 1.2217...  0.3092 sec/batch
Epoch: 17/20...  Training Step: 3292...  Training loss: 1.2618...  0.3083 sec/batch
Epoch: 17/20...  Training Step: 3293...  Training loss: 1.2633...  0.3097 sec/batch
Epoch: 17/20...  Training Step: 3294...  Training loss: 1.2274...  0.3083 sec/batch
Epoch: 17/20...  Training Step: 3295...  Training loss: 1.2779...  0.3085 sec/batch
Epoch: 17/20...  Training Step: 3296...  Training loss: 1.2572...  0.3079 sec/batch
Epoch: 17/20...  Training Step: 3297...  Training loss: 1.2543...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3298...  Training loss: 1.2201...  0.3078 sec/batch
Epoch: 17/20...  Training Step: 3299...  Training loss: 1.2186...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3300...  Training loss: 1.2463...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3301...  Training loss: 1.2837...  0.3081 sec/batch
Epoch: 17/20...  Training Step: 3302...  Training loss: 1.2686...  0.3078 sec/batch
Epoch: 17/20...  Training Step: 3303...  Training loss: 1.2642...  0.3085 sec/batch
Epoch: 17/20...  Training Step: 3304...  Training loss: 1.2645...  0.3078 sec/batch
Epoch: 17/20...  Training Step: 3305...  Training loss: 1.2879...  0.3089 sec/batch
Epoch: 17/20...  Training Step: 3306...  Training loss: 1.2771...  0.3085 sec/batch
Epoch: 17/20...  Training Step: 3307...  Training loss: 1.2689...  0.3086 sec/batch
Epoch: 17/20...  Training Step: 3308...  Training loss: 1.2734...  0.3085 sec/batch
Epoch: 17/20...  Training Step: 3309...  Training loss: 1.3112...  0.3087 sec/batch
Epoch: 17/20...  Training Step: 3310...  Training loss: 1.2882...  0.3084 sec/batch
Epoch: 17/20...  Training Step: 3311...  Training loss: 1.2631...  0.3078 sec/batch
Epoch: 17/20...  Training Step: 3312...  Training loss: 1.2940...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3313...  Training loss: 1.2560...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3314...  Training loss: 1.2838...  0.3076 sec/batch
Epoch: 17/20...  Training Step: 3315...  Training loss: 1.2865...  0.3078 sec/batch
Epoch: 17/20...  Training Step: 3316...  Training loss: 1.3051...  0.3082 sec/batch
Epoch: 17/20...  Training Step: 3317...  Training loss: 1.2981...  0.3084 sec/batch
Epoch: 17/20...  Training Step: 3318...  Training loss: 1.2643...  0.3078 sec/batch
Epoch: 17/20...  Training Step: 3319...  Training loss: 1.2367...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3320...  Training loss: 1.2358...  0.3111 sec/batch
Epoch: 17/20...  Training Step: 3321...  Training loss: 1.2717...  0.3075 sec/batch
Epoch: 17/20...  Training Step: 3322...  Training loss: 1.2591...  0.3081 sec/batch
Epoch: 17/20...  Training Step: 3323...  Training loss: 1.2556...  0.3088 sec/batch
Epoch: 17/20...  Training Step: 3324...  Training loss: 1.2626...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3325...  Training loss: 1.2648...  0.3076 sec/batch
Epoch: 17/20...  Training Step: 3326...  Training loss: 1.2549...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3327...  Training loss: 1.2286...  0.3088 sec/batch
Epoch: 17/20...  Training Step: 3328...  Training loss: 1.2830...  0.3078 sec/batch
Epoch: 17/20...  Training Step: 3329...  Training loss: 1.2951...  0.3076 sec/batch
Epoch: 17/20...  Training Step: 3330...  Training loss: 1.2698...  0.3126 sec/batch
Epoch: 17/20...  Training Step: 3331...  Training loss: 1.2607...  0.3075 sec/batch
Epoch: 17/20...  Training Step: 3332...  Training loss: 1.2605...  0.3083 sec/batch
Epoch: 17/20...  Training Step: 3333...  Training loss: 1.2719...  0.3079 sec/batch
Epoch: 17/20...  Training Step: 3334...  Training loss: 1.2599...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3335...  Training loss: 1.2972...  0.3074 sec/batch
Epoch: 17/20...  Training Step: 3336...  Training loss: 1.3277...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3337...  Training loss: 1.2786...  0.3089 sec/batch
Epoch: 17/20...  Training Step: 3338...  Training loss: 1.2797...  0.3084 sec/batch
Epoch: 17/20...  Training Step: 3339...  Training loss: 1.2529...  0.3084 sec/batch
Epoch: 17/20...  Training Step: 3340...  Training loss: 1.2504...  0.3092 sec/batch
Epoch: 17/20...  Training Step: 3341...  Training loss: 1.2944...  0.3084 sec/batch
Epoch: 17/20...  Training Step: 3342...  Training loss: 1.2611...  0.3081 sec/batch
Epoch: 17/20...  Training Step: 3343...  Training loss: 1.2701...  0.3088 sec/batch
Epoch: 17/20...  Training Step: 3344...  Training loss: 1.2267...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3345...  Training loss: 1.2530...  0.3090 sec/batch
Epoch: 17/20...  Training Step: 3346...  Training loss: 1.2903...  0.3063 sec/batch
Epoch: 17/20...  Training Step: 3347...  Training loss: 1.2470...  0.3084 sec/batch
Epoch: 17/20...  Training Step: 3348...  Training loss: 1.2374...  0.3079 sec/batch
Epoch: 17/20...  Training Step: 3349...  Training loss: 1.2455...  0.3087 sec/batch
Epoch: 17/20...  Training Step: 3350...  Training loss: 1.2687...  0.3089 sec/batch
Epoch: 17/20...  Training Step: 3351...  Training loss: 1.2671...  0.3075 sec/batch
Epoch: 17/20...  Training Step: 3352...  Training loss: 1.2664...  0.3079 sec/batch
Epoch: 17/20...  Training Step: 3353...  Training loss: 1.2549...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3354...  Training loss: 1.2465...  0.3080 sec/batch
Epoch: 17/20...  Training Step: 3355...  Training loss: 1.2850...  0.3087 sec/batch
Epoch: 17/20...  Training Step: 3356...  Training loss: 1.2625...  0.3082 sec/batch
Epoch: 17/20...  Training Step: 3357...  Training loss: 1.2627...  0.3085 sec/batch
Epoch: 17/20...  Training Step: 3358...  Training loss: 1.2664...  0.3082 sec/batch
Epoch: 17/20...  Training Step: 3359...  Training loss: 1.2328...  0.3085 sec/batch
Epoch: 17/20...  Training Step: 3360...  Training loss: 1.2446...  0.3084 sec/batch
Epoch: 17/20...  Training Step: 3361...  Training loss: 1.2704...  0.3094 sec/batch
Epoch: 17/20...  Training Step: 3362...  Training loss: 1.2532...  0.3081 sec/batch
Epoch: 17/20...  Training Step: 3363...  Training loss: 1.2246...  0.3078 sec/batch
Epoch: 17/20...  Training Step: 3364...  Training loss: 1.2653...  0.3077 sec/batch
Epoch: 17/20...  Training Step: 3365...  Training loss: 1.2593...  0.3084 sec/batch
Epoch: 17/20...  Training Step: 3366...  Training loss: 1.2557...  0.3080 sec/batch
(1980000,)
(100, 19800)
Epoch: 18/20...  Training Step: 3367...  Training loss: 1.4141...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3368...  Training loss: 1.2761...  0.3084 sec/batch
Epoch: 18/20...  Training Step: 3369...  Training loss: 1.2682...  0.3077 sec/batch
Epoch: 18/20...  Training Step: 3370...  Training loss: 1.2939...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3371...  Training loss: 1.2400...  0.3097 sec/batch
Epoch: 18/20...  Training Step: 3372...  Training loss: 1.2251...  0.3077 sec/batch
Epoch: 18/20...  Training Step: 3373...  Training loss: 1.2586...  0.3088 sec/batch
Epoch: 18/20...  Training Step: 3374...  Training loss: 1.2517...  0.3080 sec/batch
Epoch: 18/20...  Training Step: 3375...  Training loss: 1.2677...  0.3081 sec/batch
Epoch: 18/20...  Training Step: 3376...  Training loss: 1.2593...  0.3080 sec/batch
Epoch: 18/20...  Training Step: 3377...  Training loss: 1.2344...  0.3087 sec/batch
Epoch: 18/20...  Training Step: 3378...  Training loss: 1.2623...  0.3085 sec/batch
Epoch: 18/20...  Training Step: 3379...  Training loss: 1.2603...  0.3085 sec/batch
Epoch: 18/20...  Training Step: 3380...  Training loss: 1.2822...  0.3093 sec/batch
Epoch: 18/20...  Training Step: 3381...  Training loss: 1.2365...  0.3065 sec/batch
Epoch: 18/20...  Training Step: 3382...  Training loss: 1.2361...  0.3085 sec/batch
Epoch: 18/20...  Training Step: 3383...  Training loss: 1.2766...  0.3081 sec/batch
Epoch: 18/20...  Training Step: 3384...  Training loss: 1.2757...  0.3081 sec/batch
Epoch: 18/20...  Training Step: 3385...  Training loss: 1.2679...  0.3088 sec/batch
Epoch: 18/20...  Training Step: 3386...  Training loss: 1.2922...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3387...  Training loss: 1.2621...  0.3082 sec/batch
Epoch: 18/20...  Training Step: 3388...  Training loss: 1.2806...  0.3079 sec/batch
Epoch: 18/20...  Training Step: 3389...  Training loss: 1.2603...  0.3084 sec/batch
Epoch: 18/20...  Training Step: 3390...  Training loss: 1.2842...  0.3079 sec/batch
Epoch: 18/20...  Training Step: 3391...  Training loss: 1.2640...  0.3074 sec/batch
Epoch: 18/20...  Training Step: 3392...  Training loss: 1.2270...  0.3080 sec/batch
Epoch: 18/20...  Training Step: 3393...  Training loss: 1.2350...  0.3089 sec/batch
Epoch: 18/20...  Training Step: 3394...  Training loss: 1.2837...  0.3080 sec/batch
Epoch: 18/20...  Training Step: 3395...  Training loss: 1.2734...  0.3079 sec/batch
Epoch: 18/20...  Training Step: 3396...  Training loss: 1.2839...  0.3080 sec/batch
Epoch: 18/20...  Training Step: 3397...  Training loss: 1.2486...  0.3077 sec/batch
Epoch: 18/20...  Training Step: 3398...  Training loss: 1.2287...  0.3105 sec/batch
Epoch: 18/20...  Training Step: 3399...  Training loss: 1.2670...  0.3080 sec/batch
Epoch: 18/20...  Training Step: 3400...  Training loss: 1.2686...  0.3077 sec/batch
Epoch: 18/20...  Training Step: 3401...  Training loss: 1.2380...  0.3069 sec/batch
Epoch: 18/20...  Training Step: 3402...  Training loss: 1.2640...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3403...  Training loss: 1.2443...  0.3074 sec/batch
Epoch: 18/20...  Training Step: 3404...  Training loss: 1.2166...  0.3072 sec/batch
Epoch: 18/20...  Training Step: 3405...  Training loss: 1.2261...  0.3080 sec/batch
Epoch: 18/20...  Training Step: 3406...  Training loss: 1.2556...  0.3082 sec/batch
Epoch: 18/20...  Training Step: 3407...  Training loss: 1.2434...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3408...  Training loss: 1.2997...  0.3087 sec/batch
Epoch: 18/20...  Training Step: 3409...  Training loss: 1.2464...  0.3099 sec/batch
Epoch: 18/20...  Training Step: 3410...  Training loss: 1.2272...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3411...  Training loss: 1.2654...  0.3077 sec/batch
Epoch: 18/20...  Training Step: 3412...  Training loss: 1.2451...  0.3074 sec/batch
Epoch: 18/20...  Training Step: 3413...  Training loss: 1.2426...  0.3089 sec/batch
Epoch: 18/20...  Training Step: 3414...  Training loss: 1.2586...  0.3079 sec/batch
Epoch: 18/20...  Training Step: 3415...  Training loss: 1.2481...  0.3081 sec/batch
Epoch: 18/20...  Training Step: 3416...  Training loss: 1.2784...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3417...  Training loss: 1.2460...  0.3068 sec/batch
Epoch: 18/20...  Training Step: 3418...  Training loss: 1.3044...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3419...  Training loss: 1.2636...  0.3085 sec/batch
Epoch: 18/20...  Training Step: 3420...  Training loss: 1.2763...  0.3077 sec/batch
Epoch: 18/20...  Training Step: 3421...  Training loss: 1.2494...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3422...  Training loss: 1.2593...  0.3106 sec/batch
Epoch: 18/20...  Training Step: 3423...  Training loss: 1.2695...  0.3081 sec/batch
Epoch: 18/20...  Training Step: 3424...  Training loss: 1.2528...  0.3073 sec/batch
Epoch: 18/20...  Training Step: 3425...  Training loss: 1.2329...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3426...  Training loss: 1.2903...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3427...  Training loss: 1.2615...  0.3072 sec/batch
Epoch: 18/20...  Training Step: 3428...  Training loss: 1.3064...  0.3088 sec/batch
Epoch: 18/20...  Training Step: 3429...  Training loss: 1.2737...  0.3077 sec/batch
Epoch: 18/20...  Training Step: 3430...  Training loss: 1.2731...  0.3074 sec/batch
Epoch: 18/20...  Training Step: 3431...  Training loss: 1.2663...  0.3080 sec/batch
Epoch: 18/20...  Training Step: 3432...  Training loss: 1.2752...  0.3082 sec/batch
Epoch: 18/20...  Training Step: 3433...  Training loss: 1.2814...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3434...  Training loss: 1.2445...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3435...  Training loss: 1.2622...  0.3086 sec/batch
Epoch: 18/20...  Training Step: 3436...  Training loss: 1.2474...  0.3080 sec/batch
Epoch: 18/20...  Training Step: 3437...  Training loss: 1.3008...  0.3074 sec/batch
Epoch: 18/20...  Training Step: 3438...  Training loss: 1.2802...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3439...  Training loss: 1.2946...  0.3076 sec/batch
Epoch: 18/20...  Training Step: 3440...  Training loss: 1.2425...  0.3074 sec/batch
Epoch: 18/20...  Training Step: 3441...  Training loss: 1.2686...  0.3088 sec/batch
Epoch: 18/20...  Training Step: 3442...  Training loss: 1.2664...  0.3084 sec/batch
Epoch: 18/20...  Training Step: 3443...  Training loss: 1.2642...  0.3080 sec/batch
Epoch: 18/20...  Training Step: 3444...  Training loss: 1.2385...  0.3081 sec/batch
Epoch: 18/20...  Training Step: 3445...  Training loss: 1.2190...  0.3093 sec/batch
Epoch: 18/20...  Training Step: 3446...  Training loss: 1.2665...  0.3082 sec/batch
Epoch: 18/20...  Training Step: 3447...  Training loss: 1.2183...  0.3081 sec/batch
Epoch: 18/20...  Training Step: 3448...  Training loss: 1.2617...  0.3074 sec/batch
Epoch: 18/20...  Training Step: 3449...  Training loss: 1.2280...  0.3081 sec/batch
Epoch: 18/20...  Training Step: 3450...  Training loss: 1.2498...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3451...  Training loss: 1.2381...  0.3076 sec/batch
Epoch: 18/20...  Training Step: 3452...  Training loss: 1.2528...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3453...  Training loss: 1.2355...  0.3077 sec/batch
Epoch: 18/20...  Training Step: 3454...  Training loss: 1.2356...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3455...  Training loss: 1.2226...  0.3079 sec/batch
Epoch: 18/20...  Training Step: 3456...  Training loss: 1.2723...  0.3073 sec/batch
Epoch: 18/20...  Training Step: 3457...  Training loss: 1.2388...  0.3076 sec/batch
Epoch: 18/20...  Training Step: 3458...  Training loss: 1.2395...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3459...  Training loss: 1.2246...  0.3081 sec/batch
Epoch: 18/20...  Training Step: 3460...  Training loss: 1.2236...  0.3085 sec/batch
Epoch: 18/20...  Training Step: 3461...  Training loss: 1.2418...  0.3074 sec/batch
Epoch: 18/20...  Training Step: 3462...  Training loss: 1.2730...  0.3076 sec/batch
Epoch: 18/20...  Training Step: 3463...  Training loss: 1.2616...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3464...  Training loss: 1.2183...  0.3089 sec/batch
Epoch: 18/20...  Training Step: 3465...  Training loss: 1.2332...  0.3082 sec/batch
Epoch: 18/20...  Training Step: 3466...  Training loss: 1.2300...  0.3086 sec/batch
Epoch: 18/20...  Training Step: 3467...  Training loss: 1.2574...  0.3074 sec/batch
Epoch: 18/20...  Training Step: 3468...  Training loss: 1.2473...  0.3071 sec/batch
Epoch: 18/20...  Training Step: 3469...  Training loss: 1.2505...  0.3085 sec/batch
Epoch: 18/20...  Training Step: 3470...  Training loss: 1.2483...  0.3076 sec/batch
Epoch: 18/20...  Training Step: 3471...  Training loss: 1.2519...  0.3074 sec/batch
Epoch: 18/20...  Training Step: 3472...  Training loss: 1.2512...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3473...  Training loss: 1.2551...  0.3087 sec/batch
Epoch: 18/20...  Training Step: 3474...  Training loss: 1.2512...  0.3082 sec/batch
Epoch: 18/20...  Training Step: 3475...  Training loss: 1.2506...  0.3081 sec/batch
Epoch: 18/20...  Training Step: 3476...  Training loss: 1.2712...  0.3095 sec/batch
Epoch: 18/20...  Training Step: 3477...  Training loss: 1.2342...  0.3082 sec/batch
Epoch: 18/20...  Training Step: 3478...  Training loss: 1.2614...  0.3083 sec/batch
Epoch: 18/20...  Training Step: 3479...  Training loss: 1.2501...  0.3080 sec/batch
Epoch: 18/20...  Training Step: 3480...  Training loss: 1.2530...  0.3077 sec/batch
Epoch: 18/20...  Training Step: 3481...  Training loss: 1.2279...  0.3079 sec/batch
Epoch: 18/20...  Training Step: 3482...  Training loss: 1.2231...  0.3086 sec/batch
Epoch: 18/20...  Training Step: 3483...  Training loss: 1.2642...  0.3095 sec/batch
Epoch: 18/20...  Training Step: 3484...  Training loss: 1.2551...  0.3092 sec/batch
Epoch: 18/20...  Training Step: 3485...  Training loss: 1.2471...  0.3083 sec/batch
Epoch: 18/20...  Training Step: 3486...  Training loss: 1.2531...  0.3082 sec/batch
Epoch: 18/20...  Training Step: 3487...  Training loss: 1.2466...  0.3085 sec/batch
Epoch: 18/20...  Training Step: 3488...  Training loss: 1.2186...  0.3079 sec/batch
Epoch: 18/20...  Training Step: 3489...  Training loss: 1.2127...  0.3082 sec/batch
Epoch: 18/20...  Training Step: 3490...  Training loss: 1.2535...  0.3083 sec/batch
Epoch: 18/20...  Training Step: 3491...  Training loss: 1.2426...  0.3090 sec/batch
Epoch: 18/20...  Training Step: 3492...  Training loss: 1.2129...  0.3069 sec/batch
Epoch: 18/20...  Training Step: 3493...  Training loss: 1.2519...  0.3090 sec/batch
Epoch: 18/20...  Training Step: 3494...  Training loss: 1.2540...  0.3089 sec/batch
Epoch: 18/20...  Training Step: 3495...  Training loss: 1.2303...  0.3086 sec/batch
Epoch: 18/20...  Training Step: 3496...  Training loss: 1.2146...  0.3084 sec/batch
Epoch: 18/20...  Training Step: 3497...  Training loss: 1.2030...  0.3073 sec/batch
Epoch: 18/20...  Training Step: 3498...  Training loss: 1.2434...  0.3082 sec/batch
Epoch: 18/20...  Training Step: 3499...  Training loss: 1.2733...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3500...  Training loss: 1.2530...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3501...  Training loss: 1.2627...  0.3082 sec/batch
Epoch: 18/20...  Training Step: 3502...  Training loss: 1.2435...  0.3076 sec/batch
Epoch: 18/20...  Training Step: 3503...  Training loss: 1.2736...  0.3071 sec/batch
Epoch: 18/20...  Training Step: 3504...  Training loss: 1.2747...  0.3076 sec/batch
Epoch: 18/20...  Training Step: 3505...  Training loss: 1.2619...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3506...  Training loss: 1.2655...  0.3079 sec/batch
Epoch: 18/20...  Training Step: 3507...  Training loss: 1.3045...  0.3077 sec/batch
Epoch: 18/20...  Training Step: 3508...  Training loss: 1.2718...  0.3082 sec/batch
Epoch: 18/20...  Training Step: 3509...  Training loss: 1.2520...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3510...  Training loss: 1.2859...  0.3071 sec/batch
Epoch: 18/20...  Training Step: 3511...  Training loss: 1.2431...  0.3072 sec/batch
Epoch: 18/20...  Training Step: 3512...  Training loss: 1.2637...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3513...  Training loss: 1.2637...  0.3076 sec/batch
Epoch: 18/20...  Training Step: 3514...  Training loss: 1.2858...  0.3084 sec/batch
Epoch: 18/20...  Training Step: 3515...  Training loss: 1.2767...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3516...  Training loss: 1.2502...  0.3077 sec/batch
Epoch: 18/20...  Training Step: 3517...  Training loss: 1.2276...  0.3080 sec/batch
Epoch: 18/20...  Training Step: 3518...  Training loss: 1.2301...  0.3079 sec/batch
Epoch: 18/20...  Training Step: 3519...  Training loss: 1.2625...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3520...  Training loss: 1.2432...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3521...  Training loss: 1.2414...  0.3091 sec/batch
Epoch: 18/20...  Training Step: 3522...  Training loss: 1.2604...  0.3083 sec/batch
Epoch: 18/20...  Training Step: 3523...  Training loss: 1.2538...  0.3076 sec/batch
Epoch: 18/20...  Training Step: 3524...  Training loss: 1.2429...  0.3080 sec/batch
Epoch: 18/20...  Training Step: 3525...  Training loss: 1.2180...  0.3081 sec/batch
Epoch: 18/20...  Training Step: 3526...  Training loss: 1.2711...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3527...  Training loss: 1.2844...  0.3077 sec/batch
Epoch: 18/20...  Training Step: 3528...  Training loss: 1.2626...  0.3085 sec/batch
Epoch: 18/20...  Training Step: 3529...  Training loss: 1.2591...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3530...  Training loss: 1.2658...  0.3073 sec/batch
Epoch: 18/20...  Training Step: 3531...  Training loss: 1.2559...  0.3077 sec/batch
Epoch: 18/20...  Training Step: 3532...  Training loss: 1.2480...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3533...  Training loss: 1.2738...  0.3086 sec/batch
Epoch: 18/20...  Training Step: 3534...  Training loss: 1.3093...  0.3074 sec/batch
Epoch: 18/20...  Training Step: 3535...  Training loss: 1.2733...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3536...  Training loss: 1.2610...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3537...  Training loss: 1.2473...  0.3071 sec/batch
Epoch: 18/20...  Training Step: 3538...  Training loss: 1.2465...  0.3064 sec/batch
Epoch: 18/20...  Training Step: 3539...  Training loss: 1.2813...  0.3083 sec/batch
Epoch: 18/20...  Training Step: 3540...  Training loss: 1.2532...  0.3091 sec/batch
Epoch: 18/20...  Training Step: 3541...  Training loss: 1.2641...  0.3081 sec/batch
Epoch: 18/20...  Training Step: 3542...  Training loss: 1.2198...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3543...  Training loss: 1.2445...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3544...  Training loss: 1.2868...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3545...  Training loss: 1.2306...  0.3101 sec/batch
Epoch: 18/20...  Training Step: 3546...  Training loss: 1.2345...  0.3088 sec/batch
Epoch: 18/20...  Training Step: 3547...  Training loss: 1.2326...  0.3083 sec/batch
Epoch: 18/20...  Training Step: 3548...  Training loss: 1.2493...  0.3073 sec/batch
Epoch: 18/20...  Training Step: 3549...  Training loss: 1.2536...  0.3083 sec/batch
Epoch: 18/20...  Training Step: 3550...  Training loss: 1.2484...  0.3075 sec/batch
Epoch: 18/20...  Training Step: 3551...  Training loss: 1.2419...  0.3083 sec/batch
Epoch: 18/20...  Training Step: 3552...  Training loss: 1.2378...  0.3077 sec/batch
Epoch: 18/20...  Training Step: 3553...  Training loss: 1.2843...  0.3072 sec/batch
Epoch: 18/20...  Training Step: 3554...  Training loss: 1.2533...  0.3076 sec/batch
Epoch: 18/20...  Training Step: 3555...  Training loss: 1.2447...  0.3079 sec/batch
Epoch: 18/20...  Training Step: 3556...  Training loss: 1.2550...  0.3071 sec/batch
Epoch: 18/20...  Training Step: 3557...  Training loss: 1.2285...  0.3089 sec/batch
Epoch: 18/20...  Training Step: 3558...  Training loss: 1.2404...  0.3079 sec/batch
Epoch: 18/20...  Training Step: 3559...  Training loss: 1.2453...  0.3088 sec/batch
Epoch: 18/20...  Training Step: 3560...  Training loss: 1.2350...  0.3080 sec/batch
Epoch: 18/20...  Training Step: 3561...  Training loss: 1.2198...  0.3081 sec/batch
Epoch: 18/20...  Training Step: 3562...  Training loss: 1.2655...  0.3079 sec/batch
Epoch: 18/20...  Training Step: 3563...  Training loss: 1.2580...  0.3078 sec/batch
Epoch: 18/20...  Training Step: 3564...  Training loss: 1.2368...  0.3072 sec/batch
(1980000,)
(100, 19800)
Epoch: 19/20...  Training Step: 3565...  Training loss: 1.4150...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3566...  Training loss: 1.2718...  0.3073 sec/batch
Epoch: 19/20...  Training Step: 3567...  Training loss: 1.2531...  0.3076 sec/batch
Epoch: 19/20...  Training Step: 3568...  Training loss: 1.2797...  0.3096 sec/batch
Epoch: 19/20...  Training Step: 3569...  Training loss: 1.2358...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3570...  Training loss: 1.2160...  0.3075 sec/batch
Epoch: 19/20...  Training Step: 3571...  Training loss: 1.2568...  0.3079 sec/batch
Epoch: 19/20...  Training Step: 3572...  Training loss: 1.2406...  0.3082 sec/batch
Epoch: 19/20...  Training Step: 3573...  Training loss: 1.2499...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3574...  Training loss: 1.2436...  0.3071 sec/batch
Epoch: 19/20...  Training Step: 3575...  Training loss: 1.2321...  0.3070 sec/batch
Epoch: 19/20...  Training Step: 3576...  Training loss: 1.2434...  0.3075 sec/batch
Epoch: 19/20...  Training Step: 3577...  Training loss: 1.2559...  0.3122 sec/batch
Epoch: 19/20...  Training Step: 3578...  Training loss: 1.2647...  0.3083 sec/batch
Epoch: 19/20...  Training Step: 3579...  Training loss: 1.2380...  0.3076 sec/batch
Epoch: 19/20...  Training Step: 3580...  Training loss: 1.2328...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3581...  Training loss: 1.2717...  0.3082 sec/batch
Epoch: 19/20...  Training Step: 3582...  Training loss: 1.2729...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3583...  Training loss: 1.2532...  0.3081 sec/batch
Epoch: 19/20...  Training Step: 3584...  Training loss: 1.2839...  0.3072 sec/batch
Epoch: 19/20...  Training Step: 3585...  Training loss: 1.2463...  0.3076 sec/batch
Epoch: 19/20...  Training Step: 3586...  Training loss: 1.2621...  0.3091 sec/batch
Epoch: 19/20...  Training Step: 3587...  Training loss: 1.2454...  0.3087 sec/batch
Epoch: 19/20...  Training Step: 3588...  Training loss: 1.2675...  0.3076 sec/batch
Epoch: 19/20...  Training Step: 3589...  Training loss: 1.2476...  0.3070 sec/batch
Epoch: 19/20...  Training Step: 3590...  Training loss: 1.2088...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3591...  Training loss: 1.2211...  0.3079 sec/batch
Epoch: 19/20...  Training Step: 3592...  Training loss: 1.2716...  0.3072 sec/batch
Epoch: 19/20...  Training Step: 3593...  Training loss: 1.2668...  0.3076 sec/batch
Epoch: 19/20...  Training Step: 3594...  Training loss: 1.2642...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3595...  Training loss: 1.2334...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3596...  Training loss: 1.2231...  0.3082 sec/batch
Epoch: 19/20...  Training Step: 3597...  Training loss: 1.2580...  0.3075 sec/batch
Epoch: 19/20...  Training Step: 3598...  Training loss: 1.2506...  0.3071 sec/batch
Epoch: 19/20...  Training Step: 3599...  Training loss: 1.2275...  0.3084 sec/batch
Epoch: 19/20...  Training Step: 3600...  Training loss: 1.2571...  0.3113 sec/batch
Epoch: 19/20...  Training Step: 3601...  Training loss: 1.2291...  0.3075 sec/batch
Epoch: 19/20...  Training Step: 3602...  Training loss: 1.2068...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3603...  Training loss: 1.2082...  0.3076 sec/batch
Epoch: 19/20...  Training Step: 3604...  Training loss: 1.2322...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3605...  Training loss: 1.2272...  0.3074 sec/batch
Epoch: 19/20...  Training Step: 3606...  Training loss: 1.2848...  0.3083 sec/batch
Epoch: 19/20...  Training Step: 3607...  Training loss: 1.2424...  0.3083 sec/batch
Epoch: 19/20...  Training Step: 3608...  Training loss: 1.2188...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3609...  Training loss: 1.2575...  0.3082 sec/batch
Epoch: 19/20...  Training Step: 3610...  Training loss: 1.2358...  0.3079 sec/batch
Epoch: 19/20...  Training Step: 3611...  Training loss: 1.2307...  0.3075 sec/batch
Epoch: 19/20...  Training Step: 3612...  Training loss: 1.2438...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3613...  Training loss: 1.2409...  0.3081 sec/batch
Epoch: 19/20...  Training Step: 3614...  Training loss: 1.2592...  0.3079 sec/batch
Epoch: 19/20...  Training Step: 3615...  Training loss: 1.2268...  0.3086 sec/batch
Epoch: 19/20...  Training Step: 3616...  Training loss: 1.2900...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3617...  Training loss: 1.2536...  0.3072 sec/batch
Epoch: 19/20...  Training Step: 3618...  Training loss: 1.2575...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3619...  Training loss: 1.2508...  0.3084 sec/batch
Epoch: 19/20...  Training Step: 3620...  Training loss: 1.2453...  0.3082 sec/batch
Epoch: 19/20...  Training Step: 3621...  Training loss: 1.2603...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3622...  Training loss: 1.2397...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3623...  Training loss: 1.2239...  0.3089 sec/batch
Epoch: 19/20...  Training Step: 3624...  Training loss: 1.2872...  0.3084 sec/batch
Epoch: 19/20...  Training Step: 3625...  Training loss: 1.2608...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3626...  Training loss: 1.3032...  0.3079 sec/batch
Epoch: 19/20...  Training Step: 3627...  Training loss: 1.2560...  0.3205 sec/batch
Epoch: 19/20...  Training Step: 3628...  Training loss: 1.2600...  0.3083 sec/batch
Epoch: 19/20...  Training Step: 3629...  Training loss: 1.2523...  0.3084 sec/batch
Epoch: 19/20...  Training Step: 3630...  Training loss: 1.2604...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3631...  Training loss: 1.2755...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3632...  Training loss: 1.2350...  0.3087 sec/batch
Epoch: 19/20...  Training Step: 3633...  Training loss: 1.2600...  0.3090 sec/batch
Epoch: 19/20...  Training Step: 3634...  Training loss: 1.2429...  0.3079 sec/batch
Epoch: 19/20...  Training Step: 3635...  Training loss: 1.2903...  0.3095 sec/batch
Epoch: 19/20...  Training Step: 3636...  Training loss: 1.2646...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3637...  Training loss: 1.2768...  0.3095 sec/batch
Epoch: 19/20...  Training Step: 3638...  Training loss: 1.2304...  0.3081 sec/batch
Epoch: 19/20...  Training Step: 3639...  Training loss: 1.2618...  0.3079 sec/batch
Epoch: 19/20...  Training Step: 3640...  Training loss: 1.2656...  0.3082 sec/batch
Epoch: 19/20...  Training Step: 3641...  Training loss: 1.2453...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3642...  Training loss: 1.2321...  0.3083 sec/batch
Epoch: 19/20...  Training Step: 3643...  Training loss: 1.2031...  0.3069 sec/batch
Epoch: 19/20...  Training Step: 3644...  Training loss: 1.2502...  0.3073 sec/batch
Epoch: 19/20...  Training Step: 3645...  Training loss: 1.2119...  0.3075 sec/batch
Epoch: 19/20...  Training Step: 3646...  Training loss: 1.2478...  0.3068 sec/batch
Epoch: 19/20...  Training Step: 3647...  Training loss: 1.2187...  0.3073 sec/batch
Epoch: 19/20...  Training Step: 3648...  Training loss: 1.2312...  0.3079 sec/batch
Epoch: 19/20...  Training Step: 3649...  Training loss: 1.2233...  0.3081 sec/batch
Epoch: 19/20...  Training Step: 3650...  Training loss: 1.2430...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3651...  Training loss: 1.2242...  0.3079 sec/batch
Epoch: 19/20...  Training Step: 3652...  Training loss: 1.2289...  0.3079 sec/batch
Epoch: 19/20...  Training Step: 3653...  Training loss: 1.2077...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3654...  Training loss: 1.2524...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3655...  Training loss: 1.2234...  0.3073 sec/batch
Epoch: 19/20...  Training Step: 3656...  Training loss: 1.2348...  0.3087 sec/batch
Epoch: 19/20...  Training Step: 3657...  Training loss: 1.2242...  0.3082 sec/batch
Epoch: 19/20...  Training Step: 3658...  Training loss: 1.2041...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3659...  Training loss: 1.2301...  0.3076 sec/batch
Epoch: 19/20...  Training Step: 3660...  Training loss: 1.2606...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3661...  Training loss: 1.2536...  0.3074 sec/batch
Epoch: 19/20...  Training Step: 3662...  Training loss: 1.2099...  0.3070 sec/batch
Epoch: 19/20...  Training Step: 3663...  Training loss: 1.2280...  0.3084 sec/batch
Epoch: 19/20...  Training Step: 3664...  Training loss: 1.2167...  0.3068 sec/batch
Epoch: 19/20...  Training Step: 3665...  Training loss: 1.2367...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3666...  Training loss: 1.2378...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3667...  Training loss: 1.2456...  0.3086 sec/batch
Epoch: 19/20...  Training Step: 3668...  Training loss: 1.2340...  0.3084 sec/batch
Epoch: 19/20...  Training Step: 3669...  Training loss: 1.2393...  0.3076 sec/batch
Epoch: 19/20...  Training Step: 3670...  Training loss: 1.2387...  0.3091 sec/batch
Epoch: 19/20...  Training Step: 3671...  Training loss: 1.2405...  0.3072 sec/batch
Epoch: 19/20...  Training Step: 3672...  Training loss: 1.2490...  0.3074 sec/batch
Epoch: 19/20...  Training Step: 3673...  Training loss: 1.2225...  0.3073 sec/batch
Epoch: 19/20...  Training Step: 3674...  Training loss: 1.2562...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3675...  Training loss: 1.2308...  0.3087 sec/batch
Epoch: 19/20...  Training Step: 3676...  Training loss: 1.2451...  0.3086 sec/batch
Epoch: 19/20...  Training Step: 3677...  Training loss: 1.2465...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3678...  Training loss: 1.2433...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3679...  Training loss: 1.2208...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3680...  Training loss: 1.2156...  0.3075 sec/batch
Epoch: 19/20...  Training Step: 3681...  Training loss: 1.2474...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3682...  Training loss: 1.2474...  0.3079 sec/batch
Epoch: 19/20...  Training Step: 3683...  Training loss: 1.2446...  0.3091 sec/batch
Epoch: 19/20...  Training Step: 3684...  Training loss: 1.2394...  0.3073 sec/batch
Epoch: 19/20...  Training Step: 3685...  Training loss: 1.2492...  0.3072 sec/batch
Epoch: 19/20...  Training Step: 3686...  Training loss: 1.2023...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3687...  Training loss: 1.1912...  0.3085 sec/batch
Epoch: 19/20...  Training Step: 3688...  Training loss: 1.2383...  0.3069 sec/batch
Epoch: 19/20...  Training Step: 3689...  Training loss: 1.2326...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3690...  Training loss: 1.2055...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3691...  Training loss: 1.2415...  0.3086 sec/batch
Epoch: 19/20...  Training Step: 3692...  Training loss: 1.2448...  0.3065 sec/batch
Epoch: 19/20...  Training Step: 3693...  Training loss: 1.2246...  0.3084 sec/batch
Epoch: 19/20...  Training Step: 3694...  Training loss: 1.1994...  0.3071 sec/batch
Epoch: 19/20...  Training Step: 3695...  Training loss: 1.1959...  0.3074 sec/batch
Epoch: 19/20...  Training Step: 3696...  Training loss: 1.2261...  0.3073 sec/batch
Epoch: 19/20...  Training Step: 3697...  Training loss: 1.2584...  0.3081 sec/batch
Epoch: 19/20...  Training Step: 3698...  Training loss: 1.2416...  0.3066 sec/batch
Epoch: 19/20...  Training Step: 3699...  Training loss: 1.2479...  0.3088 sec/batch
Epoch: 19/20...  Training Step: 3700...  Training loss: 1.2395...  0.3073 sec/batch
Epoch: 19/20...  Training Step: 3701...  Training loss: 1.2703...  0.3073 sec/batch
Epoch: 19/20...  Training Step: 3702...  Training loss: 1.2618...  0.3085 sec/batch
Epoch: 19/20...  Training Step: 3703...  Training loss: 1.2582...  0.3085 sec/batch
Epoch: 19/20...  Training Step: 3704...  Training loss: 1.2536...  0.3081 sec/batch
Epoch: 19/20...  Training Step: 3705...  Training loss: 1.2915...  0.3075 sec/batch
Epoch: 19/20...  Training Step: 3706...  Training loss: 1.2430...  0.3084 sec/batch
Epoch: 19/20...  Training Step: 3707...  Training loss: 1.2415...  0.3076 sec/batch
Epoch: 19/20...  Training Step: 3708...  Training loss: 1.2758...  0.3079 sec/batch
Epoch: 19/20...  Training Step: 3709...  Training loss: 1.2291...  0.3071 sec/batch
Epoch: 19/20...  Training Step: 3710...  Training loss: 1.2652...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3711...  Training loss: 1.2503...  0.3072 sec/batch
Epoch: 19/20...  Training Step: 3712...  Training loss: 1.2700...  0.3072 sec/batch
Epoch: 19/20...  Training Step: 3713...  Training loss: 1.2781...  0.3076 sec/batch
Epoch: 19/20...  Training Step: 3714...  Training loss: 1.2425...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3715...  Training loss: 1.2214...  0.3075 sec/batch
Epoch: 19/20...  Training Step: 3716...  Training loss: 1.2201...  0.3085 sec/batch
Epoch: 19/20...  Training Step: 3717...  Training loss: 1.2445...  0.3093 sec/batch
Epoch: 19/20...  Training Step: 3718...  Training loss: 1.2362...  0.3112 sec/batch
Epoch: 19/20...  Training Step: 3719...  Training loss: 1.2466...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3720...  Training loss: 1.2412...  0.3082 sec/batch
Epoch: 19/20...  Training Step: 3721...  Training loss: 1.2462...  0.3093 sec/batch
Epoch: 19/20...  Training Step: 3722...  Training loss: 1.2406...  0.3076 sec/batch
Epoch: 19/20...  Training Step: 3723...  Training loss: 1.2146...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3724...  Training loss: 1.2581...  0.3076 sec/batch
Epoch: 19/20...  Training Step: 3725...  Training loss: 1.2574...  0.3085 sec/batch
Epoch: 19/20...  Training Step: 3726...  Training loss: 1.2545...  0.3085 sec/batch
Epoch: 19/20...  Training Step: 3727...  Training loss: 1.2360...  0.3083 sec/batch
Epoch: 19/20...  Training Step: 3728...  Training loss: 1.2462...  0.3084 sec/batch
Epoch: 19/20...  Training Step: 3729...  Training loss: 1.2444...  0.3083 sec/batch
Epoch: 19/20...  Training Step: 3730...  Training loss: 1.2434...  0.3075 sec/batch
Epoch: 19/20...  Training Step: 3731...  Training loss: 1.2621...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3732...  Training loss: 1.3042...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3733...  Training loss: 1.2552...  0.3087 sec/batch
Epoch: 19/20...  Training Step: 3734...  Training loss: 1.2542...  0.3093 sec/batch
Epoch: 19/20...  Training Step: 3735...  Training loss: 1.2336...  0.3088 sec/batch
Epoch: 19/20...  Training Step: 3736...  Training loss: 1.2321...  0.3081 sec/batch
Epoch: 19/20...  Training Step: 3737...  Training loss: 1.2659...  0.3074 sec/batch
Epoch: 19/20...  Training Step: 3738...  Training loss: 1.2429...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3739...  Training loss: 1.2588...  0.3087 sec/batch
Epoch: 19/20...  Training Step: 3740...  Training loss: 1.2141...  0.3086 sec/batch
Epoch: 19/20...  Training Step: 3741...  Training loss: 1.2367...  0.3080 sec/batch
Epoch: 19/20...  Training Step: 3742...  Training loss: 1.2743...  0.3095 sec/batch
Epoch: 19/20...  Training Step: 3743...  Training loss: 1.2341...  0.3076 sec/batch
Epoch: 19/20...  Training Step: 3744...  Training loss: 1.2145...  0.3079 sec/batch
Epoch: 19/20...  Training Step: 3745...  Training loss: 1.2280...  0.3081 sec/batch
Epoch: 19/20...  Training Step: 3746...  Training loss: 1.2404...  0.3087 sec/batch
Epoch: 19/20...  Training Step: 3747...  Training loss: 1.2358...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3748...  Training loss: 1.2351...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3749...  Training loss: 1.2320...  0.3059 sec/batch
Epoch: 19/20...  Training Step: 3750...  Training loss: 1.2256...  0.3090 sec/batch
Epoch: 19/20...  Training Step: 3751...  Training loss: 1.2730...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3752...  Training loss: 1.2420...  0.3081 sec/batch
Epoch: 19/20...  Training Step: 3753...  Training loss: 1.2385...  0.3077 sec/batch
Epoch: 19/20...  Training Step: 3754...  Training loss: 1.2422...  0.3076 sec/batch
Epoch: 19/20...  Training Step: 3755...  Training loss: 1.2213...  0.3075 sec/batch
Epoch: 19/20...  Training Step: 3756...  Training loss: 1.2225...  0.3086 sec/batch
Epoch: 19/20...  Training Step: 3757...  Training loss: 1.2521...  0.3079 sec/batch
Epoch: 19/20...  Training Step: 3758...  Training loss: 1.2312...  0.3074 sec/batch
Epoch: 19/20...  Training Step: 3759...  Training loss: 1.2018...  0.3078 sec/batch
Epoch: 19/20...  Training Step: 3760...  Training loss: 1.2431...  0.3075 sec/batch
Epoch: 19/20...  Training Step: 3761...  Training loss: 1.2338...  0.3083 sec/batch
Epoch: 19/20...  Training Step: 3762...  Training loss: 1.2252...  0.3090 sec/batch
(1980000,)
(100, 19800)
Epoch: 20/20...  Training Step: 3763...  Training loss: 1.3926...  0.3077 sec/batch
Epoch: 20/20...  Training Step: 3764...  Training loss: 1.2583...  0.3090 sec/batch
Epoch: 20/20...  Training Step: 3765...  Training loss: 1.2383...  0.3096 sec/batch
Epoch: 20/20...  Training Step: 3766...  Training loss: 1.2558...  0.3079 sec/batch
Epoch: 20/20...  Training Step: 3767...  Training loss: 1.2201...  0.3088 sec/batch
Epoch: 20/20...  Training Step: 3768...  Training loss: 1.2064...  0.3074 sec/batch
Epoch: 20/20...  Training Step: 3769...  Training loss: 1.2446...  0.3077 sec/batch
Epoch: 20/20...  Training Step: 3770...  Training loss: 1.2353...  0.3076 sec/batch
Epoch: 20/20...  Training Step: 3771...  Training loss: 1.2387...  0.3078 sec/batch
Epoch: 20/20...  Training Step: 3772...  Training loss: 1.2263...  0.3075 sec/batch
Epoch: 20/20...  Training Step: 3773...  Training loss: 1.2159...  0.3136 sec/batch
Epoch: 20/20...  Training Step: 3774...  Training loss: 1.2332...  0.3088 sec/batch
Epoch: 20/20...  Training Step: 3775...  Training loss: 1.2481...  0.3079 sec/batch
Epoch: 20/20...  Training Step: 3776...  Training loss: 1.2526...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3777...  Training loss: 1.2158...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3778...  Training loss: 1.2218...  0.3089 sec/batch
Epoch: 20/20...  Training Step: 3779...  Training loss: 1.2543...  0.3083 sec/batch
Epoch: 20/20...  Training Step: 3780...  Training loss: 1.2561...  0.3074 sec/batch
Epoch: 20/20...  Training Step: 3781...  Training loss: 1.2427...  0.3074 sec/batch
Epoch: 20/20...  Training Step: 3782...  Training loss: 1.2664...  0.3092 sec/batch
Epoch: 20/20...  Training Step: 3783...  Training loss: 1.2339...  0.3069 sec/batch
Epoch: 20/20...  Training Step: 3784...  Training loss: 1.2701...  0.3072 sec/batch
Epoch: 20/20...  Training Step: 3785...  Training loss: 1.2328...  0.3080 sec/batch
Epoch: 20/20...  Training Step: 3786...  Training loss: 1.2616...  0.3088 sec/batch
Epoch: 20/20...  Training Step: 3787...  Training loss: 1.2512...  0.3078 sec/batch
Epoch: 20/20...  Training Step: 3788...  Training loss: 1.2042...  0.3089 sec/batch
Epoch: 20/20...  Training Step: 3789...  Training loss: 1.2180...  0.3075 sec/batch
Epoch: 20/20...  Training Step: 3790...  Training loss: 1.2581...  0.3073 sec/batch
Epoch: 20/20...  Training Step: 3791...  Training loss: 1.2603...  0.3091 sec/batch
Epoch: 20/20...  Training Step: 3792...  Training loss: 1.2581...  0.3086 sec/batch
Epoch: 20/20...  Training Step: 3793...  Training loss: 1.2196...  0.3089 sec/batch
Epoch: 20/20...  Training Step: 3794...  Training loss: 1.2197...  0.3086 sec/batch
Epoch: 20/20...  Training Step: 3795...  Training loss: 1.2460...  0.3073 sec/batch
Epoch: 20/20...  Training Step: 3796...  Training loss: 1.2429...  0.3071 sec/batch
Epoch: 20/20...  Training Step: 3797...  Training loss: 1.2170...  0.3076 sec/batch
Epoch: 20/20...  Training Step: 3798...  Training loss: 1.2482...  0.3072 sec/batch
Epoch: 20/20...  Training Step: 3799...  Training loss: 1.2167...  0.3089 sec/batch
Epoch: 20/20...  Training Step: 3800...  Training loss: 1.1937...  0.3088 sec/batch
Epoch: 20/20...  Training Step: 3801...  Training loss: 1.2032...  0.3073 sec/batch
Epoch: 20/20...  Training Step: 3802...  Training loss: 1.2315...  0.3070 sec/batch
Epoch: 20/20...  Training Step: 3803...  Training loss: 1.2135...  0.3075 sec/batch
Epoch: 20/20...  Training Step: 3804...  Training loss: 1.2804...  0.3080 sec/batch
Epoch: 20/20...  Training Step: 3805...  Training loss: 1.2282...  0.3080 sec/batch
Epoch: 20/20...  Training Step: 3806...  Training loss: 1.2118...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3807...  Training loss: 1.2506...  0.3086 sec/batch
Epoch: 20/20...  Training Step: 3808...  Training loss: 1.2190...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3809...  Training loss: 1.2213...  0.3092 sec/batch
Epoch: 20/20...  Training Step: 3810...  Training loss: 1.2332...  0.3095 sec/batch
Epoch: 20/20...  Training Step: 3811...  Training loss: 1.2247...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3812...  Training loss: 1.2540...  0.3069 sec/batch
Epoch: 20/20...  Training Step: 3813...  Training loss: 1.2056...  0.3068 sec/batch
Epoch: 20/20...  Training Step: 3814...  Training loss: 1.2701...  0.3075 sec/batch
Epoch: 20/20...  Training Step: 3815...  Training loss: 1.2439...  0.3077 sec/batch
Epoch: 20/20...  Training Step: 3816...  Training loss: 1.2552...  0.3079 sec/batch
Epoch: 20/20...  Training Step: 3817...  Training loss: 1.2388...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3818...  Training loss: 1.2435...  0.3084 sec/batch
Epoch: 20/20...  Training Step: 3819...  Training loss: 1.2460...  0.3075 sec/batch
Epoch: 20/20...  Training Step: 3820...  Training loss: 1.2380...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3821...  Training loss: 1.2206...  0.3077 sec/batch
Epoch: 20/20...  Training Step: 3822...  Training loss: 1.2683...  0.3076 sec/batch
Epoch: 20/20...  Training Step: 3823...  Training loss: 1.2513...  0.3084 sec/batch
Epoch: 20/20...  Training Step: 3824...  Training loss: 1.2931...  0.3074 sec/batch
Epoch: 20/20...  Training Step: 3825...  Training loss: 1.2556...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3826...  Training loss: 1.2618...  0.3076 sec/batch
Epoch: 20/20...  Training Step: 3827...  Training loss: 1.2325...  0.3075 sec/batch
Epoch: 20/20...  Training Step: 3828...  Training loss: 1.2527...  0.3084 sec/batch
Epoch: 20/20...  Training Step: 3829...  Training loss: 1.2655...  0.3086 sec/batch
Epoch: 20/20...  Training Step: 3830...  Training loss: 1.2262...  0.3078 sec/batch
Epoch: 20/20...  Training Step: 3831...  Training loss: 1.2406...  0.3079 sec/batch
Epoch: 20/20...  Training Step: 3832...  Training loss: 1.2254...  0.3071 sec/batch
Epoch: 20/20...  Training Step: 3833...  Training loss: 1.2841...  0.3075 sec/batch
Epoch: 20/20...  Training Step: 3834...  Training loss: 1.2633...  0.3073 sec/batch
Epoch: 20/20...  Training Step: 3835...  Training loss: 1.2780...  0.3088 sec/batch
Epoch: 20/20...  Training Step: 3836...  Training loss: 1.2188...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3837...  Training loss: 1.2458...  0.3075 sec/batch
Epoch: 20/20...  Training Step: 3838...  Training loss: 1.2587...  0.3077 sec/batch
Epoch: 20/20...  Training Step: 3839...  Training loss: 1.2358...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3840...  Training loss: 1.2280...  0.3074 sec/batch
Epoch: 20/20...  Training Step: 3841...  Training loss: 1.2001...  0.3079 sec/batch
Epoch: 20/20...  Training Step: 3842...  Training loss: 1.2353...  0.3085 sec/batch
Epoch: 20/20...  Training Step: 3843...  Training loss: 1.2133...  0.3088 sec/batch
Epoch: 20/20...  Training Step: 3844...  Training loss: 1.2386...  0.3076 sec/batch
Epoch: 20/20...  Training Step: 3845...  Training loss: 1.2094...  0.3076 sec/batch
Epoch: 20/20...  Training Step: 3846...  Training loss: 1.2299...  0.3078 sec/batch
Epoch: 20/20...  Training Step: 3847...  Training loss: 1.2182...  0.3083 sec/batch
Epoch: 20/20...  Training Step: 3848...  Training loss: 1.2278...  0.3091 sec/batch
Epoch: 20/20...  Training Step: 3849...  Training loss: 1.2185...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3850...  Training loss: 1.2119...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3851...  Training loss: 1.2060...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3852...  Training loss: 1.2458...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3853...  Training loss: 1.2149...  0.3078 sec/batch
Epoch: 20/20...  Training Step: 3854...  Training loss: 1.2245...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3855...  Training loss: 1.2107...  0.3112 sec/batch
Epoch: 20/20...  Training Step: 3856...  Training loss: 1.2107...  0.3091 sec/batch
Epoch: 20/20...  Training Step: 3857...  Training loss: 1.2118...  0.3077 sec/batch
Epoch: 20/20...  Training Step: 3858...  Training loss: 1.2489...  0.3075 sec/batch
Epoch: 20/20...  Training Step: 3859...  Training loss: 1.2465...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3860...  Training loss: 1.2018...  0.3074 sec/batch
Epoch: 20/20...  Training Step: 3861...  Training loss: 1.2144...  0.3079 sec/batch
Epoch: 20/20...  Training Step: 3862...  Training loss: 1.2154...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3863...  Training loss: 1.2357...  0.3091 sec/batch
Epoch: 20/20...  Training Step: 3864...  Training loss: 1.2198...  0.3102 sec/batch
Epoch: 20/20...  Training Step: 3865...  Training loss: 1.2242...  0.3111 sec/batch
Epoch: 20/20...  Training Step: 3866...  Training loss: 1.2359...  0.3092 sec/batch
Epoch: 20/20...  Training Step: 3867...  Training loss: 1.2404...  0.3085 sec/batch
Epoch: 20/20...  Training Step: 3868...  Training loss: 1.2230...  0.3083 sec/batch
Epoch: 20/20...  Training Step: 3869...  Training loss: 1.2298...  0.3079 sec/batch
Epoch: 20/20...  Training Step: 3870...  Training loss: 1.2475...  0.3073 sec/batch
Epoch: 20/20...  Training Step: 3871...  Training loss: 1.2156...  0.3071 sec/batch
Epoch: 20/20...  Training Step: 3872...  Training loss: 1.2500...  0.3077 sec/batch
Epoch: 20/20...  Training Step: 3873...  Training loss: 1.2264...  0.3079 sec/batch
Epoch: 20/20...  Training Step: 3874...  Training loss: 1.2476...  0.3073 sec/batch
Epoch: 20/20...  Training Step: 3875...  Training loss: 1.2365...  0.3076 sec/batch
Epoch: 20/20...  Training Step: 3876...  Training loss: 1.2312...  0.3072 sec/batch
Epoch: 20/20...  Training Step: 3877...  Training loss: 1.2108...  0.3079 sec/batch
Epoch: 20/20...  Training Step: 3878...  Training loss: 1.2052...  0.3086 sec/batch
Epoch: 20/20...  Training Step: 3879...  Training loss: 1.2408...  0.3092 sec/batch
Epoch: 20/20...  Training Step: 3880...  Training loss: 1.2453...  0.3085 sec/batch
Epoch: 20/20...  Training Step: 3881...  Training loss: 1.2293...  0.3078 sec/batch
Epoch: 20/20...  Training Step: 3882...  Training loss: 1.2306...  0.3069 sec/batch
Epoch: 20/20...  Training Step: 3883...  Training loss: 1.2329...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3884...  Training loss: 1.2037...  0.3089 sec/batch
Epoch: 20/20...  Training Step: 3885...  Training loss: 1.1886...  0.3088 sec/batch
Epoch: 20/20...  Training Step: 3886...  Training loss: 1.2273...  0.3084 sec/batch
Epoch: 20/20...  Training Step: 3887...  Training loss: 1.2252...  0.3080 sec/batch
Epoch: 20/20...  Training Step: 3888...  Training loss: 1.1925...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3889...  Training loss: 1.2320...  0.3100 sec/batch
Epoch: 20/20...  Training Step: 3890...  Training loss: 1.2324...  0.3084 sec/batch
Epoch: 20/20...  Training Step: 3891...  Training loss: 1.2137...  0.3078 sec/batch
Epoch: 20/20...  Training Step: 3892...  Training loss: 1.1879...  0.3075 sec/batch
Epoch: 20/20...  Training Step: 3893...  Training loss: 1.1814...  0.3078 sec/batch
Epoch: 20/20...  Training Step: 3894...  Training loss: 1.2197...  0.3080 sec/batch
Epoch: 20/20...  Training Step: 3895...  Training loss: 1.2521...  0.3083 sec/batch
Epoch: 20/20...  Training Step: 3896...  Training loss: 1.2350...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3897...  Training loss: 1.2452...  0.3147 sec/batch
Epoch: 20/20...  Training Step: 3898...  Training loss: 1.2322...  0.3075 sec/batch
Epoch: 20/20...  Training Step: 3899...  Training loss: 1.2611...  0.3078 sec/batch
Epoch: 20/20...  Training Step: 3900...  Training loss: 1.2485...  0.3086 sec/batch
Epoch: 20/20...  Training Step: 3901...  Training loss: 1.2273...  0.3080 sec/batch
Epoch: 20/20...  Training Step: 3902...  Training loss: 1.2355...  0.3092 sec/batch
Epoch: 20/20...  Training Step: 3903...  Training loss: 1.2810...  0.3083 sec/batch
Epoch: 20/20...  Training Step: 3904...  Training loss: 1.2509...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3905...  Training loss: 1.2256...  0.3080 sec/batch
Epoch: 20/20...  Training Step: 3906...  Training loss: 1.2652...  0.3084 sec/batch
Epoch: 20/20...  Training Step: 3907...  Training loss: 1.2170...  0.3096 sec/batch
Epoch: 20/20...  Training Step: 3908...  Training loss: 1.2543...  0.3087 sec/batch
Epoch: 20/20...  Training Step: 3909...  Training loss: 1.2510...  0.3080 sec/batch
Epoch: 20/20...  Training Step: 3910...  Training loss: 1.2615...  0.3080 sec/batch
Epoch: 20/20...  Training Step: 3911...  Training loss: 1.2742...  0.3074 sec/batch
Epoch: 20/20...  Training Step: 3912...  Training loss: 1.2317...  0.3079 sec/batch
Epoch: 20/20...  Training Step: 3913...  Training loss: 1.2018...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3914...  Training loss: 1.2053...  0.3080 sec/batch
Epoch: 20/20...  Training Step: 3915...  Training loss: 1.2381...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3916...  Training loss: 1.2201...  0.3092 sec/batch
Epoch: 20/20...  Training Step: 3917...  Training loss: 1.2308...  0.3073 sec/batch
Epoch: 20/20...  Training Step: 3918...  Training loss: 1.2357...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3919...  Training loss: 1.2304...  0.3089 sec/batch
Epoch: 20/20...  Training Step: 3920...  Training loss: 1.2315...  0.3092 sec/batch
Epoch: 20/20...  Training Step: 3921...  Training loss: 1.2055...  0.3074 sec/batch
Epoch: 20/20...  Training Step: 3922...  Training loss: 1.2575...  0.3086 sec/batch
Epoch: 20/20...  Training Step: 3923...  Training loss: 1.2552...  0.3100 sec/batch
Epoch: 20/20...  Training Step: 3924...  Training loss: 1.2398...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3925...  Training loss: 1.2285...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3926...  Training loss: 1.2199...  0.3077 sec/batch
Epoch: 20/20...  Training Step: 3927...  Training loss: 1.2320...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3928...  Training loss: 1.2357...  0.3094 sec/batch
Epoch: 20/20...  Training Step: 3929...  Training loss: 1.2506...  0.3074 sec/batch
Epoch: 20/20...  Training Step: 3930...  Training loss: 1.2917...  0.3078 sec/batch
Epoch: 20/20...  Training Step: 3931...  Training loss: 1.2533...  0.3079 sec/batch
Epoch: 20/20...  Training Step: 3932...  Training loss: 1.2409...  0.3086 sec/batch
Epoch: 20/20...  Training Step: 3933...  Training loss: 1.2341...  0.3083 sec/batch
Epoch: 20/20...  Training Step: 3934...  Training loss: 1.2238...  0.3078 sec/batch
Epoch: 20/20...  Training Step: 3935...  Training loss: 1.2592...  0.3084 sec/batch
Epoch: 20/20...  Training Step: 3936...  Training loss: 1.2390...  0.3073 sec/batch
Epoch: 20/20...  Training Step: 3937...  Training loss: 1.2376...  0.3079 sec/batch
Epoch: 20/20...  Training Step: 3938...  Training loss: 1.2082...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3939...  Training loss: 1.2247...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3940...  Training loss: 1.2564...  0.3089 sec/batch
Epoch: 20/20...  Training Step: 3941...  Training loss: 1.2109...  0.3078 sec/batch
Epoch: 20/20...  Training Step: 3942...  Training loss: 1.2092...  0.3075 sec/batch
Epoch: 20/20...  Training Step: 3943...  Training loss: 1.2161...  0.3087 sec/batch
Epoch: 20/20...  Training Step: 3944...  Training loss: 1.2292...  0.3079 sec/batch
Epoch: 20/20...  Training Step: 3945...  Training loss: 1.2288...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3946...  Training loss: 1.2179...  0.3078 sec/batch
Epoch: 20/20...  Training Step: 3947...  Training loss: 1.2239...  0.3092 sec/batch
Epoch: 20/20...  Training Step: 3948...  Training loss: 1.2147...  0.3078 sec/batch
Epoch: 20/20...  Training Step: 3949...  Training loss: 1.2586...  0.3091 sec/batch
Epoch: 20/20...  Training Step: 3950...  Training loss: 1.2291...  0.3090 sec/batch
Epoch: 20/20...  Training Step: 3951...  Training loss: 1.2267...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3952...  Training loss: 1.2342...  0.3085 sec/batch
Epoch: 20/20...  Training Step: 3953...  Training loss: 1.2120...  0.3081 sec/batch
Epoch: 20/20...  Training Step: 3954...  Training loss: 1.2151...  0.3075 sec/batch
Epoch: 20/20...  Training Step: 3955...  Training loss: 1.2311...  0.3080 sec/batch
Epoch: 20/20...  Training Step: 3956...  Training loss: 1.2145...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3957...  Training loss: 1.1898...  0.3084 sec/batch
Epoch: 20/20...  Training Step: 3958...  Training loss: 1.2389...  0.3082 sec/batch
Epoch: 20/20...  Training Step: 3959...  Training loss: 1.2230...  0.3090 sec/batch
Epoch: 20/20...  Training Step: 3960...  Training loss: 1.2198...  0.3071 sec/batch
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Saved-checkpoints">Saved checkpoints<a class="anchor-link" href="#Saved-checkpoints">&#182;</a></h4><p>Read up on saving and loading checkpoints here: <a href="https://www.tensorflow.org/programmers_guide/variables">https://www.tensorflow.org/programmers_guide/variables</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_checkpoint_state</span><span class="p">(</span><span class="s1">&#39;checkpoints&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[17]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>model_checkpoint_path: &#34;checkpoints/i3960_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i200_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i400_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i600_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i800_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i1000_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i1200_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i1400_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i1600_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i1800_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i2000_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i2200_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i2400_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i2600_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i2800_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i3000_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i3200_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i3400_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i3600_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i3800_l512.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i3960_l512.ckpt&#34;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sampling">Sampling<a class="anchor-link" href="#Sampling">&#182;</a></h2><p>Now that the network is trained, we'll can use it to generate new text. The idea is that we pass in a character, then the network will predict the next character. We can use the new one, to predict the next one. And we keep doing this to generate all new text. I also included some functionality to prime the network with some text by passing in a string and building up a state from that.</p>
<p>The network gives us predictions for each character. To reduce noise and make things a little less random, I'm going to only choose a new character from the top N most likely characters.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">pick_top_n</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
    <span class="n">p</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">p</span><span class="p">)[:</span><span class="o">-</span><span class="n">top_n</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">p</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">c</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">prime</span><span class="o">=</span><span class="s2">&quot;The &quot;</span><span class="p">):</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">prime</span><span class="p">]</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">CharRNN</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">lstm_size</span><span class="o">=</span><span class="n">lstm_size</span><span class="p">,</span> <span class="n">sampling</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">)</span>
        <span class="n">new_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">initial_state</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">prime</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">vocab_to_int</span><span class="p">[</span><span class="n">c</span><span class="p">]</span>
            <span class="n">feed</span> <span class="o">=</span> <span class="p">{</span><span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.</span><span class="p">,</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">initial_state</span><span class="p">:</span> <span class="n">new_state</span><span class="p">}</span>
            <span class="n">preds</span><span class="p">,</span> <span class="n">new_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">prediction</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">final_state</span><span class="p">],</span> 
                                         <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>

        <span class="n">c</span> <span class="o">=</span> <span class="n">pick_top_n</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
        <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">int_to_vocab</span><span class="p">[</span><span class="n">c</span><span class="p">])</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
            <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span>
            <span class="n">feed</span> <span class="o">=</span> <span class="p">{</span><span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.</span><span class="p">,</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">initial_state</span><span class="p">:</span> <span class="n">new_state</span><span class="p">}</span>
            <span class="n">preds</span><span class="p">,</span> <span class="n">new_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">prediction</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">final_state</span><span class="p">],</span> 
                                         <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>

            <span class="n">c</span> <span class="o">=</span> <span class="n">pick_top_n</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">int_to_vocab</span><span class="p">[</span><span class="n">c</span><span class="p">])</span>
        
    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here, pass in the path to a checkpoint and sample from the network.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s1">&#39;checkpoints&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[20]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>&#39;checkpoints/i3960_l512.ckpt&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s1">&#39;checkpoints&#39;</span><span class="p">)</span>
<span class="n">samp</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">prime</span><span class="o">=</span><span class="s2">&quot;Far&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samp</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Farchat a profotmy
crushen to her all his heart, and the people could not let ut and was this
face, the meaning of their conversation as he was tryed to say and
walked to a shall on the soul. She stood strangely, but his hotser and
sensation was seen, and at the meeting he saw that they were simply
angry to her fact that she was not seeing the servants and that in harrow
highest heart that was in his word a party of the frame of mind; and,
as she was not long at them with the money about her, the persons was
told by the sight of the same stoll, the carriage was so married. The
princess asked the strong while, and still the bottom of shoot as a
low one of the matter was the bottle of the box they had no meeding of
all that, and to be sure they see nothing, and that it was not a secrot
of the signerint of the chance of her sole, and who was not too.

&#34;What do you say, I could have said, and, if you shall stop the same
with her?&#34;

The solitial carryages and the barrase was a shilling book to him
that he was desire to see her friendly for the past. And he could not
be disposping to his brilliant too, had not heard that he would come
to her. He was that in this service was the pride to her hat a back. That
had been a great man to see her. They had told the marshal of the most
peeple as a light of a pities, and so something in the crowd of hose
and a point of her mother too, a man though it was she was set him and
will another things while, that he had asked the self precention of his
hands which had served the same from the court of the marshal of
a man.

The present only so materially attentively he wounded her.

Anna with a former strange heart the same side and tower he went on a
sense of hold has the same feeling of himself, her feeling with a prayed
and carried into a stray the cresture to his state of them.

Stape she had seen the same painting in the station as they said, and
seeing her arm to the country. He was abroad, as though to show
her fat help then on this fac
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">checkpoint</span> <span class="o">=</span> <span class="s1">&#39;checkpoints/i200_l512.ckpt&#39;</span>
<span class="n">samp</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">prime</span><span class="o">=</span><span class="s2">&quot;Far&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samp</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fart inhe ilte
tit han anded tin to sorisg and wale the wans ons hh wos sar atot an ter se orerithe

isilsing
hh te ad sised te ad therind as tosth tasite he has his te sit torte sath
e ont asis ane and thered hhe here so son ote tan hed an as on on the wons hi at the hes adet hites
and sere the hind wot tir he so the ad to te hhe whing the hhe ane, an he she soses sad an hor th ol asesat the he san serand tes athind to ase hhind at hhe the and, and tesses ton te wor the ate ta the hes ansed, hh tir oon he war herisd the whir she sirete al ones, wans ot hit hat ond. he seted
here ane the ton athin tin an the ther
an serins ase and and, tast has sor there san tore te we tin hhe the seth san hers ther andd sor he wos thot

her sind whis ta sade his the hin an hed anse at istire she sil se to the th an hese that he se sirintise, whos at ase sad and hha ta and an ase totere sat hisd sis ate sad hire thint he ad atin ho torat ho there sint ans tis hhe timse tore whe hit tar the tor he shed ther
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">checkpoint</span> <span class="o">=</span> <span class="s1">&#39;checkpoints/i600_l512.ckpt&#39;</span>
<span class="n">samp</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">prime</span><span class="o">=</span><span class="s2">&quot;Far&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samp</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Farcilos., I dentring to
siss, the carered atous as the
stoures, and the prostant of
the prosition, what whe sale
to and to an the sincouling, and sto her
seating to her. &#34;Yes soined herself
to the himpored. 
That he was her atonte sinded one had he with aspeet how thought to
drise and a cont of his to ander
the posited to her, and weres, to desiritity, and the stilly and had treid humpiness, hers and tho sher whincs
sad ther
sited tile
tine themen whish at the
corst on the
sistertat to big her whan he was ancourd the soriens.

That it the pracertand the wat a was his had the sood. He wand to shise to at in the sard, but the pitsed, her wore his brook and the handes. Afe his seace, thas it seating a to
chalith abere weltire. She was and as it worlide, who has, and the
plicess trey seen then sace, he had hore said, the saitered his sain a poirtiof, what
he saill to him bring the caming and with an the criess the had as her suct of the saming wat of his his
that her some to and was the wist 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">checkpoint</span> <span class="o">=</span> <span class="s1">&#39;checkpoints/i1200_l512.ckpt&#39;</span>
<span class="n">samp</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">prime</span><span class="o">=</span><span class="s2">&quot;Far&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samp</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Farrinate with and all the statt over her
that had that he had been to so this heart that his was, and to and stick him
expection was atsoment, and the son the san of she was so see that
the seems of her answering. &#34;What alwoys whice would be never, will and
the sould and me, but any my sild, and
I&#39;m took on the posciot, but he saw she call, what
say a look and to have something to him wo light in
the stonter. And she&#39;s a moness were.&#34;

&#34;I&#39;vo soid it a some. I would not all the sore that he dede he
hid as something is to be meaning, we love a like her, but then and they were
then are it was
nothing in though takes if the some tood to
anywered how, but how he wanting to him; the deas and wele sawing the stent, and he saw the
searings, and though and whone ho soined that, he surped.

&#34;Will, I will be moring a good it. How she was a saming, by the mean,.

&#34;You could say he was stance a lighte at that shoulders on hos he were
and seet on at to me and strang to
his hand.&#34;

&#34;Whe mare thought, I&#39;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
